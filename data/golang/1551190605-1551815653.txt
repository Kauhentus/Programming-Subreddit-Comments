I just noticed. Amazing, since I told overhere it would probably be the beginning of March, which means: the bugs were quick to solve, or there were less bugs than expected. &amp;#x200B; Anyways good job for the GO team !!!
Yeah this is one of my concern since the framework doesn't need viper but the implementation does
Caddy's TLS 1.3 support is the main reason I was looking forward to Go 1.12, weirdly enough.
No kidding. I'm one of them.
&gt;The [ReverseProxy](https://golang.org/pkg/net/http/httputil/#ReverseProxy) now automatically proxies WebSocket requests. nice!
Well, a completely blank build on windows/amd64 went from 958kb to 1050kb, so a decent amount of base changes. Will have to see if there was more tree shaking done that will benefit larger packages (but at work, so can't test that nor performance atm :))
Thanks that help. I added a RWMutex to guard each task, which resolved the data race. 
Thanks for the explanation. :)
I agree, and we are working on this. Issue https://github.com/golang/go/issues/26827 is tracking this, so you can subscribe to it for updates.
[removed]
donde esta dockerhub image?
&gt;Hi. I don't write much Go myself, but there is a guy I taught to program who's starting to use it, so I sometimes have to field questions. &gt;When you pass a struct in Go, is it like C, where all the data in the struct is copied, or is it more like newer languages where composite objects are passed by reference and can be modified in place. Go is pass by value. &gt;In C, I would normally always pass as struct by pointer or as const so I could avoid having to copy wide data, but my gut says Go wouldn't make you do that explicitly for the sake of efficiency. It is the same in Go. If you want to avoid a large copy then you would use a pointer. &gt;My feeling is that pointers in Go are mostly for passing something you want to mutate in the caller, but I'm not sure. Are pointers ever necessary for efficiency, as in C? Yes. 
Yep, a few days or less.
Wow!
Agreed - salt and hash is the correct pattern. As an example, that is how the linux OS stores the local user passwords in the /etc/shadow file (which also has restricted permitions). &amp;#x200B; For completeness of understanding: hashing is good to avoid writting the password itself. Checking the hash is as good as checking the password, but knowing the hash does not allow to know the password easily. However hashes can be bruteforced to try to guess the password. Thats when salt'ing comes in: each linux system uses a specific "salt" to "mix" the hashes, to avoid the hashes of the same password in different systems to be the same (different systems, differents salts, different salted-hashes, so it mitigates previously bruteforced-hashes) &amp;#x200B; &amp;#x200B;
cool, thanks
and nginx is still faster than Caddy...
Thanks
Oh initially i thought it is a beam reimlpemented in go :D nice one but i would love much more to see a redone beam.smp :D as in drop in replacement. Could be fun.
The problem I ran into with learning Golang, or any programming language, is after you learn the basics, I am not sure where to go from there. What to build to progress from a beginner.
Ugh, not sure who thought os.UserHomeDir() was a good idea ... specifically that it's incompatible with os.user.Current().HomeDir which is expected/traditional behaviour. Feels like the docs. need an explicit warning at least.
```go package main import ( "io" "log" "net/http" ) func handleIndex(w http.ResponseWriter, r *http.Request) { io.WriteString(w, "Hello") } func main() { http.HandleFunc("/", handleIndex) go func() { err := http.ListenAndServe(":8080", nil) log.Fatalln(err) }() err := http.ListenAndServeTLS(":4433", "server.crt", "server.key", nil) log.Fatalln(err) } ``` Tried with ab (apache benchmark) ab -n 1000 -c 10 https://localhost:443/ Requests per second: 210.14 [#/sec] (mean) ab -n 1000 -c 10 https://localhost:8080/ Requests per second: 4643.45 [#/sec] (mean) So I would not call it negligeabel (how do you spell that?) 
File an issue?
I looked at the code now that I'm back at work. It has two problems: 1. It's forked from Go 1.5. AIUI there's been a lot of internal changes trying to handle namespaces. 2. It is in the context of a "sanitizer", and so I embedded a lot of code to check limits; that is, it validates that you don't have excessively long tags, excessively long attributes, excessively long total tags, excessively deep tag stacks, and things like that. Go devs may accept a fixed namespace API, but they'd never accept that into the core. Basically I'd be starting from scratch again. I also suspect I'd butt heads with them a bit. IMHO, managing namespaces requires the parser and emitters to maintain state, and that state pretty much has to be visible to allow users to set what the namespace abbreviations are, because they're going to insist on that. (As a rule of thumb, I strive for being able to parse a document in, and then turn right around and emit the same document out, and getting it to be visibly the same XML document; that is, whitespace and such may be different in accordance with the XML standard, but you don't go from `&lt;xhtml:p xmlns:xhtml="..."&gt;` to `&lt;NS1:p xmlns:NS1="..."&gt;`.) This inevitably complicates the UI.
+1 for TLS 1.3 and all the other goddies :)
Ok, thank you for your detailed explanation. I see what you mean. I will think about how to please both worlds with this cli tool, maybe with another flag where you can decide to use a plain `VERSION` file instead of a json file. Indeed i come from a web/app-developer background with react and react-native. In this world you have the package.json where the version of your app is stored. For these projects this cli-tool only partially makes sense, because `npm` already provides a `version` script to handle semantic versioning, but without the tagging feature for example. I missed something like that in go apps, for example. Thats the reason why i started to build a common tool for this. Again thanks for the input.
I don’t understand why golang needs to be in the title. Seems misconstrued 
Now waiting on [this](https://github.com/docker-library/official-images/pull/5473)
Click bait. Just like with: software x released, written in go!
Right. This is the kind of thing that should be downvoted imho. Along with spammers. 
Well for one thing, it works with modules. The code navigation and intellisense does not work at all in vscode (unless you are willing to wait like 8 seconds for hints) since it depends on tools that do not work with modules. JetBrains have their own tools that did not break and have not been broken for months.
&gt; the http.ListenAndServe() method is blocking, meaning it halts the program clarification: it halts the goroutine, not the entire program...
Did a “brew upgrade go” earlier today and already wondered when the hell was 1.12 released, not really keeping track of releases lately :-D
I did give it a try today, it's nice! I'm just struggling with all the different key bindings, Haha.
yeah, i get it, it is of course very hard to go serious on a 'pet' project, if the only motivation is just to learn a language. You definitely need to find a bit more meaning than that i think. My natural progression is always to do the quick language intro then look for digestible open source projects, but where i can see the usefulness of it. Alternative is to apply for a job where they use it. In my case i was just tired of the languages i had been doing like Java and C# so i wanted something new, i saw that Go was really easy to work with in Vim so that's why i started learning it. I always prematurely put things on LinkedIn, it says i know all sorts of things i have never seriously dealt with. But in this case a \`Go\` job offer came off that, some CEO wrote me directly looking for a \`Go\` dev, and i took it despite only being a 3 months for fun thing. i also think that especially with \`Go\`, if you have previous programming experience it should be very easy to start working on larger things, honestly a lot of the concepts in \`Go\` is found in any other language - and it doesn't add that much on top of it, except for the tooling and maybe a slight twist like implicit interfaces in a static lang.
How does caddy compare to traefik?
This is the most clear, safe, and simple answer. &amp;#x200B; &gt;[Clear is better than clever.](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=14m35s) &gt; &gt;\-- Go Proverb ([https://go-proverbs.github.io/](https://go-proverbs.github.io/)) &amp;#x200B;
whats wrong with beam.smp? its written on C and i don't think that there is a real reason to redone it )
&gt;https://github.com/mholt/caddy/pull/2399 I've heard tons of times that configuring nginx is an "X days of work" thing, but every time I've dealt with one, it's just the same-ish configs. A bit of gzip here, a few ssl things there, but all in all it's the same. Unless we're dealing with plugins/Lua, that is. And I've heard such things from people that I know they know their shit. Have I been missing something all this time? :/
As per the proposal, 9% improve, and 15% bigger: &gt;Preliminary results show that mid-stack inlining can improve performance by 9% (Go1 benchmarks on both amd64 and ppc64) with a 15% increase in binary size (src: [https://go.googlesource.com/proposal/+/master/design/19348-midstack-inlining.md](https://go.googlesource.com/proposal/+/master/design/19348-midstack-inlining.md)) &amp;#x200B;
“There is no real reason to redo it “ is not something ever any programmer took srsly
Or consider [gzipped.FileServer](https://github.com/lpar/gzipped) to serve static files which have been precompressed, rather than compressing them on the fly.
Go is easier to cross-compile (at least to platforms that Go supports)
&gt; I vehemently disagree on dicontainer.MasterDBConnection() or MakeMasterDBConnection "used everywhere", the former being the service locator anti-pattern and the latter being a singleton creating coupling everywhere it is used. For clarification, I meant "everywhere another dependency needs a fresh or cached db connection", because the only thing that should refer to dicontainer is itself and the main function. Using it anywhere else is, as you said, an anti-pattern (service location), though it is sometimes useful (temporarily) while you are refactoring legacy code.
Nope. Performance changes like that tell you nothing about what Go is doing. They are far more likely to be memory alignment effects. For example, this program's performance graph: https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743/
Here's the proposal that explains why os/user.Current().HomeDir is incorrect and os.UserHomeDir() should be used instead: https://github.com/golang/go/issues/26463
Thanks for the good advice
Awesome 
Is better than yerlang.
That test doesn't really expose the fact that an HTTPS connection has a protocol handshake overhead with the TLS connection that HTTP doesn't have. Testing a single connection by sending a request to the webserver on localhost and getting a 32 byte reply back has an execution time of [\~3.2ms](https://~32.ms) for HTTP and \~68ms for HTTPS on my workstation. This is why Google really wants the world to switch over to the QUIC protocol (which has recently become the basis for HTTP/3) as that has an execution time of \~8ms over UDP with TLS connection.
It does depend on what you mean by performance penalty. If your talking about a client connection time then it is much worse, however if your talking about performance from the server perspective with CPU utilisation then the performance penalty is no longer relevant (unless your dealing with embedded devices). &amp;#x200B; &amp;#x200B;
also look at [https://cloudblogs.microsoft.com/opensource/2018/12/13/introducing-ambrosia-new-platform-distributed-applications/](https://cloudblogs.microsoft.com/opensource/2018/12/13/introducing-ambrosia-new-platform-distributed-applications/)
tl;dr Wanted a simple variable because os/user isn't available in static compiles, thus. could fallback to using $HOME but then because of [cross includes](https://github.com/golang/go/issues/26463#issuecomment-406428805) it was changed to just use $HOME. *sigh*. Even the fallback to using $HOME is suspicious though, because that's basically never the recommendation, even in a shell script or something where it's much easier people do "getent passwd" calls.
Curious if anyone looked at Open Policy Agent (OPA) as an AuthZ microservice to be containerized along side the application? I'm unpacking this a bit now but curious the communities perspectives. [https://www.openpolicyagent.org](https://www.openpolicyagent.org) / [https://github.com/open-policy-agent/opa](https://github.com/open-policy-agent/opa) / 
"Dear developers can you please put a warning on your new feature telling everybody not to use it." ... seems like a non-positive start to a conversation.
I was skeptical at first because tests are very accessible in Go so they tend to be common. But then I saw that it doesn't actually hide the test files, just places them visually next to files with same name. And I like it. It's unfortunate that the title of this post might give the wrong first impression.
Yes, I experienced a missunderstanding already :D
A fully configure neovim requires someone yo know all the correct plugins and then to configure them. Goland just needs to be downloaded and it's ready out of the box. 
Set [Request.RemoteAddr](https://godoc.org/net/http#Request.RemoteAddr) [before calling the handler](https://github.com/v33ps/http-buddy/blob/02710de874e2a4d4f5bab288636a2384684225a8/src/packetDataReqs_test.go#L17). 
Hi! That command is usually called `tree` in linux/unix. So I googled for "golang tree command" and found this simple code: https://github.com/malicote/go-tree I hope it helps
Thank you! 
[removed]
I love you, just updated caddy on my prod servers
I mean there was a thread yesterday with the official communication. Who cares about some blog that rehashes what's been said in there?
I've been working with the AWS SDK for the past couple of weeks - I did try to mock out bits of the AWS SDK, but it was taking too much time for me at the time. I ended up just deploying a test version of my Lambda and hitting that via an API Gateway HTTP endpoint, using an API key to secure it. Adding the API key requires also adding a usage plan, that was something I fell into when i was trying to set it up. This looked like a promising way to start with testing it with unit/integration tests: https://stackoverflow.com/questions/54285068/how-to-mock-request-request-in-golang - In my case I haven't had a lot of time so I haven't dived into this in much detail yet.
I've released the editorconfig-checker 1.0.1 which should be the core for many languages which are only acting as a wrapper to provide a stable API and feature set across languages.
Sorry for the lengthy reply but I tried to breakdown various parts of the IDE and allow you and others to see the fields they might be interested in and skip the others. I also included references links to much more comprehensive articles on these topics. GoLand comes out of the box ready to be used for Go development, with no configuration needed to activate various parts of the functionality it offers. This is true for both standard Go projects using GOPATH or the new Go Modules, since Go 1.11, with all the functionality working the same regardless of the project type. To my knowledge, the state of tooling around Go Modules is broken to various degrees, but I'm happy to correct this if it's incorrect. It performs very well in common tasks such as [code completion](https://blog.jetbrains.com/go/2019/01/17/code-completion-in-goland/), finding usages of symbols or renaming them, and its performance is noticeable even with very large project sizes/GOPATH. Of course, the downside for this is the need to perform the one-time indexing operation of the project/GOPATH. You can read more about the [indexing process](https://blog.jetbrains.com/go/2018/09/11/goland-internals-1-indices/) if you want to. Thanks to the indexing process we can also do on-the-fly analysis of the source code so that our users can avoid having to save files to get feedback about the code issues. And this enables inspections such as the [Nilness analysis](https://blog.jetbrains.com/go/2019/02/15/goland-2019-1-eap-4/#nillness_analyzer) to work as the code is written. In the refactoring section, GoLand offers different options from the [Rename refactoring](https://blog.jetbrains.com/go/2018/12/07/refactorings-in-goland-rename-refactoring/), [Move refactoring](https://blog.jetbrains.com/go/2018/11/30/refactorings-in-goland-move-refactoring/), [Extract and Inline](https://blog.jetbrains.com/go/2018/10/26/refactorings-in-goland-extract-and-inline/), to [Change Signature](https://blog.jetbrains.com/go/2018/10/19/refactorings-change-signature/) or [Extract Interface](https://blog.jetbrains.com/go/2019/02/04/goland-2019-1-eap-2-is-here/#extract_interface_refactoring) The debugger also has quality of life tweaks, such as [Smart Step Into](https://blog.jetbrains.com/go/2019/02/21/debugging-in-goland-improvements-in-2019-1/), the ability to see goroutines or threads for the debugged target, [a lot of breakpoint options](https://blog.jetbrains.com/go/2019/02/14/debugging-with-goland-essentials/#working-with-breakpoints), and more. As it's mentioned in the link above, we now support out-of-the-box profiling with pprof, for now for CPU profiles only, rather than having to use different tools to get these results. And thanks to the IntelliJ IDEA Platform, we get to have all the Web related features from [WebStorm](https://www.jetbrains.com/webstorm/), and all the database related features from [DataGrip](https://www.jetbrains.com/datagrip/). We also try to give everyone, be it customer or not, a great support experience. As always, you can take this with a grain of salt since I'm working for JetBrains. However, the best way to see if what I'm saying is applicable for your development needs or not it's just to try it and see if it fits your needs or not. We look forward to your feedback.
Not only main, but factories are also able to (and often do) make use of a container or injector, but this is a side-point. Thanks for the clarification.
Will be adding this to our honeypot network! Thank you!
Thats a nice post about the feature how to hide designated test files 
I have NeoViM configured already, so no reconfiguration is needed. But switching to Golang requires both time and money, so if there are no advantages, I see no reason to switch.
Thank you for the informative answer! Since I'm already happy with the code completion, indexing, refactoring, renaming etc in NeoViM, I think the main argument for me to switch over to Goland would be if the debugging experience was significantly better. And I suspect that it is.
If it was me the first thing I'd do is properly document all of the exposed funcs/types, rather than just keeping vet quiet. &amp;#x200B; That process should help you understand a little more about which pieces belong together and help extract useful packages. &amp;#x200B; But really, don't sweat it too much, refactor as you go. I see nothing particularly bad about the way it's split up currently, just think like a user of the core gravity library, how would you like to use it? Which parts are essential and which parts are really a separate library (that's your pkg/ packages). &amp;#x200B; There are several game/graphics engines such as azul3d that might be a good starting point for package layout. 
Can you give an example?
By anonymous switch you mean a « switch true » ? I would say use the one you prefer, readability is one (if not THE) most important part in programming. I’m pretty sure a list of « if else if else » compiles to the same code as a « switch true » anyway (to be verified)
A rewrite of `date`, with less features?
Of course, you can see it like this, but have you read the readme, especially the **Why?** :)
Must suck to have to deal with MacOS, glad I don't. 
"rewrite it in rust" 
You can use switch{ case a == foo: case a == bar: } I think if is clearer. Sorry using mobile. 
Sure switch { case a: // do something case b: // do something case c: // do something default: // do something } Or.... if a { // do something else if b { // do something else if c { // do something else { // do something }
Sorry for noob question. What is that?
My rule at least is if you need more than one `else if` to build your logic you better use a switch-case.
Do not stick your fingers in there, it's a trap "A **honeypot** is a decoy computer system for trapping hackers or tracking unconventional or new hacking methods. **Honeypots** are designed to purposely engage and deceive hackers and identify malicious activities performed over the **Internet**. Multiple**honeypots** can be set on a **network** to form a honeynet."
No, nginx is trivial to configure if you know how http works.
Sorry, but what is your honeypot network? Is it possible to explore it somewhere?
I assume you meant 1.1.0 and not 1.0.1
Correct :)
It's just a small network of vulnerable devices, workstations and servers that we expose to the open internet to try and gather threat intelligence from through monitoring attackers who exploit it. It's more of an internal company project atm so not really possible to explore but if you're interested it's really not hard to setup. Just be sure to completely segregate it from your network! Use cloud hosting or external provider ideally.
In general case, I give my code a thorough look every time I end up with &gt;1 Ifs. But if checking multiple conditions cannot be changed to something more elegant, I would say golang's switch{} is much more readable.
I tend to favour using switch case if the readability with if else looks poor. That said, the moment I have more than 3 case lines, I start to seriously consider a different design. Sometimes, based on the domain, a multiple case is the clearest. Most times, a better design becomes the right approach.
Do you by any change happen to have noteworthy resources as to how the more elegant solutions can be achieved generally? I have some trouble grasping the concept of elegance in programming context.
Hey, do you know the estimated date for that?
I'll use switch if there is a clear progression in the conditions. Like, case x &lt; 10, case x &lt; 20, case x &lt; 30... I consider the reader's cognitive load to be low if all the conditions match a pattern. If the conditions are complex enough, I instead try to find a way to refactor so there aren't as many conditions in one spot. 
My rule of thumb is more than one `else if`, should use a switch. Bonus points, switch is ever so slightly faster than elifs, the sweet spot seems to be around 4-5 cases. 
Can you link a source or explain why it’s faster, as that’s quite interesting
Some will argue that it's about readability, but I think it's more of a gut feel.
I typically stick with `if`-`else` instead of `switch` because you can't `break` out of the latter. But one place where I definitely prefer `switch` is code like the following: ``` func isNonsense(s string) bool { switch s { case "foo", "bar", "baz": return true default: return false } } ```
Switch is only faster if it can create a jump table. See https://en.wikipedia.org/wiki/Branch_table
I think you mean that breaking out of a switch is slightly more difficult; you can do it, but you need to have labeled the loop you want to break out of.
nice. i think date works fine though. it is a simple matter to convert nanoseconds to seconds on the command line with either string manipulation or arithmetic. it is a nice exercise though.
[removed]
Sure, it's possible. But it's easy to forget and it clutters the code.
Could you define an interface that conforms to the parts of the SDK that you use and mock those out? May be a lot of work though...
Thanks for the feedback. Yes, converting nanoseconds to seconds isn't that problematic. But I do also have to deal with nanosecond precision and the usual solutions I found weren't too appealing in my opinion. So, this tool was very handy for me (also the parsing from formatted strings to timestamps), but it's probably too much of a niche ;-)
Just counting (`ack else|wc` `ack switch|wc`), i tend to use more and more switch ! I'm fan of switch...
Micro is a small text editor...
That's a different project. This predates the editor.
/u/dlsniper \- My company just bought me the "IntelliJ IDEA Ultimate" license - but it doesn't seem to include Goland. &amp;#x200B; Is that right?
instead of directly accessing `r.RemoteAddr`, you could write a function (say matching a signature `func resolveIP(r *http.Request) string`) that resolves it. In tests, pass a mock that returns whichever value you'd like to test. Otherwise simply pass as implementation that returns r.RemoteAddr
why do you think you need microservices? start with a monolith and break it up if/when it makes sense.
IntelliJ IDEA Ultimate has a plugin for Go, named "Go", with the same functionality as GoLand. This is not bundled by default and you need to install it. As long as you will keep your IDE updated, it will feature the latest features from GoLand releases as well. Hope it helps.
Microservices are usually a symptom of premature optimization. What you're describing isn't really microservices, it's just services. 
Generally I'm curious and I want to learn how to build them so I can learn where and why would I need them.
In my latest project, there are a number of services that communicate by NATS. Works great! Doesn't sound like you need to break your project into microservices, though.
understood. introducing microservices when the complexity isn't warranted isn't necessarily a great idea. i'd focus on plain old SOA. 
I feel like most people misunderstand microservices. Most anything one person can write alone is a microservice. Unless you're on a big team, you don't need to worry about what defines a microservice. Just write a service. Start from http.Server's [ListenAndServe](https://golang.org/pkg/net/http/#Server.ListenAndServe) (or the same kind of thing for a non-http service) and then just write your code. You don't need to worry about finding a microservice framework. Just write some code. If you need to refactor later, you can, but most likely you won't need to. 
Simple and easy are two entirely different words with entirely different meanings.
https://azure.microsoft.com/en-us/blog/design-patterns-for-microservices/ How it helps, microservice are not bind to a programming language
Yeah, having tags is a major code sniff for me. It's more readable to set up a break variable that is checked after the switch statement.
This seems useful, thanks!
- How do you build your microservices and what role they play? Just start with the basics like HTTP request routing. The [go-chi/chi](https://github.com/go-chi/chi) is an excellent package for that, and they have some middleware to help you along (like JWT,...). - I'm wondering where should my logic start? I'd start by documenting the API you want to have. People use either Swagger (OpenAPI 2.0?) or Apiary blueprints to do that. It may be just a simple list of API endpoints, their parameters and the expected response (optional). Here's a lightweight example: [crusttech/crust/docs](https://github.com/crusttech/crust/tree/master/docs/system). - Well how does your starting point looks like? I'd start with a subset of the [golang-standards/project-layout](https://github.com/golang-standards/project-layout). Effectively, I always have a `cmd/` and possibly `internal/`, and after that it just depends on how you want to structure your http routing, service layer and repository layer (I generally deviate here towards `/[name]/(service,repository,rest,websocket,types)` but this might as well be inside `internal`). - Do you hardcode your microservices or do you use library, and if so why is that? The question is a bit vague, but generally at least a routing library is used. While you can do routing with stdlib only, I prefer grabbing chi and using that to support things like HTTP verbs and virtual hosts without working around the stdlib too much. You could, but... should you? - What are the essential things I need to know when it comes to building microservices, I know that it all begins with Http routing but I don't seem to understand how to circle up the logic. The general rule of thumb is that you either have a front-end application (vue.js or something) that talks to all of these microservices. Of course, it may also be a microservice itself, but that leads to some sort of coupling. Coupling is generally motivation why people are moving to microservices, so that it may be avoided. As was said below, start with a monolith but keep individual responsibilities separate (authentications, blog entries, comments) and then you break it up if it makes sense. - What am I missing? It all depends on you. Building microservices isn't hard, usually people just struggle how to connect them or scale them or even just deploy them. Don't forget logging and monitoring. Things like database migrations might complicate your life a bit (assuming some common package for permissions across all microservices), or version control of all microservices deployed together. Most of the problems with microservices are more on the operations side imho (not so much development). Good luck :)
I think errcheck or even the built in go vet also reports this as a code smell. So you're not the only one ;)
Yeah, I try not to use labels. For my part, I usually factor out a helper function or closure so I can use return.
Ah ok, that's good. So I wont miss out on anything by not using the dedicated GoLand IDE? Thanks for responding :-)
&gt; I consider the reader's cognitive load This is a great answer. General rules aren't very useful when they lead to code that's harder to read or maintain.
Thank you soooo much for the detailed explanation! This will help me alot going through the process and it seems like a fun path to walk. Can't wait to wrap my head around these things and you sir will be responsible for that :) Thank you again!
&gt; Coupling is generally motivation why people are moving to microservices That's one motivation, but it can't be the only motivation, as there's added complexity in developing and deploying a microservice-based application (in comparison to a monolith). Where microservice architecture provides its greatest benefit is when many teams are working on the same product. Each team can develop and deploy its own service at its own cadence without affecting the progress of others.
\&gt; honeynet &amp;#x200B; A net made o honey sounds amazing.
Any benchmark comparisons with https://github.com/linkedin/goavro ?
Can I cross-compile the app from linux? 
As a minor UI thing, instead of: foo -unit us 1548449513940562 ...I think it's much better to allow the user to do: foo 1548449513940562us 
What is the avro protocol? What does someone typically use this for?
I had just started doing that and very very soon I realised I had written 250 lines of code for just the lambda SDK...
Someone has also given me some interesting advice in a StackOverflow [comment](https://stackoverflow.com/questions/54872392/mocking-the-aws-sdk-in-golang?noredirect=1#comment96531205_54872392). I intend to follow both leads you guys have given and I will come back with the results. Maybe others can benefit too.
Um do what you want if you are interested I'd say. To do a restful server https://gitlab.com/zendrulat123/bill (The naming is bad) The custom middle ware so it doesn't get in the way of your API. More of just using the go packages then being a package. https://gitlab.com/zendrulat123/prettymiddleware/wikis/home This way you have a full mental model of your project. You are not just installing crap. If you need more resources. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk 
[removed]
[removed]
I'll be interested to see where you go with it!
Others: - https://github.com/actgardner/gogen-avro - https://github.com/elodina/go-avro (last I looked, marshaled with reflect, was slow) - https://github.com/icexin/avro (reflection) - https://github.com/linkedin/goavro (forces their Record type on you, field access with getter functions that take field name as string)
Okay so this seems to use a helper library https://github.com/modern-go/reflect2 that does some very ugly and dangerous looking things, accessing the runtime directly and not through supported APIs. https://github.com/modern-go/reflect2/blob/94122c33edd36123c84d5368cfb2b69df93a0ec8/go_above_19.go#L9-L10 https://github.com/modern-go/reflect2/search?q=go%3Alinkname&amp;unscoped_q=go%3Alinkname 
I personally like to have multiple domain packages. So you end up with a package per bounded context each with their own types. Sometimes there are types in both packages, that look a little different but represent the same thing. The downside to this approach is that there is may be more boilerplate code to convert domain types from one package to another.
It's a common choice for transport encoding in Apache Kafka. See http://avro.apache.org/docs/current/. At the bottom, the comparisons with Thrift and Protobufs are useful, if you're more familiar with those. Conceptually, it's somewhere in between thrift/proto and JSON.
Short answer, no, you won't miss anything.
I can see that working; how would you place services that would need to interact with multiple domains? If I for example had a `users` package that acts as the root for my user domain and a `blog` package that acts as a root for my blog post domain, how would you implement a service that lists blog posts with their author information? &amp;#x200B; It could perhaps be a third bounded context (`blogquery`?) but it feels like it's going to get hard to get a feel for the code base by just glancing at the tree of files eventually. One of the good things about the Standard Package Layout, to me, is the how the structure screams - I can glance at the root of my project repository and clearly see it's an app that manages blog posts and users, that it uses PostgreSQL and Redis, and provides a HTTP interface, just by doing a `ls` in the root directory.
Awesome. Thanks for clarifying!
Compiler will create a hashmap of the switch in some cases. https://hashrocket.com/blog/posts/switch-vs-map-which-is-the-better-way-to-branch-in-go goes deep into this behavior.
Avro is a binary encoding schema used for transmitting data where faster speed and smaller payload size are needed vs json, xml or other readable encodings. It is also a self-describing schema making it a bit more flexible to work with than protobufs.
[removed]
There's not really anything specific to Go in here. It takes a stab at making an issue of Go's static linking, but the GPL authors' view is that there is no difference between static and dynamic linking, both should be GPL-only. I think this whole post could be reduced to "Libraries with licenses that allow you to do whatever you want with them are best because you can do whatever you want with them."
Thanks for the feedback. Maybe I'm going to add this :)
[removed]
Probably a security issue. Or maybe generics.
&gt; the GPL authors' view is that there is no difference between static and dynamic linking anyway, both should be GPL-only. That is surprising to me. Under that interpretation, I could get the source code to almost any proprietary software I want - by simply loading a GPL'ed libc into it. Even if the vendor originally linked their own proprietary libc. I could see how it wouldn't make a difference *if you distributed both together*. But that would be pretty unusual in an ecosystem using dynamic linking, where you usually expect dynamically loaded libraries to be pre-installed (e.g. by the package manager). AIUI the act of *combining* GPL and non-GPL code is fine, it's the binary distribution of the combination that's a problem (which is why proprietary kernel modules require the kernel sources to be installed - to do the actual linking on the client machines). So, AIUI, it should still make a difference. In that you can't distribute both separately, if the binary is statically linked.
It lets the caller reuse the same byte slice preventing unnecessary allocations. It’s also easier for the escape analysis to stack allocate it.
As icholy notes, it's basically to minimize allocations, which is a proxy for better performance.
switches allow the compiler to optimize it into a jump table. I’m not sure if the Go compiler does this though. Either way, use whatever approach makes for cleaner code. Worry about performance after you’ve identified it as a bottleneck.
Are you using modules?
Delete your install and re install. The documentation says you need to remove the prior install. I ran into this when upgrading yesterday. A bunch of things moved around in the packages. 
yeah, and /u/DeusOtiosus going to delete my directory and try again thanks.
Interesting, the [project goal](https://github.com/d1str0/Drupot/blob/master/routes.go#L136) led me to https://github.com/rep/hpfeeds which looks like a federated(?) pub/sub for finding honeypot information? https://heipei.io/2013/05/11/Using-hpfriends-the-social-data-sharing-platform/
[removed]
[removed]
In most cases returning a \[\]byte would be a more desirable outcome. But in many cases it would not be.
Others have already said it, but I'll also explain it. If Read returned a byte slice, it'd have to allocate a new slice every time. This could be very expensive. Allocations are among the most performance damaging operations. So, taking a slice instead of returning it enables the user of Read to reuse the same slice over and over again with no allocations. There's also one more benefit. The length of the slice allows the caller to specify the maximum number of bytes to be read. If Read returned a slice instead, it'd either have to return an arbitrarily sized slice, or the maximum size would have to be specified in an extra argument to Read.
Looks like a cast to the type *ActivityService, as if you had type MyInt int var i MyInt = 5 var realInt int = int(i)
I wonder if the issue number has any meaning? 30411 Doesn't look like it at first glance.
Interesting read. I would have assumed compiled code would be much faster.
As a counter point, go 1.11 changes to domain record compression handling broke me and kube-dns. Go elected to break backwards compat to stick to the spec. Not necessarily a bad thing...
I'm really glad that Go has anonymous switches, but if I have to use one I shudder a bit - great for that first "make it work" pass, but something to be refactored out in the "make it pretty" pass. Same with if else's - great that I can do it, but it's a flag that I need to think about this code more. If I really had to do this, then I would break the logic into two parts: first, make all the decisions and branching logic, and declare a variable with a "this is the thing we need to do" flag second, make a (non-anonymous) switch to do the actual thing example: const ( doThingA = iota doThingB doThingC ) var whatToDo int if someComplexLogic() &amp;&amp; !someOtherStuff() { whatToDo = doThingA } else if edgeCase() || trickyCornerCase() { whatToDo = doThingB } else { whatToDo = doThingC } switch whatToDo { case doThingA: doThatThingA() case doThingB: doOtherThing() case doThingC: //whatever default: //fall-through case return errors.New("couldn't decide what to do") } Then, of course, I would separate them into two different functions. The advantage of this is that the decision-making is clear, and not all twisted up in the action code. The decision reached by the logic is obvious, and which action needs to be taken is obvious. Best of all, though: I can write tests against the complex logic code without triggering the actions (and vice versa - test the actions without needing to set up complex logic for the decision tree). 
I get it. Learning something by building it :) I would start with the authentications service. Send it a copy of the login request, it returns the user ID of the user, the session ID of the session, or an "invalid login attempt" error. I would use protobuf to define and generate the interfaces. There's a wide range of choices for messaging protocol, so that's a more complex case. Something like RabbitMQ is fun to play with, maybe start there. Remember that one of the huge pain points with microservices is the asynchronous communication. What will your system do if the messaging protocol dies halfway through processing a login? What will your webserver do if the login service takes an unreasonable time to process the login? Do you keep requests open and wait for a reply? Do you convert the request to a websocket? Do you get the client to poll the server for a response? Fun :) enjoy :) 
I never noticed the "up to len(p)" part of that before. I need to be more careful about allocating the slices for my readers - I always assumed the Reader would reallocate as needed.
Good advice thank you! I will try this approach definitely
Might violate copyright law or if they have an open source license that requires you to follow certain rules
The nice thing about passing a byte slice -- in addition to re-using the buffer -- is that you communicate how many bytes to read. Otherwise you'd have to do something like: ``` Read(nbytes int) ([]byte, err) ``` 
Whether or not it's ethical solely depends on their license. And including their code as a dependency does not change anything as far as ethics are concerned.
copy and change all the variable names :)
The license determines whether it's legal or not, ethics are another matter entirely.
That does not seem to be the case. The first release of the micro text editor was in 2016 and the first release of this project was in 2017.
Sure. However, this is a matter of how [u/Gentleman-Tech](https://www.reddit.com/user/Gentleman-Tech) uses some one else's code. Those licenses dictate how the author wants their code to be handled. Following those licenses is following those author's wishes. I think everyone can agree that is ethical.
I have a small project Ive started that somewhat follows a DDD architecture. [https://github.com/longfellowone/field-services](https://github.com/longfellowone/field-services)
There's an interface that exists for that already though, I believe most (if not all) services define one: https://docs.aws.amazon.com/sdk-for-go/api/service/lambda/lambdaiface/ 
Gorilla sessions merely sign a package that gets sent to the client in the form of a cookie. They then hand it back on each request that you decode. It means you cannot invalidate sessions or log out users. It’s open to reply attacks. And I don’t know if it has been vetted against various timing or oracle attacks. I would be super cautious about using any session store that depends on the user too much. The gold standard for sessions is to send a opaque, random string as an identifier to the user, then store the actual session data in a database and just do a lookup. Since sessions are ephemeral, you usually store them in memache or redis. 
So I must not use Gorilla sessions? And by "sending string to user", you mean I write it in the header and let it persist for all further transactions? &amp;#x200B;
Send it as a cookie, so they can send it back. And then tag it as secure only. You can use them, but understand the issues of using such an approach. 
I'll generally add a comment explaining where I got it from and attributing that way. And, of course, make sure I'm complying with the terms of the license. Ethics are subjective, but I don't personally feel obligated to include a third-party dependency as a way of attribution. I'd be uncomfortable taking other people's code and including it wholesale in mine without at least a comment identifying its original author/clarifying that I didn't come up with it.
Sure, thanks man! Cleared it out. 
Nice
Great info everyone. Thanks for the insight!
What does that number refer to?
yeah, I might not be paying any attention to the license here. I justify it to myself that I'm just copying their method, really, not their entire code. The copy/paste is a mechanism for ensuring I get their method right ;)
This is the bit I'm unsure about. I'm not paying any attention to licence, because my intention is not to use their code. I just want their solution to the problem (which is method, and therefore not copyrightable. Patentable, yes, copyrightable, no). Legally it's a quagmire, because I am adapting and changing their code for my purposes, so that might count as a "significant adaptation". I'm not that bothered about the legalities. I am bothered about the ethics. If someone put a GNU licence on their code, and then I adapt it for my purposes in my closed-source code base, am I a bad person?
yes.
Since a new slice is not returned it cannot reallocate. One of the traps is that we teach a lot of noobs that a slice is like a "reference type" in that when you pass it as an arguments others can modify it. This is not true, slices are still copied when passed to another function but it's only the slide header that is copied and not the underlying backing array. So the array's contents can be modified but the slice header cannot. In the header is the length and capacity of the slice. So without returned back a new slice \`Read\` can never allocate more memory for the backing array. This is why the builtin \`append\` feels funny. It takes the slice as an argument and also returns a new slice \`\`\` var s \[\]int s := append(s, 1) \`\`\` If there is space in the original allocation append just returns the same slice back. Nothing changed. If append need to allocate more space it creates a new backing array (usually doubling the size), copies the contents of original array to the new one, appends the items, and then returns a brand new slice header. TL;DR; maps and slices are still passed into called function as copies but only the headers get copied and the headers have a pointer to the storage so it "feels" like a reference.
Relevant tech blog post: [https://engineering.shopify.com/blogs/engineering/deconstructing-monolith-designing-software-maximizes-developer-productivity](https://engineering.shopify.com/blogs/engineering/deconstructing-monolith-designing-software-maximizes-developer-productivity)
Th Micro repo was posted here in /r/golang back on January 3rd, 2016. [Source](https://www.reddit.com/r/golang/comments/3z9uir/a_microservice_toolkit/). Initial commit for the editor was March 10, 2016. [Source](https://github.com/zyedidia/micro/commit/24ce1d6b42262a08d2ba1ad9a2b28d2087f90e0a)
&gt; I always assumed the Reader would reallocate as needed. It can't because it doesn't take a pointer to a slice it just takes the slice. Allocating a new array changes the slice.
I really like Noms. Unfortunately it looks abandoned right now. We have use cases for this where I work, but it's hard to advocate for it when the project is stale.
Given that the lone maintainer is "scaling back", I would say you're right
Last commit is about three weeks ago, doesn't seem abandoned.
I don’t think there’s a hard and fast rule you can apply here. With that as my caveat, I would say that the blog context should have a view (read: type) of User that is minimally necessary to (1) perform the tasks needed within the blog context (2) connect the actions of this user to the identity defined in the User context. The User context, in my mind, is a source of identity (a uuid, and contact information). The blog context should never store this information, but it might interface with the user context to obtain and mutate this information with some API as an intermediary. In this world, the user and blog applications/packages persist data in separate Schemas. That’s what bounded contexts mean to me, in any case. Would this be a happy middle ground for you? I’d love to hear arguments against this model.
well that clears that up ;)
I get it, I just hadn't read the documentation thoroughly enough ;)
If I correctly understood what you are trying to do - your initial design is correct, your suggested interface will be unnecessary complication. There is nothing wrong in having broker reference inside a client unless its internals are properly isolated from client. To isolate broker - either move it to separate package and make only Broadcast/Register/Unregister methods exported (if broker functionality going to grow in future) or use function closures for methods that will be used in client.
https://github.com/attic-labs/noms/issues/3812 Also, PRs dating 2 years back, pulse not looking good. Not actively developed.
How is this different to centrifuge?
I was expecting a different logo than this for you project https://raw.githubusercontent.com/Clivern/Beaver/master/assets/img/logo.png
You are only wrong if you are using this code for anything other than personal projects that you will never release to the public. If you are releasing these projects to the public, the ethics behind it solely depend on the license of the code you are pulling from. The license of the code shows how the creator intends for their code to be used. If you go against these intentions, you are going against the creator of the code. You might not actually be going against these license, but by not even checking them shows serve negligence on your part. Most authors simply want an acknowledgement for their work, which is not hard to do. You not even caring to see what their licenses say is just disrespectful. &gt; A friend suggested that I'm not crediting the original author and that I should include the dependency instead, because they get credit then. It doesn't matter if you use the whole dependency or just parts of the code. If you did not write it, the code should be handled in the way that the licensor intends for it to be. Using part of the code does not get around this. &gt; I'm happy to include a "I copied this from github/someone/project" comment (and often do, so I know where I got it from), but I rarely open-source my code, so no-one is going to read it and it seems a bit pointless. It doesn't matter what you do with it. If you turn in someone else's homework, you are cheating. I'm really hoping you don't do this for work. If you do, you are possibly opening your employer up to a lot of legal issues.
Yes, decoding is around 2x-3x faster. Will add them to the readme today.
There are other implementations of the [Store](http://www.gorillatoolkit.org/pkg/sessions#Store) interface, like the built-in [FilesystemStore](http://www.gorillatoolkit.org/pkg/sessions#FilesystemStore), which I believe use the gold standard you describe. I've used https://github.com/boj/redistore successfully on a small project too for a shared cache.
Ah ok. That’s good even if it’s not scalable. Redis is a great way. I didn’t look too deep into gorilla, I just saw that it was using a cookie store before and noped out of there. 
reflect2 is just reflection without the "value" part. Under the hood it is no different to the provided reflect package. The value part of reflection is quiet slow. As you dont have the value part of reflection (for setting and getting) I use unsafe pointers, which is the same method used in protobuf.
A few lines here and there probably is not a problem. But if it's more, I'd check the license.
Does this have faster Rename than the default gorename tool? The fix at [github.com/amitbet/gorename](https://github.com/amitbet/gorename) is no longer working for me. :(
Sounds like old php all over again.
How is this different to [Nakama](https://github.com/heroiclabs/nakama)? ^(Im one of the devs who works on Nakama.)
You would have similar experience when going from javascript to C++ too. I mean I'm not sure what's the argument here. Go has no chance competing in the niche of C / C++ / Rust due to it being too slow and having a fat runtime. But generally good enough for a lot of tasks.
It looks like it is gin webapi on top of gorilla web socket that is fine but two questions. Why auth is limited to entry in confit rather than give an option to be set / selected or provided with your own function in config. There should be few authentication strategies otherwise it is just a single api key for whole setup. It is as performing as redis. How would you approach scaling it ? 
Legally, it's down to the license. Ethically, different people will say different things. My opinion is that you're doing it wrong, and this behaviour is the opposite of some central open source ideals. You should include the dependency. The author has solved a problem which you couldn't, or chose not to, and then taken time and effort to make it available. If you include the dependency then everyone is happy. You get a solution and continue with your project, they get to know their project was useful. Every coder should be very wary of including unnecessary or low quality dependencies, but there are lots of positive effects of including heathy dependencies. Also you "copy/paste the complicated bits that are the core of their solution". This reads like you're taking the central purpose of someone else's library without even a thank you, which is a dick move. 
Spot on.
Looks interesting. How do merge conflicts work? :0
Copyright law varies by jurisdiction, but I think you'll find that your assertion that code is not covered by copyright is absolutely incorrect in most of them. Contradicting the terms of the license the code is provided under is also illegal, as well as being terribly poor form IMO.
Use the dependency. If it is more than a few lines, there will be bugs and they will eventually fix them. You'll get that for free with a clear dependency management. Also it's the best way to keep track of all the licenses in your code. If you're creating the software professionally and will publish it it's really the only right thing to do
Thanks for the support guys 
Maybe 30/4/11 is an important Go historic milestone? Not sure how that would make sense though. https://golang.org/doc/devel/pre_go1.html
In my hypothetical case, I'm building a blog; the `User` (which perhaps more correctly should be called `Author`) is just a minimal view representation of an identity that owns the `BlogPost`. The actual `User` domain would live outside the scope of this application. In that sense, maybe this entire application is just one bounded context; it's a `BlogPost` context and it has all the views needed to be able to enrich those entities with more data, like the name of the author, the category it belongs to and things like that. That still leaves the question of where non-domain-code that isn't tied to a particular dependency should live though. I'd like to keep my root package free of stuff that isn't purely domain code (as long as it makes sense to do so). Maybe my domain-model of the `BlogPost` doesn't contain any author-information (just an `AuthorID`) and the domain services only return `BlogPost` models with only reference identifiers for related data. I'd then want a separate service that can return enriched `BlogPost`s where things like `Author` and `Category` are added to the return type. This information could come from different sources, such as PostgreSQL for categories and the Facebook API for the author information. I feel like logic like this belongs in separate `psql` and `facebook` packages, which is fine, but that would also indicate that I should define the service interfaces and return types in the root package. This brings me back to the original problem having `BlogPost`, `EnrichedBlogPost` and possibly also other types in the root package - only some of which are actually related to the business logic/domain of the application.
I'm not opposed to my `BlogPostService` *knowing* about `Users`, it's more of a "my domain only really cares about the `BlogPost` having an `UserID`". All the business logic and domain rules only work on these reference identifiers; maybe I don't want to have any `User` concept in the domain at all, just an `AuthorID` field on the `BlogPost` that is a `type AuthorID string` \- anything more than that is sort of outside the scope of the application domain. The problem then arises when certain clients want to do a query against my application to get my domain data - but they also want to expand those references to avoid having to query elsewhere for them; as mentioned I could just have a response type in my HTTP handlers that has more data on the author and look it up before returning the response (let's say it's fetched from another application entirely via HTTP), but I feel like I'd be violating the single responsibility principle by doing so as the HTTP handler suddenly has to do a lot more work than just interact with my domain via my domain services. Also as soon as I expose this data via other mechanics as well (for example a GCPR service) that logic needs to be duplicated or extracted into it's own service that handles the responsibility of enriching my response data. That said, I'm really not opposed to any solutions proposed here - this problem doesn't neccessarily have a One True Solution. I just have this feeling when stuffing this kind of additional logic and behavior into my root package, that I'm doing something wrong - and while everything else has a well defined place, these things sort of fall a bit on the side.
The error message is unrelated to that package. Looks like your go stdlib is wonky. 
Centrifug**o**, to be more exact – [https://github.com/centrifugal/centrifugo](https://github.com/centrifugal/centrifugo). Centrifug**e** ([https://github.com/centrifugal/centrifuge](https://github.com/centrifugal/centrifuge)) is a library Centrifug**o** built on top of. Yeah, I know how easy to mix it up :( 
First thing I noticed is you generally won't want to use if else statements and just use ifs when handling errors. if err != nil { do thing return } // Carry on with logic.
Thanks captain! Will file a refactor ticket for reducing if complexities :D
This looks to roughly be the same as I'm working on, thanks for sharing. I see you've solved this by having a package per feature you're providing where you provide a service interface and some input/output types. In my case, I could have a `query` or `search` package that uses my domain services underneath (the `BlogPostService`, for instance) - and perhaps also depend on some other code to query for the additional data I want to enrich my response types with. I am, however, a bit weary of creating subpackages under my root package that depends on other subpackages. I feel like dependencies should only ever be "upwards" in the source tree, not downwards or into sibling packages. How do you feel that's working out for you? Say for example your `search.Service` needed the `order.Service` in order to get some additional information while preparing a response. Then, in turn, the `order.Service` needed the `search.Service` in order to provide some of it's data (i know this is a very crappy hypothetical which doesn't make sense in your domain but let's assume). You could solve this by defining the interfaces you need as input in your search and order service initializers within the packages that consume them, but you'd still have fairly messy and non-intuitive set of dependencies within your code base. Thoughs?
Thanks! Challenge accepted :D Not so hard, I'm using a lib that do that already :) 
You can group constants like this: `` const ( followVerb string = "follow" postVerb string = "post" activityActorRequiredMessage = "Actor is required." activityVerbRequiredMessage = "Verb is required." activityObjectRequiredMessage = "Object is required for this verb." activityTargetRequiredMessage = "Target is required for this verb." emptyString = "" ) `` You project layout kind reassemble like you are coming PHP background. Go peeps like to stick and in general std libs name params and variables as a one letter so `input = i` or `activity = a` You should use gomod as package manager 
code is absolutely copyrightable. Methods are not. Methods are, however, patentable. And my point is not that I'm copy/pasting code blindly into my codebase from someone else's... it's that I'm copying their methods, which may involve copying their code and then adapting it to my needs.
Thanks captain! &amp;#x200B; What are the advantages of using gomod package manager? I'm really curious here sir. Definitely agree with the constant groupings. Actually, I'm from C#, Java and NodeJS background (No knowledge of PHP at all sir).
That's not how that works - you can't just take someone's code and modify it then claim you haven't copied it. The only way to implement a method in this fashion is to have someone produce it in a completely clean environment with no reference or access to the original code.
including the dependency also means I have to include any other code they felt needed to be in the package. I often find that I can drop 90% of the code in the package and still solve the particular problem that I have. I would also need to audit all of their code to make sure it doesn't introduce any security issues, and repeat that audit every time they updated the package. Way, way more effort and pain than just copying (and then adapting) the bit of code that I need.
Gomod is official package manager for go. More about that (here)[https://github.com/golang/go/wiki/Modules]. Regarding your Java background, PHP and Java are kind similar in this project structures, so it looks familiar also i added one edit. Hope you gonna pass exam
&gt;Regarding your Java background, PHP and Java are kind similar in this project structures, so it looks familiar also i added one edit. Thanks for responding sir, will definitely give gomod a look (Seems legit and worth it) :D 
U on break?
Yes, generally it is much faster for all the specific operations. However sometimes it gets confused when files get added or disappear from a git pull, so just `killall -9 bingo`.
Yea it feels fairly beta-level. I’ve only started using it and I’m not migrating my production code to it yet. I suppose I’ll make a branch and test it soon but for now, I’m waiting for the issues to get shaken out. It’s still early days. Most packages don’t support it yet, but once they do, I figure a lot of issues will get resolved. Until then, gopath4lyfe. 
it uses the postgresql fsync-and-forget method to resolve :|
https://github.com/attic-labs/noms/blob/master/doc/faq.md#how-does-noms-handle-conflicts
Regardless of license it is a matter of professional courtesy and academic practice to cite your sources. If you've lifted something from Github, then the Github repo in your [README.md](https://README.md) and code comments - if it comes from a webpage then link that in your code comments. It will help you too in the long run, when you come back to that code and know where it came from. Everyone benefits that way.
https://github.com/Lallassu/gizmo
https://github.com/Lallassu/gizmo
Source release, see comments above :)
Source release, see comments above :)
Here you are ☺️ https://github.com/tuarrep/sounddrop/releases/v0.2.0
Thank you! I'll definatelly research this.
Credit/license/law aside, it would be great to leave a comment about where did I copied the code from (project URL etc) so when bugs are found in this piece of code, I can trace back and fix then contribute back to the project I copied from. That's what I do when I copy code from other projects.
Not for golang specifically, but some Design Patterns generally are good alternatives to plain condition checks (like "Strategy" or "Command" pattern for instance). "Refactoring to Patterns" from J. Kerievsky seems to be a good resource to start with. Also, in some cases there are ways to get rid of conditional checks algorithmically (using bit flags for instance, where you can substitute conditions with bitwise operations). It worth mentioning though, there are cases where switch or mutliple if-else checks are your best options.
My understanding is that Go does not have casts. These are type conversions (https://tour.golang.org/basics/13), where the value is copied to the new equivalent type. I haven't really seen this pattern used like this before. Kinda neat. All those other equivalent types have different functionality sets, and they are converted from a pointer to the same data so it only gets allocated once, and they share it. 
Did you open dbconf.yml and update the connection url to your MySQL database?
How well versed does one need to be in Go to apply?
Try upgrading to go 1.12?
Looks interesting. Except the massive k9s logo that takes up a fist of pixels. I think if you remove that, make it perhaps just some tiny info text, somewhere, that doesnt steal a ton of space: it would get more attraction.
Not sure that really matters if it didn't get a release until a year later.
Diving in it looks like c.common is a service, defined as: \`\`\` type service struct { c \*Client } \`\`\` And then ActivityService is a new type defined like: &amp;#x200B; type ActivityService service &amp;#x200B; So it is quite valid to convert the service pointer into an ActivityService pointer. The new ActivityService type can then have further methods defined on it for performing different tasks. &amp;#x200B; I've not seen that pattern before either, not 100% sure it is very nice but it is clever.
 Hi, welcome and thank you for your feedback and thoughts. 1. Fork of the original openvpn3 source was required for small modifications and patches (issues on cross-compiling for win64 and so on), thin C library itself is new source code which reuses openvpn functionality - it so happened historically that it landed in forked openvpn3 source 2. CPFLAGS LDFLAGS were not options for the same reason - issues when cross-compiling with different compilers - somehow -lstdc++ didn’t always work with all compilers 3. I tried to avoid unsafe package usage for obvious reason because its “unsafe” :slightly\_smiling\_face: and it happened half a year ago. Now I probably do it with unsafe to avoid lots of coding - but will try to hide well those parts. All those decisions where more like a journey - fix a problem move on, we never actually came back to review solution and improve it drastically. We would be happy to assist with any other questions, you are welcome to join us in Telegram and can check out some of our documentation. [http://docs.mysterium.network/en/latest/](http://docs.mysterium.network/en/latest/) Telegram [https://t.me/mysterium\_network](https://t.me/mysterium_network) &amp;#x200B; &amp;#x200B;
I can (of course) only speak for the 2 projects I (co-)mentor: one has to be relatively familiar with Go. no need to be a ninja Gopher, but one has to know the basics of slices, maps, funcs and interfaces. GSoC is an opportunity to teach people about Open Source and coding (at least that's how I see it) so I do expect to spend some time with the student on how to best write code for our project (CI, coding (best?) practices, tests, commits, and so on.) (and for mentors, GSoC is an opportunity to learn how to teach and mentor.)
Personally, I absolutely hated that Go wanted my projects under the $GOPATH, so when modules freed me from $GOPATH, it just felt so good. I've only had one real issue with modules thus far: When we jumped from go 1.11.1 to 1.11.5, the mod sum for the same version of Echo changed. Resolving this required clearing the go mod cache, removing go.sum, rebuilding, and recommitting with the sum generated by 1.11.5, and the go.sum had to be fixed for each of our services. Echo was the only dependency we have that had this issue.
That's cool! Thanks for compiling the list
\&gt; Yea it feels fairly beta-level Yeah. Well of course. People should read the fine print/ &lt;&lt;&lt; Go 1.11 includes preliminary support for versioned modules as proposed [here](https://golang.org/design/24301-versioned-go). **Modules are an experimental opt-in feature in Go 1.11,** with the [plan](https://blog.golang.org/modules2019) of incorporating feedback and finalizing the feature for Go 1.13. Even though some details may change, future releases will support modules defined using Go 1.11 or 1.12.&gt;&gt;&gt;
I think the bulk of the problems are still because the ecosystem needs to adapt. It might be a bit of a painful process (I've also hit this golint issue today, solved it by excluding the failing version for now). I do prefer Go modules to dep though at this point. The CLI interface of dep never made any sense to me, but Go modules just continues to use the same Go commands we've been using for a long time. Dep was _really_ slow, Go modules have been far faster. After reading the all of rsc's posts, I also prefer the approach taken with Go modules in general. I do agree it's not stable yet, but we'll get there in time. I just wish we'd had Go modules at the beginning.
Thanks! I'll try it out! I can't take gorename's awful speed any longer. Refactoring instantly became a nightmare in VS Code for me. :(
By the way, what does `killall -9 bingo` do and how do I use it?
Saving this for later.
Well what about creating a server in go. There are many ways but creating one usually is one way. Is that copyrighted? What about handlers? Templating? Ect. I feel like in a language that tries to lower the amount of ways of doing things, this is gonna be a dead end. Maybe the community needs to stop with packages on GitHub and make wikis on how you built it. This way this crap doesn't happen and everyone can share
Same
To be fair, getting k8s.io/client-go to work with any dependency management has always been a massive PITA.
Indeed. I suppose the key to understanding interactions like this is to be fully aware about what an "interface value" is represented as: a tuple of `(value, type)` where `value` has type `type` and `type` is a concrete type (not an interface type).
You didn't ask for videos but this playlist from /u/campoy is excellent for learning idiomatic Go: https://www.youtube.com/playlist?list=PL64wiCrrxh4Jisi7OcCJIUpguV_f5jGnZ Sadly the playlist is reversed so if you want to watch it in chronological order you'll have to use a tool like this: http://www.playbackloop.com/playlists/PL64wiCrrxh4Jisi7OcCJIUpguV_f5jGnZ
Others have commented on their own experiences with modules, but I wanted to briefly hit on each of the specific issues you mentioned. &amp;#x200B; \&gt; Automated builds will occasionally fail to resolve modules ... So far, I think it has to do with the cache getting into a bad state sometimes &amp;#x200B; The module cache in Go 1.11 can sometimes cause various errors, including if there were network glitches or multiple go commands executing in parallel. Those module cache issues were addressed for Go 1.12. This is covered in the 1.12 release notes, or see #26794. If you see any problems with the module cache getting into a bad state in Go 1.12, I think that would be a significant finding and worthy of a filing an issue. &amp;#x200B; \&gt; Vendoring is opt-in now, which makes it sort of useless. I wish we had vendoring by default as we did before - it would fix a lot of the nondeterminism, especially in automated builds. &amp;#x200B; You are right that vendoring is opt-in in Go 1.11 and 1.12, but for the "it would fix a lot of the nondeterminism, especially in automated builds" piece, in an automated build you should be able do 'go build -mod=vendor' or 'setenv GOFLAGS=-mod=vendor' or similar to opt in more broadly during the automated build, which would mean you would be using your checked in 'vendor' directory in your automated builds, and that should eliminate any nondeterminism for your automated builds, I would think. &amp;#x200B; In Go 1.13, a 'vendor' directory very likely will be used by default. See here for discussion: \#30240 "cmd/go: automatic vendoring in module mode" [https://github.com/golang/go/issues/30240](https://github.com/golang/go/issues/30240) &amp;#x200B; \&gt; [k8s.io](https://k8s.io) client-go, etc. don't seem to work at all with go modules &amp;#x200B; I agree kubernetes is a problem area with modules. Part of the issue is the kubernetes repos don't always use VCS tags like 'v1.2.3' that are understood to be semver tags by the 'go' command. Another issue is the current k8s dependency management scheme has some atypical build approaches (currently including custom wrapper scripts on top of godep). Also, their repos are in the process of being broken apart and migrating, I think. For more details on some of those k8s changes, you could watch this recent excellent kubernetes talk by Kris Nova (but I won't quote the talk title to keep this family friendly, and I will pretend no one will read the URL itself ;-) [https://ftp.osuosl.org/pub/fosdem/2019/UD2.120/kubernetesclusterfuck.mp4](https://ftp.osuosl.org/pub/fosdem/2019/UD2.120/kubernetesclusterfuck.mp4) &amp;#x200B; And I hope no one said "it is k8s's fault" (and that is not what I am trying to say, either). Rather, I am just pointing out some of the complexity there during a transitional time for the overall ecosystem. &amp;#x200B; In terms of something concrete that might help right now as a k8s client, you can try clearing out you kubernetes-related dependencies from your go.mod, then 'go get -m [github.com/bcmills/k8s-mods](https://github.com/bcmills/k8s-mods)', followed by 'go mod tidy'. See the [github.com/bcmills/k8s-mods](https://github.com/bcmills/k8s-mods) repo (from one of the core Go team members) for more details. That is not a perfect solution, but might help as a bridge during this transitional time. &amp;#x200B; \&gt; Just today, golint no longer works with modules ([https://github.com/golang/lint/issues/436](https://github.com/golang/lint/issues/436)) &amp;#x200B; From the discussion there, that seems to have been a new issue introduced yesterday that will hopefully be fixed today. If you don't use a '-u' in 'go get' you can likely avoid it right now, or see that issue for more discussion of workarounds that might work for you right now.
Short and simple library for helping you with mocking rand package functions. I'm creating a simulation that heavily relies on the rand package and found it awkward to mock most of these methods out. Hope some of you will find it useful.
Perfect timing, I just wrote my first tests yesterday so time to see what it can do
Maybe, you can try [https://github.com/CovenantSQL/CovenantSQL](https://github.com/CovenantSQL/CovenantSQL)
Thanks for your detailed response. I'm aware of most of the things you covered. I think it's unfortunate though that there was various signalling that 1.11 modules was mature enough to use (e.g. https://github.com/golang/dep/issues/1959#issuecomment-407947097). It's apparent that right now it's not in a great state, and I've wasted a lot of time on it. I'm looking forward to stable go modules, but for now I'll stick to using dep happily (and problem free).
Is it open for everyone or only for people currently enrolled in a University? 
Getting errors for the playback ID
I am not a "solid" aficionado, and I tend to try me best to keep things as simple as possible, what makes sense to me in Go at least, is to simply make sure that I am following the principles of Hexagonal or "onion" architecture, there are many different ways to apply those principles to the way you structure your code in Go , But what works for me in the situation that you described is to just add another layer. So for your code, I'd have an /app package/layer that calls into my domain for anything that my framework ( http in your case ) layer may need to make use of in specific ways, at this layer, in your case, the http handlers would call into `app.UserQueryService` to do all the work that it need, and in the future, should the need arise for even more use case specific implementations of services, they could also live in the app package/layer. 
It's good. But I'd like to see testing something more complicated than basic math functions. Testing using sub tests and test setup and tear down. Also how to mock out databases or other external services (not necessarily http, which you showed already). My needs are simple.
Love the suggestions! I will be working on a follow up in the coming weeks, I will certainly incoporate these into that next post!
Yep, that's it. And the reason to use the parentheses around the type is because it's converting to a pointer type, and without them, it would be converting to a value, and then the * would be attempting a dereference, I believe
Do you expect the method to return a result? I would go with a sentinel error ( `return nil, ErrNoResourceFound` ), but that’s just my opinion. 
Not to my knowledge! Maybe try a different browser? Ive faced issues in the past with videos but this one looks good as far as I can tell! 
Gonna give it a look. Thanks!
[removed]
It's very different; it's not updated in the same commit as the internals it depends on.
I ran in to something similar to this. Stuff was silently broken and I couldn't figure out what the deal was until someone suggested I run`verify` 
[removed]
&gt; TL;DR; maps and slices are still passed into called function as copies but only the headers get copied and the headers have a pointer to the storage so it "feels" like a reference. Are you sure about the maps? I've always assumed I could treat maps like a reference type.
Using build tags for separating out the types of tests works out very well. We are using that for a production Go code base at my work and it allows us to have our Unit, Acceptance, Regression, Fault Injection, Performance, etc tests all in the same repo. I highly recommend it.
If you use `QueryRow`, then you can check for `sql.ErrNoRows`.
You should mention what GSoC stands for. (Google's program to give summer jobs to advance open source.)
That lint thing has nothing to do with modules, it's people using the wrong import path.
[removed]
It's a terminal command to kill bingo, vscode then would auto restart it. Should work on linux and mac, on windows you might have to use the task manager.
I’d make the broker select on two channels: 1. A chan of message chans for registration 2. A chan of message for message delivery
Yep same, I was about to jump ship off vscode until bingo came along.
So you don’t need mocking to solve your problem. The Source in math/rand and the Reader in crypto/rand are exposed so that, among other things, you can provide your own static sources for testing.
[removed]
Packages are idiomatically small so even if you have to download a whopping 3 MB of source code, you won't be adding much footprint to your executable. You should also be using go modules and pinning the version, meaning the code doesn't get upgraded all the time. You should only be auditing when you manually do an update, which should be for a good reason (security or bug fixes or new functionality).
https://github.com/Lallassu, if you're here: Thank you for open sourcing this project. Useful code in these different spaces really helps propel the community forward in these areas by helping people like me who are not sure how to start with libraries in different fields like PCM processing, Natural Language Processing, or 2D graphics in Go.
A middleware is basically the same as a route. You can test it using the standard https://golang.org/pkg/net/http/httptest/
yes there is a way. your function essentially needs "fake" values for w http.ResponseWriter and r *http.Request. you'll find that https://golang.org/pkg/net/http/httptest/ should give you what you want. for a more in-depth tutorial, you can watch this video by /u/campoy at https://www.youtube.com/watch?v=hVFEV-ieeew
Thanks for your comment. Looking at Source and Reader, you may be right but I still think randomock simplifies testing. Unless I'm misunderstood, Source only let's you implement Int63() , generating a new Rand struct (which implements all the convenience methods one would likely use) would requires you to define an implementation of Source that generates numbers that would be used by the internals of the Rand struct to get your desired mocked result. That's a bit too much reverse engineering. Again, I might be not approaching it the way you have in mind. Please let me know if you disagree.
You pass Source to New() which returns a Rand instance. The Rand instance uses the Source to retrieve entropy. If Source is static, the Rand always returns the same thing. 
Thanks for all the responses. I got this working with the following Test, after some help from some other Gophers. ``` func TestRemoveTrailingSlash(t *testing.T) { fn1 := func(w http.ResponseWriter, r *http.Request) { if strings.HasSuffix(r.URL.Path, "/") { t.Errorf("URL had a trailing slash when it shouldnt have") } } fn2 := func(w http.ResponseWriter, r *http.Request) { if !strings.HasSuffix(r.URL.Path, "/") { t.Errorf("URL did not have a trailing slash when it should have") } } h1 := RemoveTrailingSlash(http.HandlerFunc(fn1)) req, _ := http.NewRequest("GET", "https://example.com/foo/", nil) h1.ServeHTTP(nil, req) h2 := RemoveTrailingSlash(http.HandlerFunc(fn2)) req, _ = http.NewRequest("GET", "https://example.com/", nil) h2.ServeHTTP(nil, req) } ```
Thanks. I managed to get it working - have pasted my solution.
hanks. I managed to get it working - have pasted my solution.
But how would you get it to return specific values, say 54.3? What if you wanted it to return 5 the first time and 3 the second time and 9 the third time? I get that you can fix the source but it doesn't solve the problem of you needing to know what int63 values the source must produce to generate the end result you want. 
When you import the dependency you are just including it in your source code anyway. In the end your binary contains the compiled bit of both and you are already shipping it as one. Another question may be, Is forking unethical? Forking is pretty open in open source and is essentially the same thing, you could fork the library, take everything out except the core components you need. I don't believe either is unethical except if you are, intentionally or unintentionally, violating the license of that code (not including a copyright header, etc). If there is no license file then you must assume it is not available for copying. To be extra nice try to upstream any changes that you think should fit. 
Yes. [https://dave.cheney.net/2017/04/30/if-a-map-isnt-a-reference-variable-what-is-it](https://dave.cheney.net/2017/04/30/if-a-map-isnt-a-reference-variable-what-is-it) Now that should change the way you work with it. Your assumptions of "reference type" fits that of a standard pointer so your operations are right. Where slices on the other hand are a non-pointer to a struct header [https://github.com/golang/go/blob/020a18c545bf49ffc087ca93cd238195d8dcc411/src/runtime/slice.go#L13](https://github.com/golang/go/blob/020a18c545bf49ffc087ca93cd238195d8dcc411/src/runtime/slice.go#L13)
Are you sure you actually want random values? Generally when people want to make rand return static values for testing it’s so the tests are consistent irrespective of what specific values rand is returning. If you have a need for specific values like 56.3 I’d probably have abstracted any randomness behind an interface specific to my app rather than mocking out the whole math/rand.Rand interface. Then one would mock only that interface. If you want to test against a range of Rand values I’d use a fuzzer to seed Rand and add any interesting outcomes to my test dataset (so standard fuzzing). 
No probs, hope it helps. Just wanted to say - looks like a great project, keep it up. Starred.
Glad it can be of help :) (aka lallassu)
right. done :)
So oversimplified TLDR: type map *runtime.hmap type chan *runtime.hchan
GSoC requires proof of enrollment in a university: - https://summerofcode.withgoogle.com/how-it-works/ - https://google.github.io/gsocguides/student/
I think you are misunderstanding my use-case. I have specific method which heavily calls [rand.Int](https://rand.Int)(), for example, to achieve different results (in my case, combining the genes of two creatures). I want to test that my simulation produces the expected result if the [rand.Int](https://rand.Int)() calls returns certain values because the result of my simulation will be different (offspring will have different traits). I've essentially done what you are saying and abstracted away the randomness with an interface. However I made the interface generic (based on rand.Rand) so that I can use it throughout my entire code base. I'm not doing something ground-breaking here, it's simply a convenience library which drastically reduced the amount of boilerplate code I had to write. If I created interfaces specific to my app every time I would be essentially writing many of the same thin wrappers around the same functions. I did this at first and then had the idea to make this it's own library. This is for mocking out the rand calls at a granular level. I write higher level interfaces that abstract away methods that produce random results when those specific results are not the focus of my test. &amp;#x200B; Fuzzing is something unrelated to what I'm trying to do. I'm not trying to see if my code breaks down for certain values, i'm testing for expected results based on a certain set of "luck". &amp;#x200B;
I might be misunderstanding your example, but here's what I would do: If you want your user information to stand on its own as an aggregation of sources, you can either make it a micro-service on the same tier as `BlogPost`, which I'll call `content`. I'd make these both subservient to your web server: ``` Blog |-- cmd | |-- web ... | |-- user ... | `-- content ... |-- web | |-- templates | `-- web.go // web server imports content, user client stubs |-- user | |-- api // grpc server | |-- fb ... | |-- storage | | `-- pg ... | `-- user.go // does not import content `-- content |-- api // grpc server |-- storage | `-- pg ... `-- content.go // does not import user ``` Or I'd make both into libraries that multiple future packages can use. In that case, it would look like this (abridged): ``` Blog |-- cmd | `-- blog ... |-- templates ... |-- blog.go // web server `-- pkg/internal |-- content ... `-- user ... ``` Choosing between these is a preference. One leads to a monolith and the other to microservices, choose your poison! :) In the latter, `internal` prevents code that isn't in the directory tree rooted at /Blog from importing. `pkg` is less strict, but a common convention used to house libraries that "could be in their own repo". Maybe you can use this pattern to find a more ergonomic structure for your needs?
Thanks, so I guess can't apply for it. In the projects that you are mentoring, do you have issues which are open for everyone?
\&gt; Sadly the playlist is reversed &amp;#x200B; Funny enough, I reversed it because people complained about how it was "sadly" in the wrong order 😄
🤣 As I suspected. Can't please everyone heh? ¯\\\_(ツ)_/¯
Thanks for the reply. I can appreciate that you had to deal with complications that made the cgo approach less than straightforward. But based on your reasons, it means that your article is misleading in certain places. You assert that there are strict rules in not being able to pass the function pointer, yet in reality you just opted (or didn't know about) using an unsafe pointer and did it another way. And then you asserted that you must put an empty cpp file to trigger C++ compiler which is also the fact that you were just working around the ability to use cgo directives in your source and build tags to have different options for different cross compile platform targets. I would have liked to see those clarifications. My point is that if someone is reading about how to do cgo bindings, it would be clearer for them to know fact vs your custom work around or something you didn't realise at the time :-) 
You should at least tell us what it is: \&gt; A new version 0.4.0 of gore, a Go language REPL, is released today 
Hello justinisrael, I hope you have a wonderful day!
Let me try explain my understanding without butchering it. &amp;#x200B; Using my example. My "Domain" is my root package (in my case "supply") you could also call it my "business logic" [https://github.com/longfellowone/field-services/tree/master/supply](https://github.com/longfellowone/field-services/tree/master/supply) &amp;#x200B; I have an "Order" struct and "Product" struct. Each of these are Entities/Aggregates. They each have their own repository. I also have an "Item" struct that is a Value object and an "Item" can only be modified through the "Order" entity, as you cannot have an order item without an order. &amp;#x200B; I have a "Repository" for each aggregate/entity. One for "Order" and one for "Product". The repositories are "dumb" they are only meant to find and save 1 entire aggregate/entity [https://github.com/longfellowone/field-services/blob/master/supply/mongo/orders.go](https://github.com/longfellowone/field-services/blob/master/supply/mongo/orders.go) [https://github.com/longfellowone/field-services/blob/master/supply/mongo/products.go](https://github.com/longfellowone/field-services/blob/master/supply/mongo/products.go) &amp;#x200B; I have few different "Services", "search", "ordering" and "purchasing" [https://github.com/longfellowone/field-services/tree/master/supply/search](https://github.com/longfellowone/field-services/tree/master/supply/search) [https://github.com/longfellowone/field-services/tree/master/supply/ordering](https://github.com/longfellowone/field-services/tree/master/supply/ordering) [https://github.com/longfellowone/field-services/tree/master/supply/purchasing](https://github.com/longfellowone/field-services/tree/master/supply/purchasing) &amp;#x200B; Each "Service" some people also call it "Use cases". A service uses your repositories to provide a service/build use cases. It can use a repository to "get" information from any aggregate/entity then uses your "business logic" to preform an action. [https://github.com/longfellowone/field-services/blob/master/supply/purchasing/service.go#L27](https://github.com/longfellowone/field-services/blob/master/supply/purchasing/service.go#L27) &amp;#x200B; It can get information from more than one repository. BUT.... it can only modify ONE aggregate/entity per function. &amp;#x200B; On top of everything is your "Access" layer (HTTP/gRPC/GraphQL). Also "dumb", only call's methods on services [https://github.com/longfellowone/field-services/blob/master/supply/grpc/server.go](https://github.com/longfellowone/field-services/blob/master/supply/grpc/server.go) [https://github.com/longfellowone/field-services/blob/master/supply/grpc/ordering.go](https://github.com/longfellowone/field-services/blob/master/supply/grpc/ordering.go) &amp;#x200B; \-- &amp;#x200B; Now using your example. I made up a working example. Let me know what you think? [https://gist.github.com/longfellowone/5971edf87524fce88135c9b78ff6b40c](https://gist.github.com/longfellowone/5971edf87524fce88135c9b78ff6b40c) [https://play.golang.org/p/bwo0lEOvFIA](https://play.golang.org/p/bwo0lEOvFIA)
You should just click on the link.
Let me try explain my understanding without butchering it. &amp;#x200B; Using my example. My "Domain" is my root package (in my case "supply") you could also call it my "business logic" [https://github.com/longfellowone/field-services/tree/master/supply](https://github.com/longfellowone/field-services/tree/master/supply) &amp;#x200B; I have an "Order" struct and "Product" struct. Each of these are Entities/Aggregates. They each have their own repository. I also have an "Item" struct that is a Value object and an "Item" can only be modified through the "Order" entity, as you cannot have an order item without an order. &amp;#x200B; I have a "Repository" for each aggregate/entity. One for "Order" and one for "Product". The repositories are "dumb" they are only meant to find and save 1 entire aggregate/entity [https://github.com/longfellowone/field-services/blob/master/supply/mongo/orders.go](https://github.com/longfellowone/field-services/blob/master/supply/mongo/orders.go) [https://github.com/longfellowone/field-services/blob/master/supply/mongo/products.go](https://github.com/longfellowone/field-services/blob/master/supply/mongo/products.go) &amp;#x200B; I have few different "Services", "search", "ordering" and "purchasing" [https://github.com/longfellowone/field-services/tree/master/supply/search](https://github.com/longfellowone/field-services/tree/master/supply/search) [https://github.com/longfellowone/field-services/tree/master/supply/ordering](https://github.com/longfellowone/field-services/tree/master/supply/ordering) [https://github.com/longfellowone/field-services/tree/master/supply/purchasing](https://github.com/longfellowone/field-services/tree/master/supply/purchasing) &amp;#x200B; Each "Service" some people also call it "Use cases". A service uses your repositories to provide a service/build use cases. It can use a repository to "get" information from any aggregate/entity then uses your "business logic" to preform an action. [https://github.com/longfellowone/field-services/blob/master/supply/purchasing/service.go#L27](https://github.com/longfellowone/field-services/blob/master/supply/purchasing/service.go#L27) &amp;#x200B; It can get information from more than one repository. BUT.... it can only modify ONE aggregate/entity per function. &amp;#x200B; On top of everything is your "Access" layer (HTTP/gRPC/GraphQL). Also "dumb", only call's methods on services [https://github.com/longfellowone/field-services/blob/master/supply/grpc/server.go](https://github.com/longfellowone/field-services/blob/master/supply/grpc/server.go) [https://github.com/longfellowone/field-services/blob/master/supply/grpc/ordering.go](https://github.com/longfellowone/field-services/blob/master/supply/grpc/ordering.go) &amp;#x200B; \-- &amp;#x200B; Now using your example. I made up a working example. Let me know what you think? [https://gist.github.com/longfellowone/5971edf87524fce88135c9b78ff6b40c](https://gist.github.com/longfellowone/5971edf87524fce88135c9b78ff6b40c) [https://play.golang.org/p/bwo0lEOvFIA](https://play.golang.org/p/bwo0lEOvFIA) &amp;#x200B; Your http service would be something like type Server struct { bsvc // type Blogging service interface usvc // type User service interface } Then inside your http service you would call a single method per function. (Take a look at my grpc server for an example) &amp;#x200B;
No.
Scottish?
aye!
I'm returning nil, nil
You should basically never call Read yourself. If you’re doing it right, you should use io.Copy or an ioutil instead. 
\&gt; Affero GPL (AGPL) nightmare \&gt; The worse license ever. It is GPL with more restrictions. &amp;#x200B; &amp;#x200B; Stopped reading here. This is stupid trolling.
Hi. Mind to tell me why is my opinion that AGPL is bad just trolling?
Unless the method suggests that something should be found But you’re right
I found it off-putting that you didn't bother to try to explain why copyleft licenses exist and why you might want to use one as a creator. I get that you don't like the requirements that GPL licenses put on you as a consumer, but there are legitimate reasons why they exist and why a creator would want to use them. Similarly, you didn't provide any reasons why a creator would not want to use a permissive license like the MIT license. This article is written entirely from the perspective of a library consumer who wants to be able to do whatever they want. I think you should try to rewrite it and approach it from the perspective of a library creator, as that's your target audience.
Thanks for sharing! I'm interested in the groot project. :) I'm a student, currently pursuing Masters Computer Science degree. Next steps are to create a proposal and make a pull request to that project? If I understand it correctly..
of course :) - https://github.com/go-hep/hep/issues?q=is%3Aissue+is%3Aopen+label%3Afirst-issue - https://github.com/go-hep/hep/issues?q=is%3Aissue+is%3Aopen+label%3A"help+wanted" feel free to join the mailing list [1] or the slack channel [2]. [1]: https://groups.google.com/forum/#!forum/go-hep [2]: #go-hep on https://gophers.slack.com
and for CERNBox: - https://github.com/cernbox 
yep. you should contact us (by email) so we can send you a few instructions. (a few pointers, tips and also a little exercize to get a rough feeling about your skills.) contact details are there: - https://hepsoftwarefoundation.org/gsoc/2019/proposal_GoHEPgroot.html
It is somewhat ironic that you are advocating that all code should be shared, that nobody loses anything from sharing their product's source, but then you completely dismiss licenses that are specifically designed to ensure that very thing.
Btw, you can use the `//go:noinline` compiler directive.
But then every call to your db Fetch() function needs to check for an error AND then check for a nil too. This may make sense if you commonly expect requests for nonexistent entities, but it seems like in most applications that's not common -- a request for a nonexistent entity is usually a problem.
It might not be considered an error. The problem is that most people, I guess, rely on the fact that if the `err == nil` the value is not `nil`. So it's safer to return a sentinel error, as suggested by /u/TimWasTakenWasTaken.
those CNCF projects look awesome too! How long do we have before we can contact a mentor? I want to get some stuff wrapped up before I over commit myself
The wording is outrageous, and thus this sentence is insignificant. AGPL has served many businesses and funded many open-source projects with millions of euros. May I know your credentials in this matter?
According to https://summerofcode.withgoogle.com/how-it-works/#timeline: Student Application Period March 25, 2019 - April 9, 2019 (Best to let the mentors know you are interested in their proposal before the 25th of March though...) 
Can’t help on the CI pipeline but I can help with the rest. I use the default router for http routing. It works but has limitations. Another good one is gorilla mux which is very popular; I am considering switching. Gorilla has a lot of other useful libraries with it. You may consider looking at Buffalo as well, as it’s a full featured, rails-like web framework. I consider rails to be the gold standard web framework, but others prefer different frameworks. As for inter service communication, I cut my handler code in half by switching to gRPC. It also opens up a lot of nice additional functionality that can be a total pain with REST communication. Hell, being able to pass along the timeout via contexts to servers downstream is a dream come true, along with being able to easily pass down metadata values for things like connection tracing. For Kafka, use sarama and bsm/sarama-cluster. There’s an older cluster module for sarama but it depends on the old zookeeper methods that you don’t need anymore. Instead, bsm uses the 0.9+ clustering tech. One note from experience with Kafka and the cult that is event sourcing: it’s OK to directly write to your database. A lot of Kafka proponents will tell you that you only write to your datastores after it’s been read from the event source. This makes things unnecessarily complex and poses a lot of problems. Instead, just write to the database and guarantee that you’ll emit an event for other services. Routing return events can be extremely shitty, and effectively require each node to parse all messages of similar types that are returning. It just doesn’t work. I watched a video recently with a proponent of Kafka and it was a hard line, event source first before writing and responding. But I saw another video where someone was talking to the guy who effectively wrote the Bible on Kafka and event sourcing , and even he recommends just a straight write to database and then emit an event for other services to consume. 
Can’t help on the CI pipeline but I can help with the rest. I use the default router for http routing. It works but has limitations. Another good one is gorilla mux which is very popular; I am considering switching. Gorilla has a lot of other useful libraries with it. You may consider looking at Buffalo as well, as it’s a full featured, rails-like web framework. I consider rails to be the gold standard web framework, but others prefer different frameworks. As for inter service communication, I cut my handler code in half by switching to gRPC. It also opens up a lot of nice additional functionality that can be a total pain with REST communication. Hell, being able to pass along the timeout via contexts to servers downstream is a dream come true, along with being able to easily pass down metadata values for things like connection tracing. For Kafka, use sarama and bsm/sarama-cluster. There’s an older cluster module for sarama but it depends on the old zookeeper methods that you don’t need anymore. Instead, bsm uses the 0.9+ clustering tech. One note from experience with Kafka and the cult that is event sourcing: it’s OK to directly write to your database. A lot of Kafka proponents will tell you that you only write to your datastores after it’s been read from the event source. This makes things unnecessarily complex and poses a lot of problems. Instead, just write to the database and guarantee that you’ll emit an event for other services. Routing return events can be extremely shitty, and effectively require each node to parse all messages of similar types that are returning. It just doesn’t work. I watched a video recently with a proponent of Kafka and it was a hard line, event source first before writing and responding. But I saw another video where someone was talking to the guy who effectively wrote the Bible on Kafka and event sourcing , and even he recommends just a straight write to database and then emit an event for other services to consume. 
Can’t help on the CI pipeline but I can help with the rest. I use the default router for http routing. It works but has limitations. Another good one is gorilla mux which is very popular; I am considering switching. Gorilla has a lot of other useful libraries with it. You may consider looking at Buffalo as well, as it’s a full featured, rails-like web framework. I consider rails to be the gold standard web framework, but others prefer different frameworks. As for inter service communication, I cut my handler code in half by switching to gRPC. It also opens up a lot of nice additional functionality that can be a total pain with REST communication. Hell, being able to pass along the timeout via contexts to servers downstream is a dream come true, along with being able to easily pass down metadata values for things like connection tracing. For Kafka, use sarama and bsm/sarama-cluster. There’s an older cluster module for sarama but it depends on the old zookeeper methods that you don’t need anymore. Instead, bsm uses the 0.9+ clustering tech. One note from experience with Kafka and the cult that is event sourcing: it’s OK to directly write to your database. A lot of Kafka proponents will tell you that you only write to your datastores after it’s been read from the event source. This makes things unnecessarily complex and poses a lot of problems. Instead, just write to the database and guarantee that you’ll emit an event for other services. Routing return events can be extremely shitty, and effectively require each node to parse all messages of similar types that are returning. It just doesn’t work. I watched a video recently with a proponent of Kafka and it was a hard line, event source first before writing and responding. But I saw another video where someone was talking to the guy who effectively wrote the Bible on Kafka and event sourcing , and even he recommends just a straight write to database and then emit an event for other services to consume. 
Hi, &amp;#x200B; I wrote my test this way: // Query result const ElasticsearchUserUsageSuccessfulResult = `{ "took": 13, "timed_out": false, "_shards": { "total": 5, "successful": 5, "failed": 0 }, "hits": { "total": 18471, "max_score": 0, "hits": [] }, "aggregations": { "usage": { "doc_count_error_upper_bound": 0, "sum_other_doc_count": 0, "buckets": [ { "key": "Custumer1_1000", "doc_count": 3718 }, { "key": "Customer2_1001", "doc_count": 2849 }, { "key": "Customer3_1002", "doc_count": 2835 } ] } } }` func (u *UserTestSuite) TestUser_GetUserValidResult() { handler := http.NotFound ts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { handler(w, r) })) defer ts.Close() handler = func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(ElasticsearchUserUsageSuccessfulResult)) } esMock, err := MockService(ts.URL) assert.NoError(u.T(), err, nil) ... } // Mock returns an Interface func MockService(url string) (*elasticsearch.Service, error) { client, err := elastic.NewSimpleClient(elastic.SetURL(url)) if err != nil { return nil, err } return &amp;elasticsearch.Service{client}, nil } type elasticsearchMock struct { mock.Mock } func (e *elasticsearchMock) GetUserUsageByDate(startDate, endDate time.Time) (*elasticsearch.Usage, error) { args := e.Called(startDate, endDate) return args.Get(0).(*elasticsearch.Usage), args.Error(1) } My elasticsearch.Service interface has the GetUserUsageByDate method and because of that I mocked it in my test, and I used the [https://github.com/stretchr/testify](https://github.com/stretchr/testify) library. &amp;#x200B; &amp;#x200B;
That indeed is a very valid point 
Go by example or a tour of go are great resources, I'd reccomend checking those out.
Different team? Different experience, different priorities, different roadmap??? Just because Walmart exists, doesn't mean there aren't competitors.
anyone actually use fasthttp?
*Hewwo sushi drake!* It's your **7th Cakeday** bitsynthesis! ^(hug)
Google "Todd McLeod golang". He's got some YouTube tutorials, and great courses available on Udemy (which if you contact him directly can give you a discount, if you need... although Udemy is frequently giving courses for like $10).
Why not just use interface to constrain type parameters and special case numeric types. Provide some type of pseudo interface for standard operators.
Surprised they didn't talk about caching DNS lookups since a "fast" HTTP client probably means some sort of repeated access to a resource which will probably hit the same host multiple times. The current Go HTTP client makes sure that multiple clients don't repeat the same DNS queries at the same time, but the results aren't stored. Caching DNS (A/MX/TXT) lookups (and optionally refreshing in the background) is important for communication or crawling tasks.
\&gt; I will probably have 2 or 3 services communicate to each other internally. Should I just use REST between them or try some other protocol (gRPC etc)? If you are doing this to learn I think either option is fine. What are you more interested in learning? There's probably more to learn with gRPC if you are familiar with REST in other languages. &amp;#x200B; \&gt; I want to build good CI pipeline with automatic deployments. Which service do you recommend? [CircleCI](https://circleci.com/) (I am biased) &amp;#x200B;
This is just the sort of thing to get stuff in order. I’ll see myself out. Try the veal!
Because using interface is type unsafe. 
What is essential to know in Go? I have a Medium article about converting a Node backend into Go. What else must be known. 
Oops, sorry about that :bow:!
They wouldn't have to be. There would be no need for runtime type checks in conjunction with interfaces. If there were generics. But hey.
&gt; You should just click on the link. *I did.* Where else you you think I got that description from? Hmm?
Gotta say I’m really not a fan of the contracts; we already have a way to enforce that via interface es. I would rather have a generic require that the value adheres to an interface. With contracts, people are going to be using things like built in less than operators for a comparable type. But I can’t use that for a struct. Instead, if they’re forced to use an interface, then package makers and maintainers will make the inputs a lot more generic. Eg. The sort interface uses a simple “less” instead of “&lt;“. That’s a far more scalable approach. Generics will be super nice. Not required but nice to have for sure. 
Wait, is this sorting the values by the new fmt? I hope it's not. 
I do not recommend the Go course on Coursera. I recommend Stephen Grider's course on Udemy, or Todd McLeod's course at http://greatercommons.com.
from the github... &gt;intersort sorts slices of arbitrary objects according to the rules of Go's fmtsort package. fmtsort is an internal package and thus cannot be imported directly; however, its behavior is exposed via the fmt package when printing maps. So we can sort arbitrary objects by sticking them in a map, printing it, and parsing the result. &gt;**In other words, this package is an abomination and should not be used for anything. May the Go maintainers have mercy on my soul.**
pretty sure there are copyright exemptions for "adaptations". But yes, in principle there is a line somewhere in there where copy/pasting the code is illegal, while reading their code and copying their method is not.
ah, thanks for quoting them. I'm not a native English speaker and it makes me easier to understand.
I return `sql.ErrNoRows` and then handle it with: thing, err := checkTheDatabase(id) if err != nil { if err != sql.ErrNoRows { return err } //handle the "no such thing error" } I tried returning nil, nil, but that lead to exactly the same code, but with the second check in a different place: thing, err := checkTheDatabase(id) if err != nil { return err } if thing == nil { //handle the "no such thing error" } It also meant that I could only return nil-able values from database functions, which got to be a pain. And I was checking the error in two places: once in the database function (checking the error value and returning nil if it was ErrNoRows) and once again in the calling routine (checking the error value for actual errors). I tend to agree that treating "no return" as an error is conceptually not great, but the sql package returns ErrNoRows *as an error* so we don't get to make that choice. We're forced to treat it as an error, because it is one.
[removed]
Type parameters look so weird right now but it'll be super useful! I figure math/ML stuff will be much viable now. Also, u/campoy, en unos meses me mudaré a Barcelona y me encantaría invitar unas cervezas! Una forma de retribución por la maravilla de justforfunc jajaja
I don’t follow, you can have multiple types that satisfy an interface. 
It's up now. 
so it's sort anything *hashable* (there are a lot of things you can't use as key of a map, for example `[]byte`)
Even if we get contracts (and therefore some sort of generics facility), it will take a few years to develop best practices and idiomatic usage guidelines. Probably most of the code you initially write with contracts you'll be embarrassed about a year or two later.
Yeah, I'm excited about that though
Isn’t that a poor way of thinking about anything though. I do that already
&gt; NodeJS's one CPU Core restriction I realize I know literally nothing about Electron or Node but how has Node become so popular with that kind of restriction on it?
Yep, thanks! I would really like to know what happend though
God, I hope contracts don't get accepted as written.
I live in San Francisco ... 😅
[removed]
I prefer Go without generics because of simplicity
If your function requires as an input two parameters - t T and m map[T]U and returns type U, how do you do that with an interface?
but its not simplicity, it makes go simplistic 
@campoy, that's the best talk I've seen for a while. You distilled some intricate material into something I could actually understand.
 func (type U) MyMapFn(map[IndexInterface]U m, t IndexInterface) U { return m[t] }
todd sucks. I bought it. He is not expert. His teaching also sucks. 
IMHO, if you have coding experience in C, C++ or Java (or any JVM-hosted language that is compiled and statically typed), or some older languages (Ada or Pascal), you should just read the language spec. When new coders join our team, I tell them to do that. They complain that language specs are impossible to follow or learn the language from - yes, you will not get to fluency - but if you read through it, you will be able to go through a few examples and you'll mostly be done and better off than people who skipped it. I routinely cite it in my day to day work with other developers. It is also *very* short (shorter than C99 by far let alone something like Java or even out-of-date C++). 
changing is not bad, I'm just not used to it (yet)
Hmm, well just because the types are constrained with interfaces doesn’t mean we the values can’t remain as their concrete types. The types don’t need to be wrapped in the runtime interface representation.
I’d recommend checking out the [promhttp](https://godoc.org/github.com/prometheus/client_golang/prometheus/promhttp#InstrumentHandlerCounter) package from Prometheus. It leverages the [httptrace](https://golang.org/pkg/net/http/httptrace/) package.
You mean like timings? It doesn't record any. But it's not terribly hard to write a wrapper that gathers some.
Thanks. It’s close to what I want, but I’d rather just be able to see info on the connection pool so I could log it to my metrics system. 
You could likely take advantage of the same httptrace package they’re leveraging
Thanks. It’s very helpful. I’ll look into that. 
Ahahaha amazing &gt; In other words, this package is an abomination and should not be used for anything. May the Go maintainers have mercy on my soul.
I am a uni student/node and java developer and im learning go to build my resume. Shoot me a PM if you want to talk
&gt; we already have a way to enforce that via interfaces. No we don't. A lot of people say this because they don't understand interfaces or contracts and I wish they would stop. Interfaces are types. Contracts are metatypes. Say you have a SortedList&lt;T&gt; where T must implement Compare(T). Say you want to have lists for two interfaces Job and Person that implement Compare(Job) and Compare(Person). Job and Person satisfy the Compare(T) contract, but it is not possible to define a type safe interface for them. You could define a Comparer interface with a Compare(Comparer) method, but this is NOT the same thing. You would need to do runtime type assertions everywhere, whereas with contracts the types can be checked at compile time.
Would it not be simpler if you create a DB interface, for which you create an ES adapter as one of the interface implementationts? Then for testing you can swap out the ES adapter with a mock adapter. Your interface exposes the high level required methods such as Search(..) or whichever you require. This way you control the interface, making it easy to mock. Rather than having to mock an external interface like the ES client or an http server.
I don't know of any, but you might want to check out [etcd](https://coreos.com/etcd/) as an alternative to zookeeper which enjoys great support in the Go ecosystem (as well as others). 
We will need generic interfaces for sure. type X interface(T) { Greater(T) bool } Or something similar. Then we have compile time type checking. Otherwise there’s no clean type checking if you mess up the contract definition. There would need to be a ton of obtuse checking to ensure the interface can conform to the workings of the generic versus the contract. So just do genetics and generic interfaces. It’s just more logical. 
The library is good and can be used in production. We’ve used it for a long time. There are some issues but 99,99 of the time you won’t run into those and can be mitigated. It’s not as full fledged as the java libraries but those have their own issues so don’t be discouraged. Look at the wrapper here for inspiration on using the library: https://github.com/vitessio/vitess/blob/master/go/vt/topo/zk2topo/zk_conn.go as this mitigates most of the problems.
What is different from zero net?
Im not in Love with contracts so far. 
&gt; generic interfaces They're called contracts.
That was a very interesting read. Thx for sharing
I'm not aware of any atm. But if you do find some with your tool, I would be very happy to be notified about it :D [https://github.com/andersfylling/disgord](https://github.com/andersfylling/disgord) &amp;#x200B; Check out the branch called \`release/v0.10\` for the latest.
Thanks, I hate it
The slides contain a cached map of dns-&gt;ip entries?
Nice writeup, thanks! Are you merging (parts of) this to the regular client? 
Use the standard library &amp; their accompagning docs
No, they are not. Such a thing does not exist yet
Not sure why you can't have a parametric interface with multiple parametric types. That would restrict a type in terms of another, thus achieving the same thing in a different way.
Hi, I am not sure what exactly you are asking. Could you rephrase or be more precise? I am probably biased but Gonum is great!
Where is the code?
&gt;That seems dishonest. Are you really asking us to do your homework? I'm asking for feedback and advise on how to make it better, not interested in asking for asking someone else to code it.
With parametric interfaces and interfaces that describe operators. In this case: package builtin // Indexer implemented by map, slice and array type Indexer(type T, U) interface { GetAt(t T) U } --------- package main func (type T, U _, I Indexer(T, U)) MyMapFn(m I, t T) U { return m.GetAt(t) } 
zero net is more like a tor network static web site framework. CovenantForum is based on CovenantSQL which is a database use blockchain to sync "binlog". So, technically you can port any SQL based app to CovenantSQL, which makes a traditional app to a "client only" app.
No reason to punish others that might genuinely need generics because you personally do not.
It might help to think of numeric types as having methods where operators are syntactic sugar for those methods. If that were the case, all we would need beyond interfaces is to add boxing/unboxing syntax as a means to wire up the relationships.
How did the term "punish others" got into a reply to OP's "I prefer"?
I'm responding to an opinion with an opinion. An opinion which is sadly some kind of echo chamber in this sub.
Well, I'm actually running a gogs on my home server (go), plus a syncthing (go), plus a caddy (go) webserver/reverse (no nginx) , with the filebrowser plugin. My blog is generated using hugo (still go), tmail (go) for mailserver, and I wrote a DNS proxy with adblock , also in golang: https://github.com/Loweel/zabov , similar to piHole. So you can have your whole ISP stack there, if you want. :) 
Me too.
Thanks for the answer! Ok I didn't get the last part about Kafka and writing to the database, but I'm probably missing the general knowledges about it yet :) What I plan to do is to have server notifications come to some URL where my service will write put them to Kafka, and then I will have 2 other services to listen from this even (new notification came) from Kafka.
cool!
&gt; Praise for intersort: &gt; This should not be done. - Rob Pike lol
No, you're responding to _a preference_ with an unfounded _accusation_.
Firstly use Go modules for dependency management not dep, has been there since Go 1.11 You'll want to use a basic router for your endpoints: gorilla mux is the one I prefer because it just does routing and the rest is the std libs. If you want something more then look at something like echo. To manage your DB check out sqlx
That's the programmer spirit right here. Always improving on what you know and learning from the past. &amp;#x200B; btw. i really enjoy(ed) your GO YouTube series
No idea where you're seeing an *accusation*. 
It's my first project with golang so please be gentle ;) It must contain something that could be done better but I'm learning (hopefully)...
This is actually great! Every other Go graphql articles I've read are so incomplete and rudimentary as to be nearly worthless, but this one actually addresses the main issues with graphql. The dataloader approach is a really interesting solution.
They do talk about it
Hey, nice to see another gqlgen article! We’re on the cusp of a new releases with a stack of refactors and features. Happy to answer any questions people have or otherwise hit us up on out gitter.
Wow, thanks that's awesome!
Nice!
Yes, I do in production. You have any questions?
Go Wild!: [https://github.com/Kickball/awesome-selfhosted](https://github.com/Kickball/awesome-selfhosted)
have you read this [https://golang.org/doc/go1.12#runtime](https://golang.org/doc/go1.12#runtime) ?
Here https://github.com/ExaScience/elprep-bench I'd love to see some C++ wizard make it faster. As much as I like Go (work with it daily), it's not meant to be faster than C++ in general.
Will we still need to delete resolvers.go when we run the generate script ? 
Yep. This is something we’d like to address and we’ve thought about removing this feature until it can automatically update, but it’s also really powerful for getting people up and running. The next release focuses on plugin groundwork, and on the ability to map multiple Go types to a GraphQL type. And as well adding Go Modules support.
yes i did. which is why i am confused because i have the feeling that i'm seeing the opposite of what is described in that changelog. i'll experiment with that `GODEBUG=madvdontneed=1` flag to see if that can narrow things down
yeah. if you were to rewrite your software again today would you still go with fasthttp? and what do you use for context?
The provided demo is pretty slow. Is this because of a crappy server, or is this decentralized architecture just a very badly optimized?
The c++ code is not impressive. At all.
If your system monitorins RSS as "process memory" then that explains it. RSS can now include pages advised as MADV_FREE, which should not be counted against the process for the purposes of memory use accounting, killing processes for policy reasons, etc.
It's actually really nice, done right. Say you want to read in chunks of up to 1k; you create `var buf [1024]byte`. And if you want to read the max until EOF you can pass `buf[:]` to `Read`. But say you know you have to read an 8-byte value; you don't need a new buffer, you just pass `buf[:8]` instead and read will read exactly what you need.
Having schema first code generation is powerful and gets people up and running, but having to delete an entire file when the schema changes then re-generate it and apply the diff from your deleted file (resolver.go) is actually really, really annoying and creates opportunity for error. &amp;#x200B; The way you've worded your answer makes it seem like having to delete the file is actually a plus side? 
Hi, thanks for the reply. This seems like what I am looking for. Could you point me to some codebase that uses such mock adapter so that I can look at the code for reference?
Also don't forget that the different people maintain a set of forks with various fixes applied—see \[the network\]([https://github.com/samuel/go-zookeeper/network](https://github.com/samuel/go-zookeeper/network)). &amp;#x200B; We hee at my $dayjob maintain a (closed) fork which is basically the upstream version with a dozen of patches applied from staller pull-requests. &amp;#x200B; It's sad the project is dormant but still the code is almost OK, so I'm with u/Iliec on this.
with the `GODEBUG=madvdontneed=1` debug flag activated: https://i.imgur.com/zfbHtjv.png i'll keep investigating. thank you!
Not at all. I’m talking about bootstrapping, not ongoing development. An ideal version of this would obviously update the file itself, but we have higher priorities at the moment. It’s definitely something we’re keeping in mind. 
Same here. I am interested in working and maintaining but without the spof again. Would this be something you or someone else at you company would be interested in?
Oh, nice. I've been using GraphQL with Node at work and I was looking at trying some stuff with it in Go. Just out of curiosity, why `dep`? Why not Go modules? Does gqlgen work better with it in some way?
Plus is just a raw function. It can be used anywhere. Area and perim are member functions that must be called on an instance of rect. Eg, r := &amp;rect{} r.area()
I agree. I'm learning graphql now as a primarily infrastructure dev and nothing really covered it like in this article. So many of the graphql overview articles miss the query complexity bit like it's nothing.
Sorry, the github says build failing and I am wondering what the cause is. I think Golang is great and instead of diving into stuff like Scala and Java libraries for Data Science, I have decided to give Golang a shot for a research project. The speed and single binary make it a good choice for "hot reload" with a large system needed for hortonworks stuff. I think having the ability to use slices and pointers as well as the net/http would make it a better language than Java to learn with. What do you think? I know Python is like the primo language for data crunching but I have a funny feeling that Go 2 is going gain great GUI support and it could override how we think of desktop apps. I guess that would go through webassembly and browsers not so much the native window API.
Go modules are a mess right now. I'd wait. 
Current master uses the “loader” package to resolve code and imports. This isn’t Go Modules compatible. Our “next” branch has swapped this out for the “packages” and soon we will support Go Modules.
If enough people continue to echo that they prefer Go without generics, they wouldn't be added (but thankfully enough have expressed yes why every modern language has them). So, yes, it would be punishing others by sharing said opinion.
My mistake, I obviously missed it.
ok i got the idea behind it Thanks
Even if they are called contracts in a generic setting, that doesn't make them the same as "the contracts proposal" as currently understood. The thought has crossed my mind before that we may be better off using interfaces as they stand today for our "contracts", and to the extent there are use cases they don't meet, well... we may be better off just taking the hit. I say "may" because I really am ambivalent. It's just a thought I've considered. I also wonder if we might not be better off with "interfaces as they are today are our notion of contract for generics" and that the solution to "how then do we work with normal types" is to endow the built-in types with default methods that do addition and substraction and key lookup and stuff. That _might_ net out simpler than the current contracts proposal, and, honestly, to the extent that it may already have been rejected in the past, maybe it's time to have another look at it, because I'm still not sure about the current contract proposal. It works _great_ for me and I _personally_ love it, but that's not always a great thing for Go.
ah. the "build failing" badge is like so b/c AppVeyor is lagging w/ providing a Go1.12 stack. (other Go1.xx stacks are passing, see: https://ci.appveyor.com/project/Gonum/gonum/branch/master) The Linux CI is all green (see: https://www.travis-ci.org/gonum/gonum/branches) I am also thinking Go is a great language for science in general. I am probably less optimistic wrt GUI support but who knows, there are a few promising candidates... (when comes to GUIs, I usually just spin up a local web server and serve HTML pages.)
[removed]
Thanks, that's what I strive for
I personally prefer go modules too, but i am thinking its because of old habits, for those who started out before go modules
One option is to just have a mock implementation of the type that your `getRawLogs` method is on (assuming that type is what is being called in your handler). So, your handler could also have an interface for the client defined next to it, and a mock implementation defined near your tests - problem solved for the handler. From there, if you'll still want to test your Elasticsearch implementation, and in my opinion, you would actually want to really go to Elasticsearch - as in a real running instance of it. There's still the problem of forcing certain scenarios to do things like check error handling. If that's something you're concerned about then you _can_ actually mock these builder types, it's a complete pain in the ass, but it is possible. I did something similar with the Google Storage client (I think they've actually included something very similar to this in the library itself now), but here's the type it starts out with: https://github.com/seeruk/foldup/blob/master/pkg/storage/gcs/client.go You can see from there, it has an interface that returns interfaces, and an interface for the real type, and an implementation that adapts the real type into the easier to test interface with methods that handle adapting the concrete types into the interface types.
Hmm, looks like -race may be incompatible with breakpoints?
The first is a function and the others are methods on the types. https://tour.golang.org/methods/1
Fixed here [Debugger Stops Working : GO-6853](https://youtrack.jetbrains.com/issue/GO-6853)
I'm not sure what this buys you over just using a buffered channel as a semaphore. sem := make(chan bool, 10) ... sem &lt;- true go func() { work() &lt;-sem }() This approach is really simply, and very flexible for your actual work. If I want a timeout or cancellation then I can add it to my work call as appropriate. The pool approach removes type safety and specific return types. It also leaks the worker gortouine since you cannot shut down the pool. I don't see what you get with all the work the pool does to check in and out worker objects that run in goroutines and use many channels to ultimately transfer an interface{} and error back to the caller. 
Like [this](https://play.golang.com/p/rVGLwP8RVQ-)?
That makes more sense than anything I have seen so far. One way or another I need to assign the string to a func name it looks like. That is more favorable than what I was doing though.
My question would be... why are you doing this? This is kind of an anti-pattern and should be extremely rare in most go code. What is the overall functionality you're implementing? Like, where do the function names come from? &amp;#x200B; Could it instead be a slice of the functions themselves? &amp;#x200B; like &amp;#x200B; \`\`\` funcs := \[\]func(){funcA, funcB} for \_, f := range funcs { f() } \`\`\`
- Homedir is built into Go 1.12. - May as well use Go modules instead of dep unless you have a firm ideological preference. 
[removed]
Agreed but without knowing the thought process behind it I didn't want to be too harsh :)
Thanks for the comments! As I am new to the whole language, I don't really have knowledge of all things available but I will look these up. Thanks once again!
It's either this map approach or using a switch on the value and calling the right function. The map allows for dynamic registration while the switch is for a fixed smaller set of values. 
Incorporating GPL code into a closed-source code base doesn't necessarily violate the GPL. In order to violate the GPL, you have to distribute the binary including the GPL dependency without the source.
Nice, I will take a look at that, tank you :)
so i just figured out that the GODEBUG flag needs to be added at run-time, and not at build-time. so by setting that env variable in the container that runs the binary, things go back to the way they were before. but when you say that MADV_FREE "should not be counted against the process for the purposes of memory use accounting, killing processes for policy reasons", do you have any documentation about this? when it comes to low-level stuff like this, i'm a bit out of my element
The MVC folder structure doesn't feel much idiomatic. There are two main ways of doing back-end services in Go that I see. You create packages for your entities, say an `activity` package in which you put the repository, service and http transport. Or you create packages by layer, a `repository` package, a `service` package, and a `httptransport` package. In any case, in the repository you made your database calls, in the service you use that repository and add all the validations, authentication, authorization, logging, etc. And in the httptransport you just decode request and encode responses. I saw you reading from the environment variables on a controller. Better if you read that at the `main()` function and pass that down where you use it. That way you self-document your code. One, always start by looking the main function and there you can see all the configuration it accepts. Naming... Go prefers singular names and very short.
&gt; &gt; we already have a way to enforce that via interfaces &gt; No we don't. A lot of people say this because they don't understand interfaces or contracts and I wish they would stop. &gt; &gt; Interfaces are types. Contracts are metatypes. Eh, kind of. Goto 44:44 in the video. As currently specified contracts are just more powerful interfaces, so trying to argue they are different things is a bit weird. The problem is that people like interfaces, and lots of people find contracts ugly/bad/whatever for various reasons ... so people argue that they want better interfaces instead of better contracts.
It's a common way to structure Go projects: * Executables inside their own directory and sometimes under /cmd/ExecName * Shared files in the root ├── cmd/ │ ├── executable1/main.go │ ├── executable2/main.go │ └── executable3/main.go ├── cmd/ExecName/main.go ├── shared1.go ├── shared2.go └── shared3.go See: https://github.com/golang-standards/project-layout
\+1 Going to play with GraphQL and Go finally after reading this article.
In response to the title of your post as opposed to the question in your post body... No, import paths can also come from the module cache or the vendor directory: https://github.com/golang/go/wiki/Modules
one approach i take is declare functions (this case es.Client.search) so I can mock the "function" call ``` type handler struct { esclient func(string) *SearchService } func (h *handler) getRawlogs (....) { response, err := h.search(es.indexname) . . ``` to call from main or other func ```elastichandler := &amp;handler{esclient:elasticsearch.client.search} ``` and during test declare the func inside the struct ``` elastichandler := &amp;handler{esclient:mocksearch} elastichandler.getRawlogs(....) I've read many posts that mocking has problem of its own, as long as you cover many scenarios you should be ok, otherwise CICD will be far more complicated (eg load up ES container and load indices) you can simulate real "working" stack using these provisioned systems, but I can never simulate "failures" I try to write mock to cover most failure (eg conn timeout, bad data return) there were 10s of remote call i had to write mock for, worst one I'd say was SMTP client (net.smtp and net.http being the most simple one.) and I recommend write interfaces so you can mock interface rather than functions. as long as APIs have interface you can use tesify/mock (https://github.com/stretchr/testify) to create simple mock. (dont need function replacement) some discussion here on gitlab, how to mock aws-sdk https://github.com/aws/aws-sdk-go/issues/88 
[removed]
&gt;This is super interesting we haven't made the jump to 1.12 yet but I will definitely keep an eye on the resource usage of my pods before and after the upgrade. Out of curiosity what version of kubernetes are you running?
No. But standard `net/http.Client` gradually acquires missing functionality with each new Go version.
I really don't know much avout the go ecosystem, but since nobody has answered as of yet, if you're set on using go and can't find a good framework for GUIs you could always build an electron app with a go backend
The Qt bindings are just that - bindings. It doesn't change their look and feel, it just creates the Qt controls, so if you look up pictures of Qt it will look the same. I'm using it now, it's pretty ok, but not the best. I am more excited about flutter for desktop unless someone wants to write a full Go UI framework.
If you're interested in this, you might also be interested in [Aether](https://getaether.net/).
This commit message contains more information about this issue and points out potential solutions.
go-astilectron is what I would use if I were writing a GUI app in Go, just my personal choice since styling is much easier than Qt.
There doesn't seem to be a pure Go framework yet, so currently it's mostly bindings to Qt, Gtk or some C libraries. I tried [https://github.com/andlabs/ui](https://github.com/andlabs/ui) for a while, and lately been playing with this wrapper for Dear ImGui and its worked quite well for what I needed: [https://github.com/inkyblackness/imgui-go](https://github.com/inkyblackness/imgui-go).
I like to have the binaries in sub-folders of a cmd directory because then I can have a clean way of having multiple binaries in a repo. Also, if the packages are meant to be consumed by others, it makes for a simpler import path.
In addition to the suggestion that you can have multiple binaries (mains) in a project, it is also rare to use relative import paths. Or absolute path with no domain namespace. 
Which commit message?
I've heard the GTK bindings are the best option, but I'm sure QT bindings would work okay as well. I've kind of resigned myself to not doing desktop stuff with Go and just doing client/server stuff instead, since that seems to be where it shines. I'm a little more bullish on Rust getting proper GUI support at some point since Mozilla seems to be intent on porting Firefox to Rust. If I was going to make a GUI app using Go, I'd probably just use C++ or Python for the front-end, and connect it to a Go backend (either through linking or sockets).
Yeah but electron... 
Released v0.1.0 of [https://github.com/posilva/go-poolboy](https://github.com/posilva/go-poolboy) &amp;#x200B;
I don't think that wildcard query is being used correctly. Isn't the first parm supposed to be the field name? I think you want the QueryStringQuery for a 1-1 mapping with your original. 
If you want an openGL framework then g3n is pretty cool. Examples of all the GUI components are viewable in the g3nd demo app. https://github.com/g3n/engine https://github.com/g3n/g3nd
Most if not all low-level GUI APIs are C/C++, which means that any Go GUI library will require cgo, unfortunately. 
So far, vulkan-go seems to be the most promising. Vulkan is the successor to OpenGL, and is available across all of the major platforms (Windows/Mac/Linux/Android/iOS). https://github.com/vulkan-go There's also Fyne: https://github.com/fyne-io/fyne
I'm waiting for good module support with qt. I found gtk way too version specific. Upgrades where difficult.
Obviously the easiest thing to do is to compile your front-end Go to WebAssembly and wrap it in Electron! In all seriousness I don't think Go is great for desktop GUI development. When you look at the state of graphical toolkit bindings for Go vs. C++ or C# even on Linux, it's just gonna be a lot more work to use Go.
Qt works really well - therecipe - I’m running apps and cross-porting to iOS, Android, Windows (via the Docker builder) and MacOS native. The only thing I’ve had difficulty doing - switching between portrait and landscape in the app. Otherwise I’m really impressed with it. I couldn’t find any other library that gave me cross-platform portability. My only suggestion being to keep testing the app on each platform as actually seeing the app on various platforms does affect the design decisions ... 
Example: [https://gist.github.com/posilva/b26fe5ae731b7a7126566a6180188ee6](https://gist.github.com/posilva/b26fe5ae731b7a7126566a6180188ee6)
I was actually looking this up for a project at work, and [gotk3](https://github.com/gotk3/gotk3) looks really promising for cross-platform GUIs. There is some work you will need to put in for Windows, but it isn't too much. Plus, you can use [Glade](https://glade.gnome.org/) to design the GUIs and it works very well.
I use this. I'm no UI designer whatsoever, but I was able to use Glade to design the UI, then I used gotk3 to read in the XML and hook up all the functionality for a basic control dialog prompt
Thanks for pointing me in the right direction. With your help, I am able to now return the total number of hits that match, but I am unable to actually print the contents as a string. This is my code so far [https://play.golang.org/p/ZMczg2FHELK](https://play.golang.org/p/ZMczg2FHELK) &amp;#x200B; Working on it...
There's Lorca library, a lightweight alternative to Electron 
If you are interested in native Go GUI's, then those I follow are: https://github.com/fyne-io/fyne https://github.com/goki/gi
Screenshots github.com/amlwwalker/got-qt
Thank you for pointing me in the right direction. I was able to get exactly what I wanted (the simple results from my wildcard query). Code is here: [https://play.golang.org/p/Hxvomoc3EJQ](https://play.golang.org/p/Hxvomoc3EJQ)
I just installed and ran the demo on my MBP. It is remarkably erratic. Mouse clicks don't register or take several seconds to take effect. In general, every aspect seems to be unreliable in terms of response to user input. Did I do something wrong?
Jesus, yes. I cancel the installation if I see an app pulling that crap in. I understand it's easy to get cross platform with it, but I need my laptop to be able to run more than one app at a time, and not burn down my battery. Please, don't be a dick: don't use Electron.
Ah. Looks like it's using 100% of its single thread... Constantly.
You guys are really not exploring your options. There's excellent GTK bindings in Go. Download Glade, make the gui and link its functionality in code
add a verbose logger to the client arguments, i’ll dump all the requests/responses so you can see what’s exactly being sent/received
Pretty soon, webassembly will allow PWAs to be written in Go. PWAs can be installed and then are basically a desktop GUI app, but if you're splitting hairs, they aren't truly native.
For our project, OpenBazaar, we outsource the GUI to Electron. The [core of the app](https://github.com/OpenBazaar/openbazaar-go) is Go and an [Electron client](https://github.com/OpenBazaar/openbazaar-desktop) talks to the Go app over https. It'd be really great to have a good way to build the UI in Go directly but Electron has been a lot easier for our frontend devs to work with.
Exactly. The lib takes a while to get used to but after it while it starts to click. You can build some pretty advanced queries with it. I've not had a query yet that I can't express.
Thank you. Shocking people haven't realized this
I don't get it. Why can a function be homophobic?🤔
For what it's worth, [httpgzip.FileServer](https://godoc.org/github.com/shurcooL/httpgzip#FileServer) also supports serving static files that have been precompresed. See the [httpgzip.GzipByter](https://godoc.org/github.com/shurcooL/httpgzip#GzipByter) and [httpgzip.NotWorthGzipCompressing](https://godoc.org/github.com/shurcooL/httpgzip#NotWorthGzipCompressing) interfaces, which are implemented by files in the output of [`vfsgen`](https://github.com/shurcooL/vfsgen#additional-embedded-information).
I'm glad to hear it was helpful.
&gt; As currently specified contracts are just more powerful interfaces Nope, go to 45:50 in the video. Interfaces and contracts are orthogonal concepts, neither is a replacement for the other. There are things that interfaces can do that contracts can't and vice versa. Of course, there are some things that you can do with either, in the same way that you can write some functions both with goroutines and channels and without, that doesn't mean goroutines completely replace regular functions and vice versa.
How do you close the database resources, per that example? The pool does know how to shut down its goroutines but there is no way to have them clean up resources from the workers from what I see. My point earlier was that a Pool would have to provide even more functionality to be useful over just having your own semaphore and workers acting on requests over a channel. Really simple to do and type safe. If I were to use a Pool library I would want it to have Close hooks for the workers, min/max workers so it can scale up and init new workers on demand and have them shut down when they aren't in use, etc. But if it is only provided the semaphore and work request pattern, I don't get why you would want to sacrifice type safety for a simple generic dependency. 
You should upgrade to 2018.3.5 or 2091.1 EAP 7 and that should fix the issue. Also, adding the gcflags arguments is not necessary as GoLand will add them automatically for you when you Debug is selected.
Awesome projects!
https://github.com/zserge/webview/tree/webview-x
I've seen that happen before on Ubuntu - it comes with transparent huge pages enabled for entire memory. Try running ``` echo madvise &gt; /sys/kernel/mm/transparent_hugepage/enabled echo madvise &gt; /sys/kernel/mm/transparent_hugepage/defrag ``` and restarting your service. In one edge case I've seen memory use by one service drop from a couple GB to &lt;100 MB with this change.
I don't know windows. But on Linux, the xorg client protocol could be implemented in golang, like another xlib or xcb. When this low-level mechanism is done, widget, windows are possible. Wayland is another story.
A couple of months ago there was no such thing as a contract. To me it seems more logical to slightly extend what we have than to come up with an entirely new and different thing.
You can find live app examples written in Go which use GTK binding here: https://github.com/d2r2/go-rsync and here https://github.com/d2r2/gotk3/blob/master/examples/cool_app/README.md
Lorca works well, but requires having Chrome installed.
Hi, this should serve as a good example: https://play.golang.org/p/KlmYNFkIDR7 What this does is: * You're not hard-linked to ES. If you ever want to switch to a different technology, it's easy. * You can write tests securing your "SearchDB" interface along with the mock version. Once you have that test, you can easily apply that test to other implementations too to ensure they are functioning correctly. * You can mock it very easily, so you can develop without the need for setting up a lot of other services. It's based on the "Dependency inversion principle", https://en.wikipedia.org/wiki/Dependency_inversion_principle . This is part of the SOLID principles which are really good guidelines for writing code that is easy to maintain, mock, test, etc. 
What are the use cases for such a hash?
Just use gopher-lua. That's it. [https://https.www.google.com.tedunangst.com/flak/post/easy-gopher-lua-bridge](https://https.www.google.com.tedunangst.com/flak/post/easy-gopher-lua-bridge)
Any documentation Calling this out: support for PWAs in Go?
why not contribute to make QT better? 
https://code.fb.com/security/homomorphic-hashing/
Interfaces and mock implementations That’s how I do it But with ES I usually go for a Docker Test environment (local and CI)
I went on a completely different route: [github.com/zserge/webview](https://github.com/zserge/webview) which can open a kind of browser, then I made a web-application (on a random high port) which gave me the opportunity to put all my web development knowledge inside my gui app. Which I used for quickly developing my application.
I've made a small app with Go/QT. The lowest size I can get it to distribute is 78MBs. If you're planning to ship QT together with your app that's something to keep in mind.
I think type hinting is a good idea. And I would recommend doing the standard approach by naming the variables in the tag string so that you can add multiple tags with no issues. You might want to look into struct validation instead. This is a great package I use that helps with validating structs (https://github.com/go-playground/validator). You can use the predefined tags to validate the struct data or you can even define your own. This way you get a type hinting plus a way to enforce the hints as well.
I use [Language Server Protocol (LSP)](https://langserver.org/) and this works for me: // Car is a model structure type Car struct { // Brand must be in lowercase. Brand string // Btype must be five characters long. Btype string // FuelConsumption must be between 0.0 and 50.0 FuelConsumption float32 // FuelTankCapacity lorem ipsum dolor. FuelTankCapacity int } You can see it working here: https://i.imgur.com/ETO1Uku.png **Note:** tested in SublimeText, Visual Studio Code, Intellij Goland, and Atom.
I wouldn't use struct tags for this, because they are basically designed for key-value pairs for programmatic use. You could use the part of the language intended for humans, which also already shows up in Godoc, and comment the fields instead? // Car can hold information about a car. type Car struct { // Brand is the car's manufacturer. It's value should be lowercase. Brand string // ... } The more documentation that you try to make human readable in struct tags, the harder you'll find it, and you'll also limit how easily you can include real struct tags, like `json` tags. TL;DR: Use comments, this is exactly what they're intended to be used for.
Good job. Being that you are new to the language, it looks pretty good. I admit it looks better than my code when I was first cutting my teeth on Go a couple years ago. Not sure if you are interested or not but for your help message at the bottom of gdrive\_notes.go, you could use a backtick \` to write multi-line strings that will preserve line breaks. Also.. I believe its fairly standard to house your func main() in a file called main.go so people know where to start. Keep it up. I haven't delved into all of the code, but at glance it looks like you are going to have fun.
Cool thanks!
awesome! thanks for the tip. 
I would love to have a tool, that does some "human" checks, like a check on: \- number of lines within a function \- cognitive complexity (used this in php a lot) \- incoming number of params in a function \- outgoing number of params in a function &amp;#x200B;
I have not currently reached methods I will be starting strcts today thanks for the heads up 
I agree this is confusing. Its because bookshelf is a package that is not exclusive to the app that might use it. On line 38 of app/app.go its importing the package which is just one level up. `import "`[`github.com/GoogleCloudPlatform/golang-samples/getting-started/bookshelf`](https://github.com/GoogleCloudPlatform/golang-samples/getting-started/bookshelf)`"` Honestly, I have been writing Go now for a couple years and I am still not sold on this. But if I am correct that package is treated like all other packages in go, and built and made available at the $GOPATH/pkg ; so technically any other Go project could also pull in the "bookshelf" package as well.
Thank you ! i have resolved it
This project looks interesting. I would be interested in packaging my front end and back end code together, but outside of that this would be something similar to Electron.
I’m not sure I agree - Go’s been the first genuinely cross-platform environment I’ve used. I have literally the same app running on Mac, Windows, Android and iOS. The Qt bindings work well. 
I see it working in the same file, but that's not what I expect it =to do. What if I use my car in another file and have typed: mhCar := [models.Car](https://models.Car){} Hoover over Car gives me my comment (with the tags), but when I do that with your solution, all the comments are gone (in VSC) Any hints? 
I know that, but I am looking for a way to have them visible inside the editor when you hoover over such a struct. (without having to godoc any code) This would bring understanding at the spot so to speak...
So preform wins?
\#just game engine things
https://blog.jetbrains.com/go/2017/10/26/gogland-eap-17-type-hierarchy-call-hierarchy-parameter-hints-vendor-scope-and-more/
&gt;github.com/smalln... this is a case of **throughputs vs latency** 
Exactly
you can use go on Android?
I would have used the same approach too!
For a real-world pipeline based Go program (also published as part of a Scientific paper), you might want to check out this converter from RDF semantic data to MediaWiki XML format: [https://github.com/rdfio/rdf2smw](https://github.com/rdfio/rdf2smw) The whole main program consists just of code to connect goroutines, which are packed up in Go structs, with channels bound to struct fields, according to an idea that is described in two posts at GopherAcademy ([this](https://blog.gopheracademy.com/composable-pipelines-pattern/) and [this](https://blog.gopheracademy.com/advent-2015/composable-pipelines-improvements/) one), and then further improved into the [FlowBase unframework](http://flowbase.org/): [https://github.com/rdfio/rdf2smw/blob/master/main.go](https://github.com/rdfio/rdf2smw/blob/master/main.go) The individual components is where you find the actual Go-routines and channels: [https://github.com/rdfio/rdf2smw/tree/master/components](https://github.com/rdfio/rdf2smw/tree/master/components) Hope this helps!
"The review committee is actively reviewing submissions and we anticipate informing selected speakers by the first week of March." https://www.gophercon.com/page/1388210/speakers
What I keep wondering regarding these 1 million connection servers.. * How much actual processing can a server still do while managing these connections? Having a connection open is not very useful if the server does not handle any normal typed requests for it. What is the throughput in these benchmarks? Is it handling tasks that require say X milis computing time? * Does it really make sense to benchmark on a node with a 20-core CPU? I'd prefer scaling my server horizontally in a set-up with far less CPU cores required per server, even if it can't handle that many connections.
Yes: https://github.com/golang/go/wiki/Mobile#building-and-deploying-to-android You can also compile it for webassembly: https://www.youtube.com/watch?v=6v4E6oksar0&amp;feature=youtu.be 
Have you considered using types?
Seems about right. 
Why tho
Hello all, I've been dabbling in go for a few weeks/months (on and off) and decided to write something actually useful that doesn't exist yet. So I present to you the world's first static code analysis tool for go . I wish I could have included more metrics from the beginning, but I am rather busy and just wanted to get it out so that it can already be useful to some people. In addition go isn't an object oriented language, so a lot of standard metrics can not be calculated. I do not write "good" Go code and did not optimize the performance yet, but it can analyze go-master with more than a million lines of code in less than 5 seconds anyway.
Yes, and I would think that it would be easier to handle *more* connections on multiple boxes than it would on a single box. In other words, Twenty boxes with 1 CPU vs one box with 20 CPU's. _Note: one box makes a lot of other things like deployments easier._
Wayland is another api like X. It may not be a network protocol in the same way, but a go-native implementation is absolutely possible. 
Not specifically, but PWAs are just websites that do a few extra things. [Vecty WASM support](https://github.com/gopherjs/vecty/pull/232) was waiting on the new syscall/js API in Go 1.12. Once that gets merged in, making a Go PWA should be just a matter of adding a service worker and a web app manifest to a vecty project.
Why not
Traitor ;)
That's only true if you're doing it by hand. Any sort of production service - and one that actually needs to sustain a million connections - has long since automated this. Maybe by scripts, maybe by kubernetes, but if you need 1 million connections you don't care about deploy complexity. In fact, any app that needs 1MM connections would usually be worse off having them fully concentrated on one box (outage scenarios).
I've got a related question. I'm working on a web crawling project. I want to be able to launch full-fledged Chrome via Golang (not the headless version), but I'd like it to display in an in-memory frame buffer (rather than on the actual screen), as this will often be running on servers. I know there are things like Xvfb which could facilitate this externally, but I'm wondering: Does anyone know any good solutions for launching graphical apps from within a Go program in a way that doesn't require an _actual_ display? It would be nice to build this into the app itself for people to use.
If you're not looking for native UI bindings or anything, should definitely consider this. A webview with enough controls.. your application can be a simple webapp displayed inside this webview.. 
&gt; World's first static code analysis tool for Go Excuse me?
Learns golang to write a program to help them write php... NICE!
Does anyone know about anything similar for Python? Would be really nice to write Python tooling in Go, since much Python source code analysis tooling (e.g., black, etc) is terribly slow presumably because it's written in Python.
Fyne looks promising. Gi looks a bit too busy as an interface, though it is more feature-rich at the moment.
 WARNING: it looks like you are using PHP
What you have done is ok, and I don't think its wrong. My suggestion is to create a DataSource struct or something that holds your \*sql.DB. This way, you create your DataSource with a new() func or something, then open your connection to the sqlite database and return the DataSource. From this point your Insert or CreateTable funcs could be a method of the DataSource object. You can call data.Insert("data") rather than passing around the pointer. func (d *DataSource) Insert(url string) error { d.mutex.Lock() defer d.mutex.Unlock() err := d.db.Exec(...) .... } An option. About your question of passing around the pointer to sql.DB. I believe that is the prefered way, and yes use the mutex.
This is funny as hell. You can entirely replace your PHP with Go, but here we are, with a PHP linter in Go.
### Andlabs I have only found 1 that worked pretty well is **andlabs**. &amp;nbsp; It takes a bit to get used to and doesn't have much in depth documentation, but it is easy to understand how it works and get started. ### Zserge Lorca Zserge has a pretty nice setup for html I have had a hard time getting this setup on a few linux distro's. Actually, I haven't been able to get it working on ubuntu 18, but it is pretty nice and easy to use. As most people know html, css, js it is very user friendly. Also sometimes it has some runtime errors, it isn't often and it does depend on the distro as well. Still a userful, I have used it for a few small app like things. ### Sadly... Normally the problem I have is that they don't support linux or they have some special library that doesn't work right. Like I found one that works amazing on ubuntu 16, but fails hard on 18. There is also a nice one I found that does great on ubuntu 18, but doesn't support mac. &amp;nbsp; There is a really nice one for mac, but I can't remember the name. Again it only supports the newest versions of mac os. There are a few for windows that seem to run ok as well, but I want my products to be open to for anyone to use (mac, linux, windows) so it makes things a little more difficult. &amp;nbsp; To be honest... Most of the time I just use local host and run it as a server. You can make a function that checks the os and runs the command that opens up chrome or firefox with the local host url you want. Depending on what I am doing or what the program is it is very similar to web dev and super easy to get projects done. It really isn't the best solution in the world, but it works on everything. It is very similar to Zserges idea, but without the nice bow. &gt; It isn't a very good option for intense programs and sometimes requires some work arounds, but it does work. I have been praying to the gopher gods that go creates a standard library for this since I first heard of go.
I have seen this and wanted to try it out, but just haven't had the time. How long would you say it takes you to get started?
Can you name one? I do not consider tools that calculate only a single metric to be a tool. I'm talking of the likes such as sonarqube or understand.
Sadly we can't replace php legacy. 
I agree, this doesn't leave much room for processing the requests/connections it's serving, there are far better alternatives for holding the client connections while a cluster of app servers handle the requests.
First of all, linters _are_ static analysis. Statis analysis deduces facts about code without executing it. Whether these facts be bug reports, style issues, or code metrics is irrelevant. Second, `go vet` was the first static analysis tool for Go. Third, there have even been prior tools that calculate metrics like Gopham does, such as Sonarqube itself: https://docs.sonarqube.org/display/PLUG/SonarGo – also, all of the ones in https://github.com/golangci/awesome-go-linters#code-complexity
technically correct. Should have phrased it differently. I mean tools that calculate programming related metrics such loc, complexity, lcom, god classes or whatever and not security or syntax related things. Basically metrics that you need to judge code quality and where refactoring needs to happen.
In which case, SonarGo.
from their page: &gt;Metrics (Cognitive complexity, NCLOC, ...) not really sure what they actually compute and they don't bother saying it anywhere, but I guess you're right. Don't think they had any worthwile metrics last year when I checked and I dislike sonarqube in general. I'll change the description on the github page, can't do it for the title here though
[removed]
&gt; However, this improved update and verification performance can be attained only by subscribers who keep a representation of the entire Merkle tree in memory — thus requiring memory overhead linear in the number of database rows. …Why? It's a bit ironic that this post dropped just one day after [rsc wrote about merkle-tree log structures](https://research.swtch.com/tlog). AIUI what he describes solves the same problem, but doesn't require the subscriber (or publisher) to keep the entire tree in memory. Or does it?
I'm not sure why people find this funny. It's a perfectly valid way to do things. Use a language for what it's good for there are plenty of people who feel that PHP is good for web development and Go is good for making fast system tools. There's no requirement that a PHP tool be made with PHP.
Rather than taking in a slice, which often requires constructing a slice in place like your examples, you might want to look at variadic functions to accept one or more elements of a give type! 
This is, naturally, a limitation with VSC, not with the implementation. In my experience the Go plugin for VSC is generally pretty unreliable, and things like intellisense and godoc hinting simply don't work much of the time, especially cross-package. This way of using godoc formatting is the correct way to do it. Use this way, and then focus on why the tooling isn't actually working. 
Claiming “first static code analysis tool” rubs in wrong way. Thanks but no thanks, I’m sticking with gosec tool instead. 
Nice! I’ve considered writing a composer competitor in Go for the concurrency ala yarn v nvm.
Technically yes. However companies like to make money, so pretty much no.
I can give this an attempt, but I have not read the code that closely. 1. The DB functions don't really need to be in a different package since I think it isn't that much stuff right now, but that is more of a matter of personal preference. Do it if you think it will improve the code or your organisation of the code. 2. If CheckHTTP returns an Error at any point your Mutex would stay locked. Currently, if I understand CheckHTTP correctly, it does never return an error, but if you refactor that at any point you would not necessarily spot the Mutex in another func that needs to be released in that case. In my opinion CheckHTTP should not be called inside the mutex lock anyways. I would do CheckHTTP first and then grab the lock, grab the ID, increase it and then unlock immediately afterwards. All of the rest can go after the unlock. Generally speaking: The less that happens inside a Lock the better. Only do inside the lock what absolutely needs to be inside the lock. See at the end of this comment what I mean. 3. Your Unittests seem relatively reasonable. You could try to use a Code Coverage tool to see what you missed. You could also test some edge cases like overflowing the recordID and handling unknown shortURLs and stuff like that. You also have not tested the handlers or the DB functions. 1.a I would get rid of all the Globals by putting them into a struct (maybe "Server"). The Handlers and the display func could be Methods of this Server struct. This would also simplify Unittesting because you could switch out the sqlite with in [memory instances](https://www.sqlite.org/inmemorydb.html) for each unittest. This has the benefit that the Unittests always have the same starting point and are independent of each other (no globals, each test with their own instance). &amp;#x200B; &gt;func shortenURL(longURL string) (string, error) { &gt; &gt; longURL, err := checkHTTP(longURL) &gt; &gt; if err != nil { &gt; &gt; return "", err &gt; &gt; } &gt; &gt; &gt; &gt; // Not Tested. No guarantee. &gt; &gt; m.Lock() &gt; &gt; rID := recordID &gt; &gt; recordID++ &gt; &gt; m.Unlock() &gt; &gt; &gt; &gt; shortURL := base62.Encode(rID) &gt; &gt; rec := URLRecord{rID, longURL, shortURL} &gt; &gt; go writeRecord(db, rec) &gt; &gt; return shortURL, err &gt; &gt;} &amp;#x200B;
How the fuck is a security tool even comparable? Buddy, do you even know what software metrics are?
Thank you for your suggestion. I see what you mean but in order to make the same operations (such as sorting) I need to convert it into a specific type of a slice, right? I actually did not totally understand how could variadic functions help me with this case
[removed]
&gt; 95% of the time when someone mentions a static code analysis tool in my environment it is related to software-metrics and fully blown tools and not some utility function terminal program Different groups of people call the same things by different names. For example, in my environment, nobody thinks of metrics when speaking of static analysis, but only of bug finding tools. And people are very torn on the actual meaning of linter. Some think it only applies to finding style issues, some think bug finding also counts as linting. In the end, it's all very ambiguous; the only "technically correct" terminology is static analysis vs dynamic analysis. As for "full blown tools" and "utility terminal programs": in a UNIX environment, it is usually the latter that is referred to as tools. Cynics may even say that fancy web interfaces displaying metrics are for managers.
How about returning: `(ok bool, doc someType, err error)`?
Best reply ever!!!
Whatsapp was hosting their backend on a cluster of servers with ~40 cores and 100gb of RAM back in 2012 with 2 million connections per node. I don't know if they're doing that still.
&gt; However companies like to make money, so pretty much no. You're not going to get a company to switch by saying "lulz php sux". &amp;#x200B; Exactly. &amp;#x200B; And modern PHP is not bad enough to say that a complete transition from PHP to Go will be the best decision. But you can benefit from Go, like in this case, by writing tooling, separate services that accompany monoliths and daemon-like programs that complement PHP in areas where it's not a good fit.
Do you even know what static analysis is? This post doesn’t suggest so. 
unfortunately this thread is nothing but useless drivel over some technical word choices. Doesn't change the fact that there is no comparable tool to mine available. Some people need to chill the fuck out and realize that I wrote this it in my free time to help others and not for some dick measuring contest. The title was merely to peak peoples' interest on something that is new rather than the bazillionth linter that get posted here every single day. Will delete this thread shortly anyway. Zero worthwhile discussion here.
[removed]
Thanks a lot, although I did figure out how to place my code, in the process finding the elegant solution. Thanks anyway :)
[removed]
"secrets"?
Very nice 
Hmm okay that use case does make sense! Most of those connections are likely to be long-polling "passive" connections, not using server resources except for the connection itself. I wonder if they still run with large nodes today, or switched to multiple lighter nodes as a replacement. There's a lot of good automated deployment frameworks by now, making that task a lot easier.
Basics
Thanks!
&lt;?grumble echo "folder called src?" ?&gt;
Here are two different Async request hooks I did up. &amp;#x200B; [https://codesandbox.io/s/yy04l8lm9?fontsize=14](https://codesandbox.io/s/yy04l8lm9?fontsize=14) [https://codesandbox.io/s/j3lq4pkn3y](https://codesandbox.io/s/j3lq4pkn3y)
Hard to say, as far as I can tell they don't have any recent information on their physical infrastructure. The connections were plain TCP connections, they used to run jabber but they switched to their own thing. So those connections were actual client connections, sending chat messages and pictures/videos. Whatsapp famously built their system with Erlang, and as far as deployments went they heavily leveraged its hot code reloading features to avoid having to restart and lose all the sessions. The other thing is that they used Mnesia, a distributed database that runs inside BEAM, the Erlang runtime, essentially running a DB shard on the same hardware as the application server inside the same processes.
So what is 400 in Roman numerals?
Set the mine type to text/css I believe. It’s a simple header add command. 
I wish but I think I learned more from justforfunc then anything
No, a `...int` in a function declaration is the same as `[]int`.
https://github.com/golang-ui/nuklear
That is correct. Browser wants to make it happy. 
IC
it should just print "no" and exit status 1.
This happens to me when I serve files manually (rather than using a file handler for static files). As mentioned by BulletsandCofee and dshrouds you will have to send this with a mime type of text/css.
Interesting. I’m not particularly photogenic but I’ll think about it. 
We also need editors, script writers, coders, reviewers ... join.justforfunc.com
Yes I know that but If you took a look at the functions there is no force type like \[\]int, it is all dynamic.
This happens because it's missing the "Content-Type: text/css" header. Use `http.FileServer` or `http.ServeFile` and it will set headers automatically for you. That being said, I've been having the same problem with JavaScript... Some files are being send as "text/plain" I don't know why. But I solved it with this line: ```go mime.AddExtensionType(".js", "application/javascript; charset=utf-8") ``` In your case, it should be: ```go mime.AddExtensionType(".css", "text/css; charset=utf-8") ```
Application submitted :-)
just for func is awesome, I think learning about the things that make a language special is the best way to learn. A lot of people try to translate their old language thinking to the new language when switching, but that is never a good way to do it. just for func is great for learning how go works in terms of a go way of thinking. We have a Typescript shop, so I've been trying to find out ways to use wasm for performance. Go - wasm - TypeScript stuff would be some great stuff to dive into. I look forward to the future of the channel.
No its going to pull in the latest version of that specific import path because it's new and there are no constraints. So 2.x is the latest. I think you are confusing the "v2" concept with a project that has actually made it part of their import path, either by naming it in their go.mod or having a really v2 subdir in the root of the project. 
I didnt see this reply and just spent some time looking into go modules and I dont see the benefits. It looks more like packaging your own project then managing dependancies. &amp;#x200B; What would you say is the best tool currently out?
Also, if you check out the readme for the kingpin project, they instruct you to use the vanity import paths. If you want v1, import "gopkg.in/alecthomas/kingpin.v1" 
figure out a way to optimize your code so you can render them pointless and thus viola, delete 
* On Linux: 5 Mins. * On Mac: about 10 Mins. * On Windows: about 20-30 mins of setup for the GTK bindings. &amp;#x200B; Of course, your mileage may vary.
Oh thanks, not to bad, I may have try it out.
Thanks, now that vanity import path make sense. I finally found the answer I was looking for in the Go documentation. &amp;#x200B; &gt;Code written before the semantic import versioning convention &gt; &gt;was introduced may use major versions v2 and later to describe &gt; &gt;the same set of unversioned import paths as used in v0 and v1. &gt; &gt;To accommodate such code, if a source code repository has a &gt; &gt;v2.0.0 or later tag for a file tree with no go.mod, the version is &gt; &gt;considered to be part of the v1 module's available versions &gt; &gt;and is given an +incompatible suffix when converted to a module &gt; &gt;version, as in v2.0.0+incompatible. The +incompatible tag is also &gt; &gt;applied to pseudo-versions derived from such versions, as in &gt; &gt;v2.0.1-0.yyyymmddhhmmss-abcdefabcdef+incompatible. &amp;#x200B; This explains why I was seeing "v2.2.6" and "+incompatible" in the go.mod file. &amp;#x200B;
I would avoid the global service instances if you can. It makes testing harder because everything depends on that shared reference. You are better off avoiding that whole list and doing a Server style struct which takes the dependencies as fields (store, etc.). You can then make sure your handlers have a direct field reference to their dependency. And this will make reusability and testing better because you can create discrete instances of this service configuration with different types of dependencies. 
This seems to be a good starting point for you: https://github.com/ribice/gorsk
I'm trying to accomplish something similar but put it on hold until I'm further along in the project. Personally I would go for receiver method especially if you're passing something like a single database connection or something that does not change. https://medium.com/statuscode/how-i-write-go-http-services-after-seven-years-37c208122831 If you're trying to do something like determine the correct database or something that changes depending on the http connection, then you might look at middleware/context or session. Personally I don't like the session approach. 
Think it would be better than the hirak/prestissimo composer plugin?
I missed that, I also didn't write a test for it so easy to skip . But I think that's why we share our code that people can judge your code. &amp;#x200B;
https://github.com/BurntSushi/xgb 
Alright, fixed that real quick. Do you see any other problem than that?
Damn, I knew it was all scripted.
I selected the “host” option because you can select only one, but I’d be up with pitching in anywhere it’s needed.
 **david@raspberrypi**:**\~ $** sudo chmod -R -rwx /usr/bin/go . seemed to get rid of one of the errors, but i still get the following and i can't change the ownership &amp;#x200B; **david@raspberrypi**:**\~ $** ls -lah /usr/bin/go lrwxrwxrwx 1 root root 20 Dec 27 2016 **/usr/bin/go** \-&gt; **../lib/go-1.7/bin/go**
you probably shouldn't do that in a goroutine
Haha, yep you are right about that.
&gt; IC Is this a pun?
Campoooooooy
I didn't know it existed. Looks impressive (at first glance)
Will justforfunc be a nonprofit organization? Will you put all assets (the brand ownership and the money flows) in it? Will you be open about it's purpose in a contractual way?
Used in my company for 1 year Very good
Any examples with migrations and seeders?
same here.
I like the format of show like Justforfunc or the Boring show(google flutter channel) where we can see real engineering trying to address problems live, with mistakes, bugs, stackoverflow etc... I hope that just for func could be a bit more topic focus. Let say something like: - Monkey Monday: create commandline tool to automate your work - Web Wednesday: work on Web/Microservices tech - Fundamental Friday: work on core Golang principal - Serious Sunday: some review/pull request over Golang open source projects like Kubernetes or Hugo I hope each topic could drag out through a span of 2/3 episode with user question sections etc... @campoy: what do you think?
[https://youtu.be/E75b9kuyRKw?t=904](https://youtu.be/E75b9kuyRKw?t=904) maybe we can create a library like [checkers](https://github.com/conal/checkers) to provide testing utils that checks properties of standard interfaces that must be followed.
Why do you think the **/usr/bin/go -&gt; ../lib/go-1.7/bin/go** link is a problem? Is your go get still failing? Based on the versions, I'm guessing you installed Go using apt. You might want to uninstall the very old distro version and install using the instructions at [https://golang.org/doc/install](https://golang.org/doc/install). You'll want to use the ARMv6 package at [https://golang.org/dl/](https://golang.org/dl/) for the Pi.
probably you launched `go get` in the past as root (sudo), take back the entire dir ownership: ``` sudo chown -R david:david /home/david/go ```
How about [https://golang.org/pkg/math/big/#Int.SetBytes](https://golang.org/pkg/math/big/#Int.SetBytes) ?
Yep, can't believe I missed it! Thanks!
Symlinks always look like they are `777`, because they are simply pointers to a different object, and have nothing to do with the permissions of that object.
This is just not true unfortunately. People hire engineers that are familiar with the company's current stack. Java Recruiters won't even look at your Linkedin profile if all it mentions are Haskell, Clojure and OCaml. I'm not saying that it should be like this but I can see why it's cheaper to get someone who is already stack proficient.
If I was more confident in my go, I'd be joining. Alas, I still use justforfunc to get an idea how to code Golang better. So super happy it's coming back :) 
How does it compare to gorm?
Gorm is an ORM library, this is not.
No migration system in place with ozzo-dbx, I’m using dbmate myself (but wont advise it to you)
a := rune[](mystring)
A := []rune(mystring) Correct way
This is slow operation, O(N) by the way
About how it works: golang is clever, and parce Unicode chars in correct way. He literally knows about symbols.
Something like this needs benchmarks, bad. 
How do you mean?
Yes but if each element of this slice of run takes each element of a slice of bytes (a string), how does it know when two successive bytes (which translate in a special character in the Unicode table) need to be taken as one element and not two ?
Not []byte, []rune. Golang is smart, really smart. Just try :)
This is about there is expensive O(N)
Yes, I know it will work. My question is why and how ? How does Go's compiler know when two successive elements of a slice of bytes represent one (special) character and not two ?
There are Unicode table and set or rules inside runtime.
Okay, thank you for your answer. Do you know an article when I could read more about it ?
Check out `stringtoslicerune`. - https://golang.org/src/runtime/string.go - https://godbolt.org/z/9n4tU5
This is not a Go problem, but a variable length encoding problem. You should read up on how UTF-8 works.
Are you willing to help with that or just wondering?
I don't think it's going to become a daily show, tbh But if you're willing to help organize the show you're more than welcome to apply! I like fresh ideas
I haven't tried to do this, so I can't help with your question. However, I have noticed that on more recent go versions, vim-go appears to be running into issues that other IDEs I have used do not struggle with. There are GitHub threads about them, but I don't see any clear fixes.
I understand this is just a small tutorial, but I'm not sure what it is trying to teach. Why would you want to deploy a container that, along with the binary, contains the source and the go compiler?
Very interesting. How does it compare to sqlx and go-pq. The latter is much more specific to postgres than DB-agnostic though
See https://en.m.wikipedia.org/wiki/UTF-8
Right. That‘s what a build container is for.
Yes, I've been taking a look but I don't see anything clear yet. I'll probably switch to vscode if I can't find a solution &amp;#x200B; Thanks
https://en.m.wikipedia.org/wiki/UTF-8 linked by /u/matthold has the answer.
This is very much something I'd like to be doing. I've never worked with qt, or really much in the way of a gui (I've been almost exclusively command line or backend stuff). Can you point to some examples or articles that got you started?
How do you even use fyne? Is there a cheat sheet?
Hey /u/serdaozun why did you delete your comments? Deleting comments on Reddit makes for a bad reading experience.
I'm usually happy when stuff like this even works correctly. 
[removed]
Nice. I would be interested in the packaging section. Hope there will be a section on how to sign binaries there:) 
https://github.com/fyne-io/examples/
How are you sharing your iPad screen on your Mac like that? 
Im using Quicktime Player to record a new movie which displays the screen, then capturing the quicktime screen using screenflow!
Ah ! Right. Forgot you could do that. Very cool. 
Shit this is awesome! Great usage ideas!
This looks decent, I’ll dive in deeper to look at source and architecture. Also for readers, check https://github.com/upper/db which has been in dev since 2012 and had years of production use and iteration. I wonder how they compare 
The documentation’s pretty weak on the “how to do Qt” bits. If it would help, I’ll sort some sample bits - I use the widgets directly so I didn’t have to learn QML and UI Gen (all part of the huge Qt library). Others might point you in the general direction of less ‘direct’ methods. I’d suggest starting with a look at Qt itself - fire up Qt creator and have a look at the various widgets available. From there just dive in and have a go :)
Not a problem if you run DockerSlim on that container... It will strip everything your app doesn't need to run and the minified image will be a few megabytes instead of 355MB it is now :)
It uses the first bits to determine if the rune is 1,2,3 or 4 bytes long, this is explained in the book “The Go Programming Language”
I’m late to the party here, but I just wanted to suggest some changes to your database functions. 1. It seems like you liberally use panic for database operations. While this is probably fine for things like table creation (app can’t run if the table doesn’t exist), you should probably not tear the whole thing apart if for example there is no record found, or if a constraint was not met. The SQL package has some checks for that kind of stuff, plus whatever driver you use should have some built in cheddar for DB specific error codes. 2. I noticed that you are creating another error variable “err2” instead of just reassigning “err”. This will be fine as you have already assigned and checked “err” for error, and it is no longer necessary outside the context of where you had used it. Keep up the good work though!
I would say dep. It has worked well for me over the past couple years. It was supposed to be the official tool until Russ Cox decided to go against everyone else in the community and make go modules without discussing it first. 
so your library executes database queries and returns maps them to structs... but isn't an ORM? ok.
I'm not doing it inside a goroutine. I think it's something specific to my machine. I'm on Windows. ```go // On Windows, MIME types are extracted from the registry. // // Text types have the charset parameter set to "utf-8" by default. ``` That's what it says on the "mime" package. But it's true that doesn't happend with all JavaScript files. I'm doing a single page application and I have a lot of imports and only some of them are sended as "text/plain". At least, adding the extension manually solves it.
Using Bytes() and SetBytes() will only work for ints &gt;=0 big.NewInt(-1).Bytes() returns []byte{1}
If you’re doing this for fun, continue on, but practically there’s not much value in this. You’re going to end up adding a slow, buggy cache in front of an already cached service. 1. The db already has its own query cache, and is going to do a better job of it than you. 2. There are projects already along this line of thinking, but I believe they’re meant for shared or redundant MySQL dbs. 
Im surprised by this response because from researching online it seemed like adding a DB cache like Redis or Memcache for your most frequent queries is the default thing to do for performance reasons. I wanted to learn how to do this but only if there’s a practical benefit from it later on. But if what you’re saying is the case, then I’m going to re-evaluate. 
Okay, um, I’d say don’t start with caching unless you have a reason to. The DB can and will do this for you. A case where the db cache might not be adequate is where maybe you have a lot of expensive queries to one area, and that data doesn’t change often, then this type of caching might be useful. Don’t do this prematurely though. If your app is simple, revel in its simplicity, and don’t add optimizations until you are forced to. 
I've never heard of somebody using Redis to cache DB queries. I guess maybe if they're very expensive queries that don't need to be run constantly maybe it'd be a good idea, but that's not the average use case. Memcache is great for caching stuff like pre-generated html pages, but again I've never heard of somebody using it to cache the result of a mysql query. MySQL already does a ton of caching that you can rely on. Are you having specific issues with mysql performance or are you just trying to learn techniques?
‘github.com/lib/pq‘ is abandoned/dead. Last commit oct 2018. The Microsoft guy was the owner. Bus-factor = 1.
I’m just trying to learn techniques and increase my knowledge in this area as a newcomer. I thought using Redis or Memcached with MySQL/Postgres is a very popular thing to do (realizing now that I may be wrong about that) and just wanted to see some patterns folks have implemented.
This makes sense. Thank you for the feedback. I may still try to go about this project for fun, but what you have said gives me some good perspective.
Why such a defensive reply? These are simple and fair questions. "No" is also an answer. :-/
Not related, but the same author has created a [Go starter kit for REST APIs](https://github.com/qiangxue/golang-restful-starter-kit) which has sensible collection of libraries packaged together. We've been using it in our company for 2 years with great success. Also to note that he's a primary dev for a well known [PHP framework](http://www.yiiframework.com) &amp;#x200B; &amp;#x200B;
You showed him! Superior knowledge.
I'm looking for people to help with this. I'm asking you whether you're willing to assist. If you find the answer defensive, or you expect me to owe you extra work to be able to answer, right now and for you, a question I have no answer for yet ... that's your problem.
In general, if something (your http.Handler) does its work via a dependency (your Elasticsearch struct) then you should construct the first thing by taking an _interface_ description of the second thing as a parameter. ```go // If you have this type Elasticsearch struct{ ... } func (es *Elasticsearch) Search(query string) (results []string, err error) { ... } // Don't do this func NewHandler(es *Elasticsearch) *myHandler { return &amp;myHandler{Elasticsearch: es} } // Instead do this func NewHandler(s Searcher) *myHandler { return &amp;myHandler{Searcher: s} } type Searcher interface { Search(query string) (results []string, err error) } ``` This advice is fractal: if your Elasticsearch struct does its work (Search) via a dependency (an ElasticsearchClient) then you should construct the first thing by taking an _interface_ description of the second thing as a parameter. The point of doing all of this is so you can test each layer of the dependency stack in isolation. That is, when you test myHandler, you pass in a mock/fake/whatever implementation of the Searcher interface, which always returns the same data. In other words, you test only the handler code, not the underlying Elasticsearch stuff, which doesn't matter. This decouples the use of Searcher from its implementation, making your code easier to reason about.
A string is NOT the same as a byte slice. If you look at the Go source, you'll see that under the hood, a string's representation is as follows: ```
[removed]
You can import using any SCM provider (most commonly git). So the import path is pretty much arbitrary. The main reason you don’t see more is mainly that running your own git server can be a pain. Most people don’t want to do it, and when it comes to open source, a lot of projects like the exposure that GitHub gets you, and there’s a certain level of trust/stability with GitHub. It is also possible to setup a “vanity” import path, even if the code is hosted on GitHub (or another common provider), but there is a little extra work to do so. More info can be found here: https://golang.org/cmd/go/#hdr-Remote_import_paths
Those are called [Remote import paths](https://golang.org/cmd/go/#hdr-Remote_import_paths), the gist is that `go get` will request the specified URL with `?go-get=1` appended, and expects to find a "go-import" meta tag containing information about the repo to be cloned. Quoting the example: `&lt;meta name="go-import" content="example.org git https://code.org/r/p/exproj"&gt;`
[removed]
`go help importpath`
If it's just a single server, use Go's map instead of redis. It's simpler and faster. Redis cache only makes sense if you have multiple servers that want to cache the same data. 
[removed]
[removed]
I really appreciate your great videos and I fully respect that you owe me nothing (not even a reply, so thank you for that). Please keep giving back to the community and please don't be mad at me for asking for clarification of your plans before committing to anything.
To maybe answer more directly, it probably assumes it's something that would require uint32. Which would be a higher code on the utf8 chart and if it's lower than those codes it truncates to uint8.
Cool package, but I must ask: What problem is this trying to solve? These fluent DB packages look ideal on the surface but when it comes down to serious data querying with joins and subquerying and so on, they become as complex - if not even more so - than the standard raw SQL strings in your codebase. Granted, it makes simple selects and inserts look nice, but is having the following really so bad that you feel an entire dependency is worth it? selectStatement, err := db.Prepare("SELECT title FROM books WHERE id=$1") // err handle row, err := selectStatement.QueryRow(bookId) // err handle There's other issues too, since these effectively generate SQL of which you have no immedaite visibility; you have to be ok wtih ambiguous queries being run on your database or deep dive into the package and figure out what it's doing, in which time you could have just written a standard database function and moved on. Also the business implications: Having to onboard new devs to some package that they most likely will have never used - Looking at the comments there are at least 4 other fluent DB interface packages - when inversely they will probably already know how to write SQL. On a recent project at work one of the team used [squirrel](https://github.com/Masterminds/squirrel) for the POC and we ended up removing it for the production codebase, owing to it being both too hard to read and lacking documentation on performance impact. It's odd, coming from a .NET background the first thing I missed in Go was fluent interfaces such as LINQ, and when I first saw squirrel I thought my dreams had come true. Actually seeing a solution written with it though, I was taken aback. We moved to simply using functions in postgres to take most of the query string boilerplate away, which is also useful for other solutions which would want to interface with the same db that might not be necessarily written in Go. I'm not saying we shouldn't write these packages, but I think we need to consider as gophers what the actual problem is with data querying that makes us want to abstract it all away into with sexy method chaining.
As someone getting started with Go, and wanting to do some DB work, would this sort of framework/lib be advised over the built in sql support of the language? Or SQLX is better to look at?
Thanks! Also check out my edit, I would like feedback on the structure.
I also have a close quetion: Given that Go community is generally anti framework, what is your view of Ozzo? Anyone using it in production?
Interesting. So if I'm correct, whenever we write this : ``` sliceOfRune := \[\]rune(stringValue) ``` The compiler knows it has to use the `stringtoslice` function in the runtime ?
But if a string isn't a slice of bytes, then why is possible to "go through" a string in a for loop (using \`len\` and not \`range\`) and why are each individual characters of that string treated as one/multiple bytes ? &amp;#x200B;
The runtime examines the first byte to determine the number bytes used to encode the rune and then shifts and masks those bytes to create a rune (alias for uint32). There is no truncation uint8 involved.
Yes, and you'll find examples of that for many conversions, including whenever you convert a non-interface value to an interface value. Note that the compiler is pretty smart about inlining (and is due to become even more smart about inlining in the future, check out "mid-stack inlining" if you're curious), so stuff like this usually gets optimized away. Some other things you might be interested in the same vein (core language features which are really just runtime functions and code inlining): - https://www.youtube.com/watch?v=KBZlN0izeiY - https://www.youtube.com/watch?v=Tl7mi9QmLns
Neato! Thanks bud
While I agree, I do want to point out that the query cache was removed with the release of MySQL 8. 
I would highly recommend against using plugins for your middleware.
thanks
Could you elaborate?
Could you explain why?
This is super interesting, thanks! I found an article with more information. https://mysqlserverteam.com/mysql-8-0-retiring-support-for-the-query-cache/ I think it does support what I was saying about how it’s hard to get this right. The maintainers concluded the cache wasn’t super helpful and sometimes hurt performance. My original recommendation stands; don’t optimize until you know what needs it, and weigh your options and trade-offs then. 
Seems like you got a pretty good answer there.
Last commit from Jun 16, 2018 ? Seems not good.
Nice article, vut I disagree with the conclusion: in caching the hsrdest is cache invalidation. As the article says, at the db engine level they know what to NOT cache as it is non-deterministic. It is hard to do without parsing and understanding zhe query and know the functions and tables included. For cache invalidation, the db engine is the oracle that knows when a table has changed, so if at least some form of notification would be available, that may replacs the need for a db level query cache. The best cache is the closest to the client: it's browser. The second is the application: it knows what may be cached, till when, and when to invalidate. But this adds complexity!
I can't say why they did, but personally I think it makes more sense, as it looks like a function call, where the argument is some value and the return is that same value with a new type. Putting the \`\[\]\` in front makes more sense lexigraphically too, as now all types are right left to right ("slice of runes", in your example), not in some crazy spiraling order or whatever it is that c does.
Well, they seem not to like superfluous parentheses, so I just attribute it to that.
It's not a cast, it's a conversion. Casts are free as they are a reinterpretation of the same bytes, conversions are conversions of bytes to a new type. Go does not have casting, it has conversions and assertions.
\&gt; Should every handler be explicitly given, as an argument, a reference to the necessary dependencies? &amp;#x200B; Yes.
Wait, so what does Rob mean when he says “In Go, a string is in effect a read-only slice of bytes. ” in https://blog.golang.org/strings ? Or are you just saying they’re not of the same type?
Post spec itself has no limit, to my knowledge. You would handle it like any other post. That is, in your handler, read from the http.request.Body. Read from it like you do from any ReadCloser. The fact that your data is immaterial to the post itself, as you get the byte string from the request body. From there what you do with it is up to you. Here's a good place to start: https://golang.org/pkg/encoding/csv/ 
What do you want? The server side (the handler), or the client side (the uploader)? &amp;#x200B; The simplest is without multipart/mime-data encoding, just direct upload as text/csv: set Content-Type:text/csv and provide the content as-is. &amp;#x200B; For the client side, I suggest [https://github.com/mholt/curl-to-go](https://github.com/mholt/curl-to-go) as a starter. &amp;#x200B;
just the server side handler
I searched _“golang upload csv file”_ on Google [1] and found this [2]. [1] https://www.google.com/search?q=golang+upload+csv+file [2] https://astaxie.gitbooks.io/build-web-application-with-golang/en/04.5.html
It's a built in function
To answer your question, try applying the Decorator design pattern https://en.m.wikipedia.org/wiki/Decorator_pattern
What happens when I "cast" a struct as an interface? It's not really converting the bytes to a new type since the interface works with the same underlying struct as before
Why should they have introduced casting just for runes? 
There are no "casts" in Go. That is something you simply cannot do because there is no syntax to do dis that would compile. It is literally impossible to "cast a struct as an interface" in Go.
First thing to note is: The import path is just a string, no magic here. Really just a string which identifies a package. No remote, no github, no local, no nothing here. Just an identifier. No comes some tooling in the form of the `go` tool (what you invoke like `go get ...`, `go build ...`, etc). This tool can work with package identifiers which start with a hostname (roughly, just to get you the idea) and download a package from that host. For a few common code hosting sites (github is just one of several) the tool knows directly how to get the code. For unknown hosts (e.g. gobot.io) the go tool query the host on how to download the package (see Bappdekkel's or jediorang's answer for details).
No, I’m against using these kind of packages and agree with a lot that has been said already. In almost all cases using simple sqlx is as readable and doesn’t incur any performance cost on the app. As a starter who is familiar with SQL, sqlx should be easier to use than learning Ozzo/Gorm/yourfavdbpkg as they all come with an opinionated API.
Come on... If you're correcting me, it means you understand what I initially meant By asking this I already admitted not understading how it works Simply repeating what the guy above said in a different maner is not helping Here is an example of what I'm talking about https://play.golang.org/p/ooDH76sUVRs
Sometimes it just says: this package is stable :-)
This is hopefully, what you're looking for, I've been using it for a few weeks now and it's great :) : https://github.com/gomodule/redigo
If you print the pointer to `myStruct` and `myInterface` you can see they are are actually stored in two different locations. When you're "casting" (it's really a conversion) `myStruct` I *think* what is actually happening is that you're creating a new representation of the data explicitly stating that `myStruct` conforms to `myInterface` where the data is a pointer to `myStruct` and the method set of is that of `myInterface` (you're doing an explicit conversion rather than relying on the compiler to verify that `myStruct` conforms to `myInterface`) &amp;#x200B; [https://play.golang.org/p/cLbSa4vT4cM](https://play.golang.org/p/cLbSa4vT4cM) [https://golang.org/ref/spec#Method\_sets](https://golang.org/ref/spec#Method_sets) [https://golang.org/ref/spec#Conversions](https://golang.org/ref/spec#Conversions)
Slice of runes sounds like a great series
I think an interface reference is essentially a tuple of (actual type, implementation table, address of value). During a cast, you drop the strong, static type in favor of a type *value* and the interface implementation. This is all speculation. And influenced by what I know about C++ vtables.
To convert to an interface maintains the type of the original value: https://play.golang.org/p/6grLH7Wd1fR
They are a Linux only thing and that level of abstraction is adding a huge developer tax on then having to maintain the codebase for something that's easily explained inline in code. It's a form of context switching.
Merge the first two and you're correct (ignoring optimizations about what's allowed to be the value). See: https://research.swtch.com/interfaces Go/Rust have "fat pointers", while languages like C++ or Java have vtables.
And of course it's by Filippo. The guy is awesome. :)
1. If you're going to proceed with traditional REST APIs, I prefer using [http://www.gorillatoolkit.org/](http://www.gorillatoolkit.org/). 2. If you have a cluster of microservices, but only one of them is client-facing, I really suggest you use gRPC. That's a life-saver when you're jumbling around services and forget to update one of the JSON keys 😩 3. For Kafka, the best client I've used is from the folks from Confluent - [https://github.com/confluentinc/confluent-kafka-go](https://github.com/confluentinc/confluent-kafka-go) 4. [TravisCI](https://travis-ci.org/) anytime. But if you want the jingles of Kubernetes. go for [Codefresh](https://codefresh.io/)
TL;DR: I wanted to run complex P2P Go code on Android and I wanted to make a React Native UI for it. Turned out it's a lot harder than I expected, so I made a library to bridge the two worlds in a secure but seamless way :) Feedback welcome!
&gt; Wait, so what does Rob mean when he says “In Go, a string is in effect a read-only slice of bytes. ” in https://blog.golang.org/strings ?Or are you just saying they’re not of the same type?ReplyGive AwardsharereportSave They are not the same type. They are "in effect" a read-only slice but in fact, they are completely different types.
Honestly, I hate the `(Type) value` casting syntax. Leads to the problem that, if you have an object whose member you want to access, you always need an additional pair of brackets: `((Type) value).member`. In comparison, `Type(value).member` is much easier to read and write.
You playground code has nothing to do with strings and runes. What you do in your playground code is an obfuscated assignment of struct value to an interface value. Your `myInterface := MyInterface(&amp;myStruct)` is just an allowed way of writing `var myInterface = &amp;myStruct`. The first bullet point in non-constant conversions in https://golang.org/ref/spec#Conversions allows this type of conversion. The original question is covered by the last bullet point. The whole question boils down to "Why does Go not have C-style casts of the form `(sometype)somevalue` but only conversions of the form `sometype(somevalue)`? Why is the syntax different? And this I do not know. I think C needed the braces around the type for some technical reason, C could not use sometype(somevalue). But sometype(somevalue) is much more sensical so Go, freed of the technical issues which required the braces in C chose the later. 
The first is a function. The latter is a cast. It's not a new feature
Thank you for your interests!
Can someone explain what the Go Module Notary is?
see this blogpost; [https://blog.golang.org/modules2019](https://blog.golang.org/modules2019) especially the section titled: \`Module Authentication\` &amp;#x200B; Also see this video: [https://www.youtube.com/watch?v=\_wXf5Oixz28](https://www.youtube.com/watch?v=_wXf5Oixz28) especially starting at minute 4 to about minute 10. Also relevant: 1. [https://research.swtch.com/tlog](https://research.swtch.com/tlog) 2. [https://www.certificate-transparency.org/](https://www.certificate-transparency.org/)
[removed]
[removed]
&gt;Now there are two major approaches to deploy the content: &gt; &gt;\* Serve HTML/CSS/JS with an embedded HTTP server &gt; &gt;\* Injecting HTML/CSS/JS via the JavaScript binding API Would it be possible to serve/inject CSS and JS parts of a front-end framework, or the complete front-end framework ? Preferably the whole framework, but only once at startup, for all screens. &amp;#x200B;
\&gt; Slice of runes sounds like a great series I imagine a gardening and home improvement series, set in 10th century scandinavia.
They do use the same memory layout though, which does let you do some... interesting things in the name of efficiency.
Thanks :) 
I'm using goqu at the moment, and compared to working with strings, it's a _lot_ easier, and cleaner using goqu. I've been able to write many more general-purpose useful functions for SQL that have just cut down the amount of code I have to maintain and ensured problems are approached consistently. If you don't have very dynamic queries, then strings are fine, but if you need to build them up based on different options, etc. then using a query builder to dynamically build it does make it far easier IMO. String concatenation can get a bit tricky; did you put a space between that keyword and that identifier when you concatenated them? You need commas there but on the last one? These are problems a query builder easily solves, and as long as it's got some good tests you can be confident that it works.
((Person) thomas).address Person(thomas).address The second doesn't look like carrying but looks like calling a method or looks like calling a constructor. It'll confuse folks.
I agree with you that the close resource is something that is missing I will add it soon, the min and max was something I considerer but left out for now. I will do some simplifications removing some channels. I am an Erlang developer just getting my feet wet in Golang in my free time :)
i completely understand but i think this information muddies the water for the novices here.
The Go authors did not use casting syntax from C for conversions in Go because casting and conversion are different operations. As an aside, Go does not have casting.
Yeah, that's right: function calls and conversions now use same syntax. You suspect it could confuse you? Believe me, while writing Go, I was never confused. And frankly, I wonder under what circumstances there'd be danger of confusing functions (mostly called after a verb, like `create`) with types (mostly called after a noun, like `File`)..?
What about when I want to convert a int16 to a int32? In C this might not even be an assembly level operation, since it might already be holding the short/int in a 32 bit register or chunk of memory. Is Go smart enough to optimize out temporary conversions to larger representations, like C does with implicit casting?
Something like this https://play.golang.org/p/V_RahLfEFSe
I'm not a game Dev but I've been following this and `faiface/pixel` for a while out of interest. Super cool project, thanks for all the time you're put into it! 
Am I the only one who just wants a normal, simple, processing style graphics library for go? All the graphics libraries out there seem to overcomplicate things.
Sounds cool. I'll check it out.
Same! I've never written a game and keep failing to make the time to play around with something, but both these projects have fantastic dedicated caretakers that are very interesting to follow. :)
Pretty sure lots of conversions are free (or at least negligible): &amp;#x200B; type MyString string var s string = "hello, world" var ms MyString = MyString(s) &amp;#x200B;
[removed]
and in the case that there is no such nice URL, one can also link to the git repository directly, being an address ending in .git.
Why websockets? https://github.com/abenz1267/cachy/blob/90d23ea5e0a40df2d36a975e09df87e13808bc73/cachy.go#L218-L230
if that's the case, you're free to write your own lib, mainly if you know in which parts they "overcomplicate"
I probably will honestly.
I am not using this plugin in my self yet, because it isn't supported in neovim yet. So i just have a neovim terminal session where i run \`dlv\` directly from the cmdline. My suggestion might be obvious, but i dont know how you do it: 1. Create a new very simple project with only a \`main.go\` file setting a variable and printing it. 2. See if \`:GoRun\` works, the run command from \`vim-go\` 3. Now run a \`GoDebugBreakpoint &lt;line nr where you declare variable&gt; 4. Run a \`GoDebugStart\` If that doesn't work, i suggest you open a issue on their github profile
The article is mostly about why I believe copyleft is bad. It's an opinion. Not a dry technical analysis of all kinds of licenses and their differences on the legal system. &amp;#x200B; I based this article on a letter I wrote to persuade against a license change (from BSD to LGPL) as a stakeholder of a particular Go project (I wrote about 99% of the code).
Like other people have said, there's not a great reason to do this in production, but fun for experimenting. If you really had expensive queries, you can also just cache them in MySQL itself, the same as you would redis. It's super fast as a key value store and keeps you from having to manage a separate piece of infrastructure.
Hey, Just wanna say that it always brightens my day when I see one of your posts here. I love it when people actually stick to their projects and develop them for a longer time. (Also I love the name 'beep' it was just a silly suggestion by me but i am glad you chose it ;))
Looks interesting. But why did you decide to create your API over HTTP calls? Couldn't you create a React Native module with some Java code and then call your Go code from there? Or am I missing something? :)
There is strong use of In Memory Grids in the sectors that require scaling far beyond that of any database (sql &amp; nosql). For those that haven't worked in production telco/banking/trading/gaming/etc it comes down to making the network the bottleneck. Any solution that uses files becomes the bottleneck (int 21 services are painfully slow in comparison to backplane \[bus, memory, cpu\]). Given go's performance goals it is well suited for In Memory Grids. Redis has good support found here: [https://github.com/go-redis/redis](https://github.com/go-redis/redis) Now going down that rabbit hole you'll want to pay attention to three things with respect to scaling: 1) eliminate network calls entirely (near or edge caching / redis &amp; memcache don't have this / you can build it with go by using a map or use hazelcast's near cache) 2) eliminate network calls. The fact that you are going to copy the data from another location means more network calls. So it's best to colocate processing, like financial antifraud rules or game collision detection with the data In Memory. Again here is where hazelcast allows you to run serverside code that both redis &amp; memcache lack. 3) reduce the size of the payload on the network. Nothing you do will have more impact on the performance of a distributed system than the serialization you employ. Profiling is the only way to determine the best results here. And yet Hazelcast has strong go support too: [https://github.com/hazelcast/hazelcast-go-client](https://github.com/hazelcast/hazelcast-go-client) Hope this helps
Well, I couldn't tell from reading the README or the documentation that it supported precompressed files at all, so the docs could use some work.
If you just think of Person as being a built-in function which returns a Person with the same value as its argument (for suitable values of "same"), then it really doesn't matter whether you confuse casts with functions or not, does it?
Parent Comment Here \^\^\^\^
Software engineer working for a couple of years on a project almost by myself (say, I created the architecture and wrote 95% of \~50-70k loc). Repository was set from public to private after a year. A year passed by and a decision for opening it up was made, but the licensing counsel asked for a license change (from BSD to GPL). I disagreed with this decision and shared some data (this post is basically based on the data I acquired in late 2017 with a few missing). Not included, as an example, I show that all our competitors use MIT, Apache, or BSD for the same line of work. &amp;#x200B; I understand why some businesses decide to use AGPL. However, I am against it both for technical reasons and for principles. While I didn't express much my ideas on the IP matter I provided a couple of links on the second paragraph that corresponds to my idea on the subject.
I didn't talk much about the Apache license because I see it as just an overly complex permissive license and my goal here was not to analyse all possible licenses. &amp;#x200B; Am I talking from the point of view of a consumer rather than a creator? Not at all. Regardless, we are mostly consumers anyways. We all are. While we create one of two things, we usually consume many others. It's no different when we talk about libraries. You may write a library that even doesn't use anything else besides a standard library, but you can only do it thanks to many other people who made hundreds of other libraries and programs available. &amp;#x200B; Just to make it dead clear: I'm not saying you shouldn't make your source code private or work with closed source development. &amp;#x200B; [https://www.youtube.com/watch?v=IYO3tOqDISE](https://www.youtube.com/watch?v=IYO3tOqDISE)
A `string` is *neither* just arbitrary bytes, *nor* UTF-8 (or some other unicode encoding). It is type that is stored as a bunch of bytes (hence random access), but offers some operations (e.g. `range` and the mentioned conversion to `[]rune`) that assume UTF-8. It also differs significantly from `[]byte`, in that it's immutable (and thus also has no `cap` or `append`) and offers `+`. So - you are *in essence* correct, that a `string` is stored as a bunch of arbitrary bytes. But whether it's used that way, or as a UTF-8 encoded text, depends on the operation you are using on it.
What about unsafe?
Thank you :) I, on the other hand always appreciate interacting with the community :)
Also see the reddit threads for that blog post. https://www.reddit.com/r/golang/comments/a7ngj2/go_modules_in_2019/ I personally find the notary (and the published proposal) pretty spooky, especially the immutable nature of the logs which assumes devs will perfectly adhere to "best practices", never delete or recreate repos, mistag versions, force push, create a new github account with an existing name...
Why do you think copyleft is bad?
&gt; Am I talking from the point of view of a consumer rather than a creator? Not at all. I disagree, there's nothing in your article about why a particular license benefits the creator. It's all about downstream consumption.
All good. I'm not trying to discourage you as a newcomer. It's really awesome that you are being so productive in a new language. I only meant to comment specifically on the project on its own, as an offered production solution, and to get a more detailed explanation on why someone should pick this up as a dependency in its current form over writing the equivalent worker code. Good luck on your Go journey! 
Ooh sweet! Ive not done front end game stuff with Go yet. I'd love to see a library based on C# monogame/xna, bit goified.
I'm finding it really hard to like the idea of an immutable "notary" keeping track of all of the versions of every public Go repo. It really feels like this, along with enforced semver and versioned import paths, assumes a perfect system with developers who never make mistakes, and code that is always compatible. I gave this example the last time the notary thing came up: I forked someone's IRC library, then made some modifications. Later, I deleted that code. A few years later, I made a repo with the same name, API incompatible, but written the way I wanted. If the Go notary had existed back then, then all of the crap in the fork would be locked in place, including any tags that the fork would have had from the upstream or I created. If it had a version tag, then the sum wouldn't match on the new repo if I tried to version it and import it. Things would break, all because of a throwaway project. I can't imagine wanting to make _anything_ unfinished public for fear of wanting to delete and redo it later, (especially if the Go tooling always contacts the notary, which means just looking at my repo's godoc.org would break things, something I do now as local godoc doesn't work with anything outside of GOPATH). Also take the go-bindata problem, where the owner dropped off the face of the planet and deleted their account. Someone else recreated it, pushed the exact same repo (so the exact same sums) and then a few more commits. The extra code wasn't malicious, but it could have been. It just seems like all this stuff is being shoved in all at once. I like that my dependencies can be managed without external tooling and outside of GOPATH, and all of the upcoming stuff like `std` itself being a module, but there are enough oddities to make me uncomfortable... I don't want to try to argue this with a form of "perfect solution fallacy", I'm just concerned.
&gt;I forked someone's IRC library, then made some modifications. Later, I deleted that code. A few years later, I made a repo with the same name, API incompatible, but written the way I wanted. If the Go notary had existed back then, then all of the crap in the fork would be locked in place, including any tags that the fork would have had from the upstream or I created. If it had a version tag, then the sum wouldn't match on the new repo if I tried to version it and import it. Look at it from the point of view of any users of your package. If they stumbled across and decided to start using v1.2.3 of your public fork, what happens if you force push a new v1.2.3 later? The code they thought they were using changes underfoot. Worse, this kind of replacement is essentially indistinguishable from an attack, like the [event-stream attack](https://research.swtch.com/deps#watch_your_dependencies). In that case the inability to force push the tag meant it had to use a new tag, which at least reduced the exposure for many users. One mitigating factor here is that with modules, any old GitHub fork does *not* work as an importable module. If the original said `module github.com/me/pkg` in go.mod, so will the fork, so importing the fork from `github.com/you/pkg` will fail. The same would happen if the code had `// import` comments. So your fork will *not* end up in the notary or version-constrained, unless (1) it is a fork of pre-module code without `// import` comments, or (2) you explicitly modified `go.mod` to allow importing using your github.com path. And note that (2) is *not* required to refer to a fork in a module `replace` statement. The vast majority of forks of modules will not modify `go.mod` and will therefore stay out of the notary's logs.
I just posted [https://golang.org/design/25530-notary](https://golang.org/design/25530-notary) a few hours ago. Before that, [https://blog.golang.org/modules2019](https://blog.golang.org/modules2019) was the best information. &amp;#x200B;
I expose some reasons why this benefited me (as a software engineer) at this comment here: [https://www.reddit.com/r/golang/comments/avisq9/opensource\_and\_go\_what\_license/ehs5kj5/](https://www.reddit.com/r/golang/comments/avisq9/opensource_and_go_what_license/ehs5kj5/) &amp;#x200B; Also, I tell that if you are a company looking for developers to join you (or any similar situation) it would be easier to find more people willing to join you if you use a permissive approach, especially if this is what the market for your product prefers - meaning your developers are not in a situation akin to 'vendor lock-in'. If they want to do a side project or maintain a library other people can use, they are not forbidden from reusing useful parts of your code, etc.
There are a lot of companies using Redis as a cache in front of MySQL. Simply because that’s what redis is made for. A lot of times MySQL is faster without a query cache. Redis also supports memcache protocol so you get extra functionality when you upgrade to redis.
I played the hell out of that tetris web demo lol
And use pipelining with Redis to reduce network overhead.
Instead of a map you could use [golang.org/x/sync/singleflight](https://godoc.org/golang.org/x/sync/singleflight) depending on what do you want to "cache"
Have only run it on Windows, but I haven't experienced any performance issues in the demo or my application.
Forgive the following braindump and likely the negative impression I'm giving... this all has just been on my mind since the original blog post, and my recent experiences migrating projects to modules have been mixed (especially my largest project which imports Docker...). I understand that force pushes could and probably should be seen as attacks, and I agree that protecting against them would be good, it just feels like the punishment for making a mistake (or simply being inexperienced) is overkill - some external party is watching everything going on and then prevents your package from being used. Beforehand, it's very possible that nobody except me ever sees or uses my repos; I can do whatever I want with them without trouble, fixing my mistakes as I need. With some external thing you can't opt-out of (the Go tool would contact it, godoc.org, etc), that freedom is lost. Go's lack of a centralized place for packages can be a downside, but is also an upside because of that lack of control. My library fork example didn't/doesn't have a `go.mod` (it was 2015), so if I hadn't deleted it before modules, then all of the tags on the repo would have been there and picked up by the go tooling, right? Also note that my fork was of another fork, where everyone down the line was changing the `// import` comment to point to their own forks so they could use them. My code was never merged back into the original project, so I lost interest until relatively recently and wanted my new project to have the name "irc". Ignoring my specific example of a fork, how would things play out with independent throwaway projects? If I write some experimental junk now with a "nice" package name, version it v1.0.0, then delete it later on and come back a while later and want that package name, there's no clean way for way for me to continue. Sure, I can start adding `v2` to everything, which I think would work even if the git histories are completely different, but at the cost of being weird (start my project at v2?) and excluding users without `go.mod` (golang-migrate has this issue because they were forced to go up to v4 due to their existing git tags, making all code above a specific version unimportable from non module repos). If you're making something you're hoping people use and plan to support fully with backwards compatible changes or version bumps, sure, things work out, but if I'm hacking on something and don't want to provide support, the notary is going to be locking things down. Maybe this all isn't a big issue if you don't care about the way some particular code is imported (don't mind v# all over the place) or have control over the naming of a project, but if you're implementing some spec like IRC and name your package "github.com/username/irc", hopefully you can see why it bugs me. Marginally related, but how will a singular, immutable notary handle issues like those created in Go 1.11.4, where sums were generated incorrectly and manual intervention from users was required?
I'm using github.com/rubenv/sql-migrate Used for postgres migration, simple and effective. 
&gt; I expose some reasons why this benefited me (as a software engineer) at this comment here. No you don't, the only reason you give in that comment is that your competitors use those licenses. Copyleft licenses would also allow your employees to reuse code in side projects. You have not given any reasons why copyleft is bad for a creator.
Sure! Give me feedback if you want!
Im using pop by markbates / gobuffalo. I like it a lot and it hasn't let me down so far!
I’d play that 5e module 
“Go has no functional approach” Whiskey tango foxtrot There are literally no objects in go. 
PHO still knocks it our of the park for rapid prototypes which can evolve into large scale applications. 
How so? Can you elaborate? Go’s enums come from its C heritage, where you didn’t have enums and kind of rolled your own by defining integer constants. You could then take those and, say, use them as indices in a jump table (an array of function pointers) to get dynamic behaviors for each enum option. Java ran with that by using its built-in object method to create a kind of enum that I would call very “fat”. Go doesn’t have the fat enums, true, but it lets you give them integer-based types, and give those types methods. 
Huh, TIL. Awesome!
Wat
This single question is the foundation of most of my side projects 
Thanks for reviewing. Unfortunately, the code isn't mine.
What do you mean? If you have a different idea on how to signal your browser that he needs to reload on file change... Feel free to tell me. 
The typical structure is to place your binary-producing packages under a `cmd` directory, ie `./cmd/master` You can run tests recursively on a directory using `go test ./cmd/...` (`...` is the recursion trigger) You can run all .go files without using `go install` or `go build` via `go run ./cmd/*.go`
Look at the source of Go itself. All tools are organized under `cmd` folder with each tool living in a sub-folder named as the tool and the main file there named `main.go`. You can typically build all using `go build ./...` but, I believe, `go build cmd/...` should also work.
Very good. I did not expect to learn much, but I did. Clean design as well!
Except your employees might have reservations against doing so, especially in case of a Go library as it would likely not be useful for most Go projects due to the linking issue I showed.
It's like a Union type which has it's own type. The problem however lies that without match statement enums are not as useful as they could be.
So Rust isn't the most functional language either, but it does have default immutable which might be what this person is referring to. The term "functional" is a broad term, and a gimmicky term currently, and includes many practices, and I agree that Rust is a more functional language than Go is, but it's no Haskell either. About Object Oriented being broken.. I don't see it. If he is referring to Generics (that Rust has), than he probably needs to word his argument better. Overall, Rust has more features IMO than Go, but it also requires more time to get it out the door. I am seeing my time coding Rust to be 2x to 3x what it would take me for a similar project in Go. So its boringness might be a feature.
[removed]
How is it not useful? It just means they'd have to release their project under a GPL license. Everywhere I've ever worked has been entirely closed source so that's still a huge win.
[removed]
How will this work with proprietary Go code bases? I do not want to expose anything to a public ledger about my private repo. Please enlighten me.
One option would be to go with a single binary and multiple “subcommands”. One way to implement this is through https://github.com/spf13/cobra
I'm using skeema https://github.com/skeema/skeema it calculates a delta between your scheema definitiona in files and what the db actually has them only pushes safe changes to your db.
&gt; one spot that really hits me hard is enums yes &gt; Am I just missing something no &gt; Enums in Go seem unusable for the most part. kinda There is two ways to do enums in Go, one is failure prone but simpler and less boiler-platy than the more robust method. ### integer constants and the `iota` keyword https://play.golang.org/p/VXQKrl4GNut type myEnum int const ( VariantA myEnum = iota VariantB VariantC ) func CheckThisEnum(m myEnum) bool { switch m { case VariantA: return true case VariantB: return false // note here that the compiler won't verify you checked all cases } panic("oops") } var _ = CheckThisEnum(4) // this works from outside of the package, and causes a panic var _ = CheckThisEnum(VariantA) // == true // etc ### (ab)using interfaces to provide discriminated-union like capabilities https://play.golang.org/p/LNiQvRJ8abm type SlightlyMoreRobustEnum interface { methodThatCanOnlyBeImplementedWhereThisEnumIsDefined() } type VariantA struct { // put variant specific fields here } func (VariantA) methodThatCanOnlyBeImplementedWhereThisEnumIsDefined() {} type VariantB func() bool func (VariantB) methodThatCanOnlyBeImplementedWhereThisEnumIsDefined() {} type VariantC int func (VariantC) methodThatCanOnlyBeImplementedWhereThisEnumIsDefined() {} func CheckThisEnum(m SlightlyMoreRobustEnum) bool { switch e := m.(type) { case VariantA: // 'e' can be used here return false case VariantB: // etc return e() case VariantC: return false // again, compiler won't check for exhaustion of cases, // but as long as you keep the switch up to date it's not possible // to hit this panic from outside this package } panic("oops") } var _ = CheckThisEnum(44) // will not compile var _ = CheckThisEnum(VariantC(44)) // should == false var _ = CheckThisEnum(VariantA{}) // should == false To summarize, i think enums could use some improvement for Go 2: - No exhaustiveness checking on `switch` statements means they are brittle in the face of change (especially in a large codebase) - `iota` based enums are limited and prone to breakage from outside package boundaries - `interface` based enums make me cry a little inside. Why? - interface/type switching overhead - boilerplate (which is fine in automatically generated code like protobufs but manually writing it is a pain) - only provides safety across package boundaries, because... - it's essentially just a hack based on package public/private namespacing rules
What's wrong with boring? Boring technologies work. Boring technologies are easy to understand. Boring technologies are easy to train and find people and maintain. &amp;#x200B; I don't want to work with people who want their tech to be exciting. I want to work with people who create understandable, maintainable code. &amp;#x200B;
&gt; We are concerned primarily with authenticating downloads of publicly-available module versions. We assume that the private servers hosting private module source code are already within the trusted computing base of the developers using that code.
subtests is one of my favorite features in Go's testing package, you really should try it. 
Ha, that definitely made me laugh. GitHub and the like are Unicode-"safe", so the description could just use the actual emoji sequence (`🤖`) instead of `:robot`.
Hi! I would love to see how subtests can help implement multiple `TestMain` functions. However, after reading the entire SO thread linked above (including their chat), I think they confirmed that subtests are not that applicable to this situation. Do you have any ideas on how they can help? And many thanks for replying!
If you mean: type myStruct struct {} func (myStruct) method() {} var x interface{ method() } x = myStruct{} That isn't a cast, it is plain variable declaration and then assignment. `myStruct` is [assignable](https://golang.org/ref/spec#Assignability) to a variable of type `interface { method() }`. 
Yeah, strictly speaking, Redis itself is not reliable. It would be better to say "Redis streams is more reliable than Pub/Sub", see [Motivation](https://github.com/RussellLuo/rpubsub#motivation).
We use liquibase. The schemes are put in a standalone repository.
&gt; In the past weeks I talked to a rust developer, who thinks Go is a boring language with super old concepts. In my experience, Rust developers are the proselytizing vegans of the programming world. The "[Rust evangelism strikeforce](https://www.reddit.com/r/rustjerk/)" is a thing for a reason. While I am not saying he has an argument, the fact that he self-identifies as a "Rust developer" would already make me slightly skeptical of his arguments.
I actually agree that Go doesn't have many new fancy features, other than CSP. This is exactly why: 1. Go is easy to pick up; 2. Idiomatic Go code has great readability. In addition, what I really like about Go is not the language itself, but the ecosystem. &amp;#x200B; I think being boring is fine for Go. I believe the goal is to get things done, rather than get fancy. &amp;#x200B;
Also researching this. Is Gin still a solid choice?
First thing, `TestMain` only run once, instead of for every test case it runs, you can confirm this behavior with the following code: ``` $ cat go_test.go package main import ( "fmt" "os" "testing" ) func TestHelloWorld(t *testing.T) { t.Log("HelloWorld!") } func TestFoo(t *testing.T) { t.Log("Foo") } func TestMain(m *testing.M) { fmt.Println("before!") ret := m.Run() fmt.Println("after!") os.Exit(ret) } $ go test -v before! === RUN TestHelloWorld --- PASS: TestHelloWorld (0.00s) go_test.go:10: HelloWorld! === RUN TestFoo --- PASS: TestFoo (0.00s) go_test.go:14: Foo PASS after! ``` So for sub tests, it's kind of the same as `TestMain`, that you have two test functions, `TestApple` and `TestBanana`, do initialization, and then run all actual tests as subtests: ``` func TestApple(t *testing.T) { appleInit() t.Run( "apple_test_1", func(t *testing.T) { // actual test code }, ) t.Run( "apple_test_2", func(t *testing.T) { // actual test code }, ) // other tests appleCleanUps() } ````
This has been asked a lot. Please do some searching. 
Parity Ethereum client.
Cloudflair's user-facing firewall configuration also has a rust backend. I've been looking for examples and they're definitely out there. I'm starting to think I was wrong about rust.
its pretty bad. They do a lot of code generation for some SDKs, so you get WEIRD APIs.
Seems mostly accurate. Those are Go's selling features. Are those not the very reasons why you were enthusiastic about Go?
Faiface's pixel library is fantastic
[removed]
&gt;Ignoring my specific example of a fork, how would things play out with independent throwaway projects? If I write some experimental junk now with a "nice" package name, version it v1.0.0, then delete it later on and come back a while later and want that package name, there's no clean way for way for me to continue. If it's really experimental junk, tag is v0.0.1 instead of v1.0.0, or don't tag it at all. And then when you come back with something nicer, use v0.1, v0.2, etc, until you want to push something out that you want to commit to as far as API. Just don't reuse tags. And if you're super, super sure no one is using it, then even deleting an old v1.0.0 is not really a problem. You can't ever replace the expected go.sum lines for v1.0.0, so you can't redefine the v1.0.0 tag, but you can delete that tag and history and push a new history with a new tag, say v1.2.0. &gt;if I'm hacking on something and don't want to provide support, the notary is going to be locking things down. It's making sure no one downloading v0.0.1 or v1.0.0 from your repo gets one set of bits today and another set of bits tomorrow. That's all it does. As soon as there are multiple possible bits for a given module, version pair, tons of things stop working nicely, like reproducible builds, proxies, and so on. What you think you are doing in private is not really private once other users are involved. You can do literally anything you want, including deleting tags and the commits they reference, with the one exception that you can't redefine a tag. &gt;Marginally related, but how will a singular, immutable notary handle issues like those created in Go 1.11.4, where sums were generated incorrectly and manual intervention from users was required? That was a mistake, should not have happened, and will not be repeated. My apologies. The sums are what they are and will never change again. We have the flexibility to introduce a new sum algorithm (s/h1:/h2:/) if needed.
Not sure which part you’re disagreeing with. 
If you need to transform the data in the process I suggest write your own migration tool with gorm. It is an orm. [http://gorm.io/](http://gorm.io/) 
yeah
Echo was a nice light weight framework. Echo is pretty much another version of Gin. Gin and Echo both require you to choose your stack, orm, log tool, config tool. [https://github.com/dorajistyle/goyangi](https://github.com/dorajistyle/goyangi) is a good example for Gin. I have a echo boilerplate ready soon once I finish adding graphql support. &amp;#x200B; If your team want something quick like RoR, an all-in-one solution, use Beego. It's bulky and slow sometimes, but the development speed is good, community is active. &amp;#x200B;
That's a really good point. I haven't looked at it from that perspective yet. I also think it's nice and good to have a super fancy language, but if the ecosystem around it isn't good it doesn't help.
&gt; slice of runes But we can also read `rune[]` as a "rune slice". Am I missing something here? You are right though that Go's syntax makes casts look like function calls.
For a fistful of runes...
I‘ve used this one: https://github.com/pressly/goose
Thanks for the response; I appreciate it!
Get things done in a robust, reproducible, and easy to maintain manner.
[EventSource](https://developer.mozilla.org/en-US/docs/Web/API/EventSource) or HTTP/2 is also an option I guess
\&gt; First thing, `TestMain` only run once I can't believe I didn't realize it sooner. Many thanks for clearing this up and the sample code as well!
I will look at event source. Thanks. 
*YOOOOOOOOOO!!!!* It's your **2nd Cakeday** jadeydi! ^(hug)
Ebiten is very simple and straightforward.
 Its blowing me away the responses in this thread. Please, do use some front cache server over MySQL in production. I highly doubt anyone commenting otherwise actually runs a sizable system, nor seems to care about performance. &amp;#x200B; Just a few absolutely massive reasons to use Redis in front of a production database: * Databases usually are not on the same machine (security, scalability and more ram access for the DB), while a redis server can be. You will get faster responses accessing a server on the same machine than a database on a separate system. * Redis uses both an in memory and paged cache mechanism, allowing redis to scale horizontally INCREDIBLY easily. Have fun doing this level of scaling efficiently with a database. * If you're not hosting your DB (azure or some other service), then you will massively reduce the costs for month to month, as your DB does not have to keep as many execution plans in memory, as well as just in general WAY less trips to the DB. * Redis removes a large problem of locked tables for constant changing data. Cache isn't only good for data that hardly changes, assuming you don't need fully live data (most things dont), it's much easier to allow the data to constantly change and only periodically update the cache. &amp;#x200B; Please, do use a separate caching mechanism. There are probably even way more reasons than I stated above why, I have no idea why this sub is suggesting otherwise. It is an INCREDIBLY useful thing to do, for both small AND large services. Better scaling for large services, cost saving for smaller. There is literally no reason not to, it is not hard to do.
Go has objects. We just usually avoid the term in practice because of the misconceptions most devs hold to regarding behavior sharing and it's tight relation to taxonomic origin. Please see this talk (press "n" for presentation notes): https://meetup.euggo.org/talks/objectively_harmful/objectively_harmful.slide
Be enthusiastic about a choice you made. If somebody starts a pissing contest, let him/her. It's not about winning the contest, it's about what you can do with it. And I'll bet, that when you're enthusiastic, you can move mountains.
Thanks for your help
Nice, thanks. Any suggestions on auth set-up? I want to avoid JWT 
Ah yes, there is a catch :) Originally I also used gomobile + Java API calls through native libraries. The annoying-but-solvable issue is that if your Go library changes a lot (i.e. heavily under development), then every change entails reworking the CGO bridge, reworking the Java wrappers and the React Naive module. Doable, but painful. A more problematic issue is that you are very very limited on the types you can expose from Go to Java, so you need to jump over a lot of hoops to get your high level types across. Same happens when going from Java into React Native, making things messy. The deal breaker however is that if you want to use images in React Native served by Go, you're in a huge pickle. All RN image tags can have either file or http urls as the sources. If you cannot serve the images via HTTP, the alternative is to get it via some other means and inject them in as data urls, but those will murder performance instantly.
https://github.com/ribice/gorsk
looks great, apart from it uses JWT auth D: haven't read great things about using JWT for sessions in production.
I will definitely write about that in a future post. Thanks.
You could make it a tiny bit simpler IMHO by using: fmt.Fprint(w, "hello world")
Right. Shall do that. Thanks.
Yup, I avoid JWT in prod projects. But for example project it was the easiest thing to implement without introducing more dependencies.
What do you tend to go with when you implement auth on your prod projects?
Store sessions in an in-memory database (mostly Redis), encoded in gob/msgpack and fetched in middleware by authorization token.
&gt; Go’s enums come from its C heritage, where you didn’t have enums and kind of rolled your own by defining integer constants. C does have enums, which even if they're not type-safe a prone to issues can at least be spot-checked by the compiler: https://clang.llvm.org/docs/DiagnosticsReference.html#wswitch
You can even pass handler function as closure. package main import ( "net/http" "log" ) func main() { http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, "hello world") }) log.Fatal(http.ListenAndServe(":8087",nil)) }
If you want context you can have a return of responses in your handler like here. https://gitlab.com/zendrulat123/prettymiddleware/blob/master/server.go
You can trim it some more and write all of this in one line! func main() { log.Fatal(http.ListenAndServe(":8087", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, "hello world") }))) } 
Oh that's ugly code...
Yeah it is and it's content body only works in that request. But it does show an example of wrapping a handler for other handlers. Right now though I'm focusing on trying to combine types for consuming apis. Learning is always stacking.
Where to start.. * global error instance - poor race detector * db is connection pool, not single connection, so no need to open each request. * error shadowing * ignoring errors * hardcoded db credentials * use unsafe.Sizeof * don't understand why there is `ctx` parameter (shadowed and not used)
It's mock data..... All you need is the header info
let me google that for you ... oh.. it's here https://matt.aimonetti.net/posts/2013/07/01/golang-multipart-file-upload-example/
As an alternative you could consider an interface with multiple structs implementing it. You don't avoid needing an array of constants that way though and I think your current solution is more concise anyway When I find myself wanting something "better" it always seems the first problem is to define better. I think what you are trying to avoid is having to edit multiple things when adding enum constants. If that is the case I would suggest you consider code gen or reflection. If it is something else that bothers you let us know.
https://play.golang.org/p/BZVg6rMDYKf If your type is based on `int`, you can just enumerate over it using a for loop. And if you define your own type, you can define additional methods on the type. 
&gt; I think what you are trying to avoid is having to edit multiple things when adding enum constants. That's kind of the point. That and also I try to keep my code as clean as possible. I thought my implementation wasn't super clean &amp;#x200B;
I think the `allMyTypes` slice is unnecessary, since you can range over the map of additional info directly. It only would be needed if you wanted to have consistent ordering (since map iteration order is randomized). You could also define a `LastMyType` and iterate from first to that, but I'm not sure that's actually nicer to read at the point of use: [https://play.golang.org/p/Xw8eQPhHpGd](https://play.golang.org/p/Xw8eQPhHpGd)
Actually, after a lot of search, I found this post quite useful: &amp;#x200B; [http://sanatgersappa.blogspot.com/2013/03/handling-multiple-file-uploads-in-go.html](http://sanatgersappa.blogspot.com/2013/03/handling-multiple-file-uploads-in-go.html)
I had seen them. The first one is not useful, and the second is about a single file upload. 
If you're willing to give up on `const`, you could do it this way, which gets rid of the indirection through the map: [https://play.golang.org/p/Ezt3rDVdYWA](https://play.golang.org/p/Ezt3rDVdYWA)
What prevents you from adding multiple file inputs in the form ? &lt;input type="file" name="uploadfile1" /&gt; &lt;input type="file" name="uploadfile2" /&gt; or simply google "html input multiple file" and find this &lt;input type="file" name="uploadfiles" multiple&gt; Don't you want me to come and do the googling for you ? You didn't bother even to upvote my effort. Jeez, senior developer kids these days.. 
I like to call Go a really slick 1990s-era programming language. It takes decades of experience in this paradigm, and slices away what didn't work and adds some things that definitely do. It is most assuredly not cutting-edge tech as programming languages go. (I'm speaking only of the language itself. The runtime is definitely developing into something pretty advanced.) Among the things that it cuts away \_fully on purpose\_ is inheritance, which is considered by many people to be a bad idea. Object Orientation is such a fuzzy word that declaring whether something is or is not "object oriented" is really quite difficult, and it's an even bigger mistake to assume a moral stance based on whether or not it fits the definition. It isn't really an interesting point. Rust is definitely a different language, and IMHO I think one well worth learning. It complements Go nicely. Some Rust advocates... no, too specific... some \_$LANGUAGE\_ advocates think their language is the bestest at everything and any other languages simply must suck in every way. Rust has its fair share of those. But it definitely has some downsides to it as well. It is significantly harder to program in because of everything you need to do to make the compiler happy. It is absolutely true that as you gain experience in the language, it gets easier, but it never gets as easy as Go will be with the same level of experience. On the other hand, you get more out of what you put into a Rust program. There are many tasks I would simply not use Go for because you need that extra assurance a Rust program can give you. One of the reasons I use so much Go is that I use it professionally, where the fact the language is simpler is a \_huge\_ advantage. I can get developers up to speed much more rapidly, and the resulting artifacts are far easier to pick up and modify for developers. A Rust programmer will then argue that it is too easy, but, well, I got deadlines to meet, bills to pay, and an inability to do everything myself without also having a team helping me out, so here we are. But if a task ever comes up where I wouldn't trust Go to do it, Rust would be on my shortlist. The best way out of being \_that $LANGUAGE guy\_ is to go learn more languages. After the first 5 or 6, you really ought to be noticing that all languages have strengths and weaknesses. If not, well, I dunno what to say.
https://github.com/syndtr/goleveldb was a very helpful project back when there was only boltdb. https://github.com/siddontang/ledisdb was a redis-like store built on top of it that supports it as a backend. Glad to see the Cockroach team continuing to work in this space. As we've seen with SQLite and Localstorage, embedded data stores are really powerful for certain applications. 
The allMyTypes isn't needed, you could iterate through the map alone. Apart from that, for the specific thing you want, the simplest would be map[enumType]extraInfoType imo, which is what you have already.
CovenantSQL miners are most in China currently, and the forum is deployed in Singapore. The network delay is about 110ms, this is the main reason.
I found this video tutorial nice: [https://youtu.be/0sRjYzL\_oYs](https://youtu.be/0sRjYzL_oYs) 
With `go mod`, I'm not going to have a malicious patch accidentally added to my code (_thanks npm_). I would prefer one-or-more, optional module review systems/sites where I can check the status of the libraries (since I don't have perfect auditing skills). I would like to see consumer reviews and notes about projects. Who audited it last? What about the maintainers? How active is development? Are PR's welcome? 
Aether is interesting, the most significant difference is that Aether message is ephemeral, CovenantForum one is more like "covenant". Second, Aether has nice UI, CovenantForum is ugly...
Someone mentioned this as an option, but here's a concrete example using interfaces: [https://play.golang.org/p/beiaNFIoJPx](https://play.golang.org/p/beiaNFIoJPx)
A similar question was recently answered on SO: https://stackoverflow.com/questions/54989828/cannot-save-multiple-files-in-golang
Dont get me wrong, ebiten is an awesome library. But personally the whole everything is images is not my style and doesnt work well with my use case, which is computer generated art. Most of the time I'll just write it in glsl shaders but the times I need to use the cpu I'm stuck on processing which is also really awesome but fairly slow. Ideally I'd just use openframeworks but I really despise c++ and especially developing c++ on windows. Golang and processing is really the only thing I can dev on my own pc and keep my sanity. Even for python ill use a vps.
I guess what I should have said is that go is _consistently_ left-to-right, whereas reading types in a language like C (which I'm picking on for being really bad in this respect) is [a bit more involved](http://unixwiz.net/techtips/reading-cdecl.html). They could have made it right-to-left, which would correspond to "rune slice", the important thing is that it's consistent. In left-to-right, the modifier always comes first, so in the weird type: chan map[int][]*[]rune You can easily read this as chan: "channel of" map[int]: "mapping of ints to" []: "slice of" *: "pointer to" []: "slice of" rune: rune "channel of mappings of ints to slices of pointers to slices of runes" The type is stupid, but the type declaration is easily converted into english.
It might be overkill if you only have a handful of enum values, but a code generator could fit the bill.
I’ve implemented LRU caches before but never had to do LFU. The algorithm didn’t intuitively look right to me so I had to go do some more research. For anyone else that’s similarly thrown off, there isn’t a true frequency element in LFU (not just this implementation, in general). It’s typically implemented as simply “least used (of all time).” A known problem of the algorithm is that something accessed on burst for a short time, say a logo for a specific olympics, can get stuck in the cache functionally forever even though its frequency of access drops to near zero shortly after the event. 
This is for single file upload.
That is typically solved with aging by halving the frequency score every time period. In the article's case this could be to walk the `frequencyParent`, so a bit nicer as `O(k)` instead of `O(n)`. I think the author missed your observation on stuck entries, as he specifically states *LFU eviction approach would evict the assets that are not needed any more after the hype has settled*. As you said if the storm was really big, it may take a very long time before a larger storm occurs to force eviction. The age trick mitigates this fairly well.
How does this compare to bolt?
Is it possible to do something like this with iOS?
Read this: https://github.com/boltdb/bolt#leveldb-rocksdb
Use spaces for preformatted blocks in reddit: ./ ├── common │ └── structs.go ├── master │ ├── master.go │ └── test │ └── matcher_test.go └── slave └── slave.go
every `.go` file under the same directory should have the same package name (exception: `_test.go` files _could_ have a different package name). if this directory/package is a lib (no `main` function) the package name should be same (or very close to) the directory name. If this directory/package has `main` function then the package name usually should be `main` (name it something else _might_ work? I haven't tried that though).
If users need to give the access also to 3rd party services then I'd say that you should use OAtuh2
Like a lot of sources I've read this sounds very inexact. I've seen a few examples with package main with no func main inside and vice versa: package &lt;app name&gt; containing fund main. Forgive my exasperation :)
No, strictly a self-contained authentication system to protect user data from unauthorized access. That being said, I've not found much on implementing a stand-alone authentication/authorization solution in golang with oauth. All the docs I am finding refer to using google or facebook as the authentication provider, instead of doing that in-house.
&gt;I've seen a few examples with package main with no func main inside when you say `no func main inside` do you mean that single `.go` file or the whole directory? Either way it works, but if it's a lib but the package name is `main`, when you use anything from the lib you have to say `main.Foo`, which usually means the quality of the lib is low and you probably shouldn't be using it :)
Try this one: [https://thenewstack.io/understanding-golang-packages/](https://thenewstack.io/understanding-golang-packages/) 
I missed that, thank you!
You might like https://github.com/dgryski/trifles/tree/master/cachetest , my framework for exploring timing and hit rations for a number of different cache eviction algorithms.
Have you considered:https://github.com/dgrijalva/jwt-go
Isn't this explanation redundant since modules in Go 1.12?
Another way to do it, with more restrictions, is that you can have different package names for apple test and orange test. In go the test code doesn't have to have the same package name with the main code, for example in `foo.go` you have `package lib` and in `foo_test.go` you have `package lib_test`, and import your main code by `import "path/to/lib"` (they are still under the same directory). This way your test code can only access exported code by your lib, so you are actually mimicking a user to your lib, avoiding rely on any unexported part of your lib (essentially a more black box test). That doesn't always make sense, of course, and you are allowed to have some test code (file) using `package lib_test` and some test code (file) using `package lib` to actually test some of the unexported code. So for your use case, if you don't rely on any unexported code in your apple and orange tests, you could just have `apple_test.go` with `package lib_apple_test` and its `TestMain`, and `orange_test.go` with `package lib_orange_test` and its different `TestMain`. That _should_ work (I haven't really tried that, but I don't see a reason that won't work).
https://github.com/ory/hydra is great, but you have to develop your own consent and login endpoints, in order to link it to your user accounts.
I hope Golang one day implements enums like Swift does. With associated values. Much cleaner to define state.
I'm definitely leaning towards JWT as the authorization framework once users are "logged in", but I still need a way for them to log in to begin with :)
&gt; But files have main functions, not directories. Actually, a package can only have one main function, it doesn't matter if you have one big file or split it across several. You cannot have file1.go and file2.go with the same package name and the same function in both (a couple caveats, like init). So you can only have 1 main() in all of those files (all functions end up in the same package). You need to think in terms that a package is a set of files sharing the same package name. They are all combined into the same logical "thing". It doesn't matter if you have 1 file per package (and packages should be grouped in their own folder) or you decide to split the package up between several files so you can be more organized. On the other side of the compiler, it's all wrapped up into one package (i.e. mylib.MyFunction1()) If you want a binary executable and aren't sharing/publishing the code, then all the files in the same folder can be in package main. If you are using the code as a library, then there are other ways to organize the code so you can have an executable and library code in the same repo.
https://github.com/boltdb/bolt
I've resolved this for practical purposes by having only a single file - main.go under the project root directory. This file contains "package main" and "func main". Everything else goes in subdirectories where files contain "package &lt;subdir name&gt;". I still don't understand what "package main" really means since it seems to refer mainly to whatever contains "func main", ie. a file not a directory.
For a simple key-value store see bolt- or badgerdb. Use gob to serialize your objects. 