You do not want to quit emacs. Emacs is everything you need. There is a package for everything. Need an other program for the desaster scenario that there is no package for a task? Use exwm to open it inside emacs. NEVER quit emacs! 
Right now I have Emacs open, and any file I edit is opened with emacsclient. This is the first program I launch when I log in.
Thank you. Emacs-ish is more accurate. Emacs-ish (adjective): as a long-time Emacs user, my fingers know their way around this editor. I can get stuff done quickly with it. I do miss shells, comint, and the emacs-speaks-statistics (ess) modes though. Maybe someday...
I took the class and enjoyed it. It was a great intro to golang with the material presented very well. 
&gt; Mg is a lightweight public-domain Ersatz Emacs, dating back to 1986. **Mg was originally known as Micro GNU Emacs,** as it strove to adhere more closely to the default behavior of GNU Emacs than other contemporary Ersatz Emacsen, **but was renamed at the request of Richard Stallman.**
Yes indeed. I've used all of them in my time, but the need rather faded away when we got emacsclient. 
I do this a lot. I usually use my own API to interface with other 3rd party packages, only exposing the functionality i need. It also provides a nice way to plug in a different implementation later if you need to -- this way you only need to update your wrapper package instead of call sites everywhere else in your codebase.
I have no idea what the other language is supposed to be, and from a cursory look at the images from the google search for "programming language logos" I didn't get closer either :(
 (add-hook 'kill-emacs-hook (lambda () (shell-command "shutdown"))))
MuPDF fitz library can do that, Go wrapper can just extract pages a images or text, for now.
Use ISO-8601.
This looks more like a proxy to other cloud services than a real push server since it has a dependency on other services to do the heavy job. What a letdown.
Problem is people have different ideas of health. Solution is allowing them to specify those ideas.
How does the package compare to [math/big](https://godoc.org/math/big#Int)?
I’ve been writing Java since there’s been a Java. FWIW, the monikers “verbose” and “slow” have been with it since the very start. 
...kids today... /s
Irresistible urge to wrap everything in golang
[removed]
TIL Java has a mascot
Though depending on when the values were written to the struct, they may still be in L1 cache when you reach the destination code, since a recent CPU will likely have 32KiB of L1 cache with 4-cycle latency. So it's complicated...
Well, formally your statement might be okay: The less you pass, the faster the code will be. But in almost all case you do not pass arguments and do not _use_ them. Try benchmarking real code where you actually _use_ the values passed and you'll be surprised. (Modern architectures offer a wide range of unintuitive performance characteristics and are pretty fast in handling continuous memory and suffer from cache misses much more than gained by copying 20 bytes.) 
Java is one of the fastest garbage collected languages. I think people consider java slow because of the abstraction provided by frameworks.
What are some faster than Java GC’d languages?
Thanks. This is gonna come in handy. If i ever decide to share my emacs config this is going to be in there. 
Then they should say that their server is only for mobile devices running Android/iOS. For example i cannot use this project to send push notifications to web, desktop or embedded apps without depending on 3rd party services.
Go, if you avoid dynamic allocation as much as possible (reducing GC pressure), although it still loses to Java in raw compute. 
That looks like a pretty good thing to show people how a processor / vm works. 
I would appreciate it if you could summarize your experiences and findings at some point, this is of general interest.
IIRC, the reputation was well-deserved back in the 90s, and once something gets into collective memory, it's almost impossible to get it out (see JS being slow).
.net core is marginally faster than java in most cases.
Web Push Notifications are relatively new and only just recently gaining wide browser support. While not directly supported by this library the FCM backed notification service does support this and would be somewhat trivial to extend this library to support. Perhaps a feature request to add?
If `chi` works for you, you are golden I, personally, needed `echo` for specific requirements in routing on one of my projects. While working on that, I built my own middleware and other pieces around it and reuse that from there on. Pretty sure I could get by with `chi` on some but`echo` is just working great for me. There are a lot of convenience methods on `Context` in `echo`. Many are wrappers since `Context` has references to both request and response. You will be using methods passing request and response writer in `chi`, just busier code, slightly more typing. Some like `chi` "stick to net/http" approach, some prefer `echo`.
There were various emacs clones as they called themselfves, like `joe`, that had no elisp whatsoever. Just basic emacs key bindings. I'd really like to see a more modern lisp implementation without internal hacks emacs used. Something like Guile or Scheme based editor. 
Has Duke been blunted? Should have a pointy head. And he looks kind of saggy. :( 
Not yet.
Not really, JVM is still faster.
Not OP, but maybe I can help! The standard lib package `database/sql` doesn't know anything about _specific_ database engines like MySQL, Postgres, SQLite, etc., so to get support for these engines you have to import their respective driver packages. The driver packages automatically "register" themselves with `database/sql`, so that they're available to connect to and use, and all you have to do is simply import the driver somewhere in your app. But, if you simply did `import "github.com/lib/pq"` but don't actually _use_ anything from the `pq` package, the Go compiler wouldn't let you build your app because of a "variable that was declared but not used," in this case the `pq` name exported by the package you imported. So most people do `import _ "github.com/lib/pq"`, which imports the pq package into the `_` variable, which is the variable name you use when you want to disregard a value. You get the 'side effect' that `lib/pq` registered itself automatically with `database/sql` so you can use it, but you yourself don't use anything from `lib/pq`.
Oh ok then, maybe these benchmarks are wrong http://benchmarksgame.alioth.debian.org/u64q/csharp.html
As requested, a small writeup of how to get sdl2 working on the raspberry without xserver: I am using the official raspbian "jessie" release. The packaged libsdl2-dev is version 2.0.2, which is too old. So first we need to install a recent libsdl2 with kms support. I chose to build custom deb:s, based on the upstream debian sdl2 repo which has the most recent sdl2 2.0.8, so: On your pi: sudo apt-get build-dep libsdl2 git clone https://salsa.debian.org/sdl-team/libsdl2 cd libsdl2 cat &gt; libsdl2-pi.diff &lt;&lt; EOF diff --git a/debian/control b/debian/control index 4674513..79ff6e9 100644 --- a/debian/control +++ b/debian/control @@ -9,7 +9,6 @@ Uploaders: Standards-Version: 4.1.1 Build-Depends: debhelper (&gt;= 10~), - fcitx-libs-dev, libasound2-dev [linux-any], libdbus-1-dev, libegl1-mesa-dev [!hurd-any], @@ -22,7 +21,6 @@ Build-Depends: libudev-dev [linux-any], libusb2-dev [kfreebsd-any], libusbhid-dev [kfreebsd-any], - libvulkan-dev [linux-any], libwayland-dev [linux-any], libx11-dev, libxcursor-dev, @@ -36,8 +34,7 @@ Build-Depends: libxv-dev, libxxf86vm-dev, pkg-config, - libsamplerate0-dev, - wayland-protocols + libsamplerate0-dev Build-Depends-Indep: doxygen Vcs-Git: https://salsa.debian.org/sdl-team/libsdl2.git diff --git a/debian/rules b/debian/rules index 3a28a85..afbfc73 100755 --- a/debian/rules +++ b/debian/rules @@ -9,9 +9,8 @@ confflags = --disable-rpath --enable-sdl-dlopen --disable-loadso \ --disable-nas --disable-esd --disable-arts \ --disable-alsa-shared --disable-pulseaudio-shared \ --enable-ibus \ - --disable-x11-shared --disable-video-directfb \ - --enable-video-opengles \ - --enable-video-wayland --disable-wayland-shared + --disable-x11-shared --enable-video-directfb \ + --enable-video-opengles --enable-video-kmsdrm # disable autoheader (invoked automatically by autoreconf), necessary in order # to use debhelper compat level v10 without overriding dh-autoreconf calls @@ -55,7 +54,7 @@ override_dh_auto_configure: dh_auto_configure -- $(confflags) override_dh_auto_build-indep: - GZIP="-9n" tar czf debian/examples.tar.gz test --owner=0 --group=0 --mode=go=rX,u+rw,a-s --clamp-mtime --mtime="$(SOURCE_DATE)" --sort=name + GZIP="-9n" tar czf debian/examples.tar.gz test --owner=0 --group=0 --mode=go=rX,u+rw,a-s --mtime="$(SOURCE_DATE)" doxygen docs/doxyfile # useless files find output -name "*.md5" -delete EOF git apply libsdl2-pi.diff (some additional dependencies might be needed at this point) dpkg-buildpackage -b -uc -us finally, install the deb's: sudo dpkg -i ../libsdl2-2.0-0_2.0.8+dfsg1-1_armhf.deb sudo dpkg -i ../libsdl2-dev_2.0.8+dfsg1-1_armhf.deb Building the debs took about 50 minutes on my raspberry pi 3 model b. 
Performance should be similar given that both packages use the same representation of the set. &gt; adding/testing/removing individual elements Use [SetBit](https://godoc.org/math/big#Int.SetBit) to add or remove elements. Use [Bit](https://godoc.org/math/big#Int.Bit) to get an element. &gt; finding the maximum element [BitLen](https://godoc.org/math/big#Int.BitLen) &gt; iiterating and finding nearest neighbors. Use a for loop and Bit method.
It’s probably because of the JVM startup time.
Once upon a time, at Google, the app I worked on took over an hour for a cold start, and 10-20 minutes for a warm reload, on a very beefy 8-core 64gb-ram machine dedicated dev machine. This is was fairly average as far as things were concerned. (After it was running, it was indeed plenty fast.) I once tried writing Java in vim for a week, and it was excruciating. Everyone who writes Java uses Eclipse or similar, so 90% of the code is generated automatically from a few clicks here and there. Writing it out manually is brutal. I have no problem writing Go in a plaintext editor. Java certainly has its strengths, but I don't think you can claim it's comparable to Go in startup time or verbosity with a straight face (except for maybe trivial cases).
I don't agree. Health monitoring is [a well-established pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/health-endpoint-monitoring), and there are many tools that consume such a health endpoint: Nagios, Icinga, DataDog, PandoraFMS, etc.
Synthetic benchmark are not really useful, it varies a lot about the implementation, also Java are on part for most of them or faster for some. If you look at that popular benchmark: https://www.techempower.com/benchmarks/#section=data-r15&amp;hw=ph&amp;test=json Java crushes C# ( net core ) by a large margin in every scenarios.
...yes, but his cap still starting, just look at the picture for a while
&gt; once it's going it is fast. Nowadays. At the start it wasn't particularly fast (performance optimizations came later), and the average machine at the time wasn't well suited to the requirements of the runtime. It was a huge setback to the language as end-users were afraid of applications written in it.
Cool, I didn't know about the big.Int Bit methods. It certainly pays of to know your standard library! The iterator in this package should be much faster than iterating over all possible bits, though. It skips zero words and uses bits.TrailingZeros64 to skip consecutive zeroes within a word. There are some other minor optimizations as well.
Very useful as I‘m implementing a vm in go at the moment, helpful to see the general strucutre and how everything is put together.
Don't get me wrong about startup time. Go is practically instant. I suppose it all depends what you're working on. 
That is completely unrelated to my remark. The README notes about timezone offsets, as in +1 hour, or whatever. I'm talking about the format "dd/mm/yyyy" versus "mm/dd/yyyy" which you can't magically differentiate between unless you receive the date format string to begin with.
Whatever application you choose, I am most interested in how to deal with multiple api objects that reference each other. Historically I've done both small packages while artificially restricting imports to be one-directional. I've also done a mega package where all the crud objects can communicate effectively, but leaves an enormous api surface. Neither one feels great.
`go doc` is a subcommand within `go` tool. Just like `go build` and `go get` are also subcommands of `go`. It's documented here: https://golang.org/cmd/go/#hdr-Show_documentation_for_package_or_symbol. `godoc` is a specific command. It's documented here: https://godoc.org/golang.org/x/tools/cmd/godoc. `go doc` is higher level and uses `godoc`. They're similar, and the differences are subtle. It's good to be familiar with both and use both depending on what you need.
pretty good virtual machine. I see that you are using the stack based approach as opposed to the register based approach with explicit pop push.
They certainly are useful, they just maybe don't tell the whole story.
some more details about Agones https://cloudplatform.googleblog.com/2018/03/introducing-Agones-open-source-multiplayer-dedicated-game-server-hosting-built-on-Kubernetes.html 
Example: https://github.com/kubernetes/kubernetes/blob/f850b4247493a6ee98847847b0b1569b24cced5a/staging/src/k8s.io/api/batch/v1/generated.pb.go#L48
that's quite a lots of vendored dependencies. Wondering whether its so large project.
More less, that is the point of whole project. :)
thank you very much for your effort
Verbose, slow and old fashioned are all things that proggit calls go, too
When I inquired about this, the consensus was that JVM startup times are negligible. Also worth noting that the .Net VM also needs to start up, albeit it's possible that the .Net VM just has better startup performance.
Thanks @sh41. It seems like Godoc the tool may need to be downloaded separately whereas "Go doc" is built in but still uses the Godoc tool. Also, I think, unlike other tools, the links above from 2015 seem to indicate that Godoc is downloaded to the GOROOT directory rather than GOPATH.
Good talk. lol
Really cool project!
Binary installations of Go (from https://golang.org/dl/) bundle the `godoc` command, so it ends up being placed in `/usr/local/go/bin` next to `go` and `gofmt`.
And, if anything, Java has faster and more concise over the years.
Back in the day, Java's big sell was around "applets" which appeared in a lot of web pages. They would slow your entire machine down, often take 30+ seconds to start, and frequently crash your browser. The poor implementation of applets did a lot of damage to the language's reputation, which is a shame.
Hey there, this is a great question! We thought about this quite a bit when we designed these function interfaces, and we think it's better to use function interfaces that are idiomatic in the language, familiar to programmers from that language, etc. That's why the Python environment (both builder and runtime) use Flask, the Go environment uses the standard library interface for HTTP handlers, and so on. This lets you use existing docs/google/stack overflow for commonly used things (like, where to find HTTP headers) instead of learning a new interface. It also lets you move your code between Fission and a regular deployment/service running in Kubernetes. That said, the piece of Fission that wraps functions (we call this an "environment") is easily changeable. So you can change it to whatever interface you'd like. For example, here's the [Python environment](https://github.com/fission/fission/tree/master/environments/python). You can edit and rebuild that, and load it as an environment into your Fission setup.
Good to know, thanks!
Good to know, thanks!
Thanks @enneff for the explanation! In strategizing how to build a local, non-public version of godoc.org, my first thought was that ideally I would want to download a dump of the preexisting godoc.org website/database and supplement it with local, non-public godoc documentation generated using the standard Go Doc/Godoc tools.
Setting up user aunthentication with apis. Make sure to add in table relations. I am practicing with a URL/meta tag searching site but I need to add the great complicity of user tables. Simplifying that would be really appreciated. And please no frameworks.
I only glanced over this since the tech is familiar to me, so I won't comment on the content beyond saying it seemed fine, but I did want to say I love the idea of a URL shortener as a simple intro project to making APIs with Go. Good beginner project ideas are hard to come by, so its no small thing.
Not sure it makes sense. Java was slow and bloated for most of its existence. Sun's marketing went batshit crazy about everything in Java. However its engineering never really delivered on that. Java folks are still trying to write compiler/runtime/GC in Java. The thing Go committers finished many years back. In short Java was way big on marketing. If they were just a little bit reasonable people would not have piled on Java so much. Whereas Go till now worked as a engineering project mostly escaped from Google marketing machine. No ridiculous ads about how this and that is written in Go.
Thanks for the details on that decision. I can't say that I agree, but it is good to see that the Python environment is swappable. I find it strange that I would need to import Flask and use it as an implementation detail. It feels more natural and abstracted to me to define a function that is passed everything that I need as a request object. That way no user needs to think about swappable python environments. Fission could switch it out to whatever one is the best and continue passing the same context. I would rather look at the Fission docs once and see everything I can access on a context object, and what I am expected to return or raise an exception.
But that means it's getting used. Any significant issue tracker is a scary place.
&gt; give you the following date: 02/03/2018. Can you tell me whether it's the March 2, or February 3? You can't. That's not a parsing problem though. It appears that it will parse that just fine. 
just try to use non-pointer method receivers.
I had way too much fun thinking about it an implementing it. However I took the implementation correctness and encoding design very seriously. The following issue really made the encoding quite elegant, it introduced support for concatenation and sorting. https://github.com/keith-turner/ecoji/issues/7
[removed]
[removed]
[removed]
I’m newer to Go, but I’ve only heard about how it’s fast. Who says it’s slow?
Sorry, I thought that was pretty apparent. I will add a section explaining that. Thanks for reading !
Thanks for this Dmitri. I have always been pretty frustrated trying to search issues with a given prefix in github. Because it always gives you other issues it thinks are relevant. This really helps when you are working on a specific part of the project.
&gt; Is this a sane project layout if I don't really have an opinion on anything yet? Yes. It's not required by any means, but there's nothing wrong with it. &gt; What's the safest vendoring approach? It looks to me like dep is currently the most likely candidate for becoming the "official" tool in the future. It's what I use and I've been decently satisfied with it. I haven't used vgo. If this is your first big go project, you might consider _not_ vendoring (all your dependencies will simply be installed "globally" at $GOPATH/src). If the libraries you depend on are well behaved, that might "just work," and if it doesn't, you'll be in a better position then to understand what you need from a vendoring tool.
&gt; If this is your first big go project, you might consider not vendoring I started thinking this and I'm glad you brought it up. I think it would be best for me to delay this decision until I know I need it. Perhaps the role of vgo will be more obvious by then. I found [this article](https://sdboyer.io/blog/vgo-and-dep/) mentioning vgo and dep and it sounded interesting, particularly this part: &gt; i will continue to work on dep as i have for the last couple years - in my “spare time” (lol). i am also - to be fully transparent - being contracted by Google for work on vgo. Specifically, the contract covers a thorough technical review of vgo, ongoing meetings with Russ, and creating automated migration tools that map dep, glide, govendor, and godep to vgo. i have taken care to ensure that the work specified in this contract does not incentivize me towards any particuar technical outcome, but rather focuses on things that Russ and i both agree are important for this next phase of experimentation.
For the layout, I found this post really helpful https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1 Ben has some great thinking on the subject and is definitely worth the read. As for vendor... Using Dep currently. Before that, nothing :) Have fun 
People that work on the real-time problem domain, usually with no GC languages.
Having a "human interface" date parser is a great thing, don't let some of the comments here dissuade you from pursuing that as it can be an almost magical thing when it works. However you might want to look at some of the other APIs (mostly not in Go) that do this kind of thing, the big thing is having input like "Thursday 12:00" parse ... and some of the more advanced things parse things like "last Wed 1st 12:00" (which might be more than a week ago).
I would follow the KISS principle. Most projects don't need all that structure. - /cmd: You don't need this, since you are developing one application, just put your main package in your project root. - /internal: Only useful for libraries to hide internal packages from library users. - /pkg: If you have shareable code to be used by other applications. I prefer to create individual projects for shared code instead. - /vendor: If you want multiple machines to build using the same libraries, then vendor your libraries. Personally, `go get -u` have never caused a problem for me so I have never bothered to. - /test: When writing unit tests, put them in the same directory as the functions you are testing. For example: hello.go should be tested by hello_test.go. When you have big integration tests then maybe /test is a good idea, but I have never seen any projects do this. - /docs: First make sure you code is properly commented such that the godoc documentation tool generate a good output. /api, /web, /configs, /init, /scripts, /build, /deployments, /tools, /examples, /third_part, /githooks, /assets: No opinion, what ever you need, none of them seems Go specific. 
Either, depending on whether or not it's able to grow in place.
I used to write real-time code. I can confirm I Go is "slow". (It's one of the faster GC'd languages, though, as far as I can tell)
Thanks for the info, I had missed that. It does seem, as /u/lhxtx also mentioned, that vgo is situating itself to replace dep. Having said that, the current official advice from the vgo developers seems salient: &gt; The publication of the vgo prototype doesn’t change any of our immediate plans for dep, nor does it change dep’s status as the recommended tool. With that in mind, I'll amend my advice: - If you can do without vendoring, consider doing without it - If you need a dependency management tool that is relatively stable and works _now_, you want dep - If you want to prepare yourself for the future, and are okay dealing with an unstable prototype that is subject to bugs and breaking changes, then you want vgo.
Total noob so this thread I found interesting then confused. I thought all my code goes under /src. At the same level or /src is /bin and /pkg. That so far is all I knew to do. What am I missing.. where did I go wrong?
Why I didn't see this before? I wonder how long this button is there? Probably the folder icon was not associated with this action for me... Thanx a lot :)
looking at the commit activity of gin it looks really low. According to their milestones v1.3 is overdue by 7 months. I don't know if they'll ever release it. Not to mention that one of the goals to meet v1.3 is to move to dep, but someone commented saying they should wait for vgo. So now they'll hold off on releasing it for an undetermined amount of time instead of just releasing what they got. The only thing keeping me from just dropping gin is that it's meant to have the best performance. I would love to get some up to date benchmark comparison of gin vs echo
That's just not correct. Part of parsing data is interpreting it correctly. If I give it "02/03/2018" it will not give me March 2, which would be the correct result from Europe's point of view.
Happy to hear it's going to come in handy!
I think most of javas perception of slow comes from swing blocking repaint in event handelers. 
&gt; Is there a better way to write this Yes there is: if err := a(); err != nil { return fmt.Errorf("doing a stuff: %v", err) } if err := b(); err != nil { return fmt.Errorf("doing b stuff: %v", err) } if err := c(); err != nil { return fmt.Errorf("doing c stuff: %v", err) } return nil Also [errors are values](https://blog.golang.org/errors-are-values). You can program with them to make the API more concise: type abc struct { err error } func (t *abc) a() { if t.err != nil { return } t.err = a() } func (t *abc) b() { if t.err != nil { return } t.err = b() } func (t *abc) c() { if t.err != nil { return } t.err = c() } func main() { t := abc{} t.a() t.b() t.c() if t.err != nil { log.Fatal(t.err) } }
[removed]
I can't remember exactly when, but it's been more than a year and a half for sure. I do agree it's not immediately obvious you need to use that icon but I hope that will improve in the future.
seems simple enough to write your own `Coalesce` if each of the functions have the same signature. for me i don't know the threshold of usefulness for such a thing -- how many such conditions does it take to make compacting it into a single -- possibly obfuscated -- condition preferable? i can't think of a practical case for it. package main import ( "fmt" "log" "math/rand" "time" ) func Coalesce(fs ...func() error) error { for _, f := range fs { if err := f(); err != nil { return err } } return nil } func main() { rand.Seed(time.Now().Unix()) n := 0 EP := func() error { n++ if rand.Intn(5) == 1 { return fmt.Errorf("EP() #%d failed.", n) } return nil } if err := Coalesce(EP, EP, EP, EP, EP, EP, EP); err != nil { log.Fatal(err) } } 
I'm generally happy with the features and the performance. It's only become an annoyance when I realised I haven't gotten any of the fixes for 7 months and that it's seemingly stalled on trying to merge my patch. Definitely will be evaluating echo for the next new project 
[removed]
how does it compare to gRPC and NATS?
Not with this, no. However, if you're looking to build one yourself, check out the articles here: http://wiki.vg/
there is a bug, you use modulo res1 := binary.BigEndian.Uint64(resBuf) % ((1 &lt;&lt; diff) - 1) should not there be bitwise and?
I get the need for cmd , vendor and for api, if it's applicable. I don't understand the need for internal. Unlike vendor, nothing in the go spec says anything about internal. All the rest sound like fluff.
Good catch. (The bitwise and is a modulos with 1 &lt;&lt; diff, but faster.)
This is not unreasonable but just because someone named his user golang-standards is no reason for you to believe that this is some kind of "official standard". Some things are less "standard" than just how the tools work, e.g. /internal and /vendor. Some things are common like grouping executables in /cmd. Some advices from golang-standards are a bit strange, e.g. /pkg and /test. 
 func convert(s string) []byte {return nil} Is the fastest way. Albeit not the most correct one. (Paraphrasing Russ). func convert(s string) []byte {return []byte(s)} Is an other candidate which turns a base-10 64 bit signed integer string to a byte slice. It is very fast and correct and converts any string to a byte slice. Your use case seems like speed of conversion won't be the problem: Writing to disk is presumably slower than strconv + bitfidling.
Note that you'd have to turn the `int64` into a `uint64` before `PutUint64` will work. But if writing to disk anyway: ``` n, _ := strconv.ParseInt("12345678901234", 10, 64) binary.Write(w, binary.LittleEndian, n) ```
`errOR` is an OR operation on errors. The name should be changed, probably. func errOR(errors ...error) (error) { for _, err := range errors { if err != nil { return err } } return nil } Call site: return errOR(a(), b(), c()); 
Even better - if err := a(); err != nil { return errors.WithMessage(err, "doing a stuff") } if err := b(); err != nil { return errors.WithMessage(err, "doing b stuff") } if err := c(); err != nil { return errors.WithMessage(err, "doing c stuff") } return nil With the indispensable `github.com/pkg/errors` package
Interesting take on solving the issue. I don't like the readability of this though, it's not obvious there are conditions inside: &gt; t.a() &gt; t.b() &gt; t.c() 
Link for the lazy: https://github.com/pkg/errors Do you mean `errors.Wrap`?
I find this hilarious yet readable!
Nah, I meant `WithMessage`. `Wrap` captures the stack trace too, which is a costly operation. `WithMessage` is much lighter. Since the OP used `fmt.Errorf`, I used its closest alternative.
I don't understand why you have to use a dependency of 1.2k+ lines of code just to send a simple message up to the user. If you really care about the cause of the error then instead of a simple message you can send a custom type that includes the cause and which is trivial to do.
&gt; Unlike vendor, nothing in the go spec says anything about internal. [Internal proposal.](https://docs.google.com/document/d/1e8kOo3r51b2BWtTs_1uADIA5djfXhPT36s6eHVRIvaU/edit)
I think there's some psychology behind why this comes up a lot. As a Go newb you return errors without touching them and you start to wonder, why do I need to repetitively check and return? Couldn't this be like, implicit, or something? It's just really non-DRY code! I'm just doing the same thing over again and Go is forcing me to code this way! And then after a digesting some Dave Chaney posts and other Go materials you start to realise that maybe you *shouldn't* be just returning the errors. Maybe the problem isn't with Go, it's with the fact that you're *choosing*, over and over again, to do nothing with the error. Then you start wrapping errors with context and you realise there's actually nothing to DRY up, you were simply choosing not to handle the error correctly before. Finally you either accept or disagree with one thing: Go forces you to *handle* the error. Even if that means simply returning it. It puts that choice in your face, making it hard for programmers to ignore inconvenient errors. This is important for scaling code bases, especially when on-boarding new programmers who might be tempted to not handle errors. I don't know where I was going with this. 
&gt; Go forces you to handle the error. I agree with everything you said except that technically Go doesn't force you to handle errors (though I understand what you mean). For example this is the signature of [fmt.Println](https://golang.org/pkg/fmt/#Println): func Println(a ...interface{}) (n int, err error) I don't see much error checking on that.
The problem is often that a, b and c often returns values along the error
Don't forget to check the [Upspin log package](https://github.com/upspin/upspin/blob/master/log/log.go).
Mainly because a lot of the time there's a `fmt.Errorf` in the middle somewhere. `pkg/errors` exists to remove the boilerplate of adding the custom types every time you want to wrap an error, and provide utilities to work with the wrapped errors too. I don't think `pkg/errors` is perfect though, there are a couple of bits it's missing IMO.
How do oranges compare to apples? They aren't the same :) I think that is best answered at the bottom of the [go-chi/chi github readme](https://github.com/go-chi/chi#beyond-rest) in the section titled "Beyond REST". Here's my attempt to try to compare them tho: In intent a comparison gRPC is closest, but different in every way - line protocol (tcp + protobuf), client implementations and coverage, etc. gRPC does provide an API, but it's not so much an abstraction as it's an integration (if that sentence makes sense). Basically, it doesn't feel like you're working with a remote API, but a local one. NATS is sort of a focused subset that is aimed at solving messaging patterns (push notifications, channels, typical pub/sub use cases). People do implement their own idea of RPCs over these channels, but unless there's a more accepted "rpc" layer that's built on top of NATS, I suspect the implementations might be more fragmenting than unifying in terms of standardization. I hope that explaining some differences, it really is hard to give a good answer to such a general question. If you'd pose the question as "Which should I use?", then it's easier to come up with an answer: *it depends*.
You could wrap the functions and store the results in other variables defined outside of the call... something like: var ar, br, cr int return errOR( func() { ar, err := a() return err }, func() { br, err := b() return err }, func() { cr, err := c() return err }, ) ...please don't do this.
[removed]
I am enjoying vgo; however, be aware that you may encounter issues with tooling support. For example, as of this past weekend, many of the vim-go IDE features don't work with vgo projects; compiling, auto imports, etc are all non-functional. I haven't tried other IDEs, but with vgo so fresh, I would expect a general lack of support which might make your development process more difficult than it needs to be. Personally, I like vgo enough that I'm living with it, but it is mildly annoying.
I wrote about some useful patterns before [in this article](https://scene-si.org/2017/11/13/error-handling-in-go/). You could ctrl+f "flow" in there. Alternatively, you could just look at [this playground sample](https://play.golang.org/p/AStZiZ_-Ml), or perhaps the [x/sync/errgroup package](https://godoc.org/golang.org/x/sync/errgroup).
Stack traces will tell you the nitty gritty details you didn't ask for, this can at least, slow you down a lot, and at most, completely bury the actual problem. Stack traces can't capture the semantics of the error. Good error handling encapsulates domain specific details, the semantics of the error (in my opinion). I don't think they are mutually exclusive: you can have good errors and a stack trace included for good measure. If you want some interesting material on error handling and Go I really enjoyed these articles: https://commandcenter.blogspot.com.au/2017/12/error-handling-in-upspin.html https://hackmd.io/s/B1NrW6_dM
&gt; ...please don't do this. Why? it actually doesn't look that bad. you can even do one liners which you can't with if statements. err( func() error { a, e = do1(); return e }, func() error { b, e = do2(); return e }, func() error { c, e = do3(); return e }) if there was 15 I/O steps personally I'd find it easier to read. Furthermore declaring variables before hand is actually the most readable thing one can do.
I'm not sure I agree really. I think it's functionality could be useful for almost anything unless you only have one layer in your app that returns errors (i.e. an error from a library is always only one error away from being handled for the last time), because you might want to treat different errors differently. Aside from stack traces, how would you provide the rest of the functionality of `pkg/errors` in 5-6 lines?
I foresaw this response! ;) I'd argue that my comments generally hold true *in practice*, errors that should be handled are hard to not handle. I think a strong counter point would be an anecdote describing how it was Go semantics, not the programmer, that was mostly responsible for why a serious error was not handled correctly, or rather, was hard to handle correctly. 
I agree; context is very important. Like you've said though, they're not mutually exclusive. If stack traces were a built-in piece of functionality for errors then it'd just make the process easier.
b and c may also have side effects that are not wanted if a errs out.
Actually, depends on how you can handle an error. Generally if you can't handle an error you just return it down the execution stack, until it hits the outer most code which does something like logging. Since by default errors don't have stack traces, it makes is *really hard*, really *impossibly hard* to figure out where some error is coming from, especially if you didn't wrap it along it's path, for which you'd probably convert it to string and lose some underlying context which is returned by some packages (encoding/json SyntaxError, database/sql driver dependant error objects,...). At least pkg/errors allows you to Wrap an error without losing it's underlying cause (`Cause() error`), which you can still type cast or print with `%#v` with all it's details. The most obvious issue I have with pkg/errors is that `errors.New` is used to define errors that may be returned in the package, and it does this by using a var. See the `os` package for [the ultimate example](https://godoc.org/os#pkg-variables) in the stdlib. The stack trace for such declarations of errors is useless, as it doesn't give you information about where the error was returned from, but only where the instance was made. While I concede that it's overkill having stack traces everywhere, it feels somehow limiting that you can't have them with compiling with some debug flags or something. If we're into this kind of territory, then it's better to end it here. As with all things, if you know how it works, you can use it to your advantage.
Coming from somebody who generally starts with `main.go` and then moves it into `cmd/[name]` and moves other stuff around to refactor, having done this for three hours today during the night, it seems to me that it's better to start off with `cmd/*` and the proper package layout as it should be, as these hours spent refactoring later really aren't worth it. In sum, you'll use less time following some semblance of the final structure, instead of refactoring it later.
It's good that your issue got sorted. Sorry if my reply wasn't on the right path for you.
If you're shooting for a Scrapy like library I'm on board but yeah, some more in depth documentation is needed for us to give this a shot.
&gt; I agree with everything you said except that technically Go doesn't force you to handle errors (though I understand what you mean). psychological force, not technical force
I have a bindings for mini_al here https://github.com/gen2brain/malgo , there is an example for capturing sound from mic, there is also aac example here https://github.com/gen2brain/aac-go/blob/master/examples/micgrab/micgrab.go that uses malgo. If you need more control, e.g. what device is going to be used for capture see advanced_example in mini_al repo.
&gt; you were simply choosing not to handle the error correctly before Kind of, but kind of not, but mostly. In a lot of other languages with error/exception types there's a syntactic way of handling them with special keywords like try/catch, which allows them to be handled at specific points in the control flow. Think about a method for opening and reading a file into a buffer, which might raise an error if the file doesn't exist, if there are not sufficient permissions to open it, during the reading of the file into the buffer, or when closing the file. But you can bundle all of those up in a try/catch block when you call the method rather than checking at each step inside the method. This seems good when you just want to catch a generic error from a group of linked operations that should succeed or fail as a unit, and log the failure message from the exception (whichever one it might be). But once you start having to care about different kinds of exceptions and handle them differently, you have to then write a bunch of different exception handlers for the different cases. And now you are handling all of them anyway, they are just far away from where the code that threw them is. And even worse, if code below yours doesn't properly wrap code they are calling in try/catch, an exception might bubble up to your code! And this isn't just theoretical, I've seen this happen in real world code. The openstack network orchestration layer is neutron and is written in python, and I remember a bug from a few versions ago where some low level code, calling out to the OS to bind a port to a bridge, threw an exception, but wasn't caught when the method that threw it was called, so it bubbled all the way up to an exception handler in the quota code (i.e., "your tenant/user can only have 10 ports but you asked for 11"). Took quite a a bit of reading through code and debugging to figure out the actual issue was several layers down, and the over quota log message was just masking the real issue. Java of course has checked exceptions but we're trying to be less verbose and tedious so moving on. Go also does have a `recover` keyword that can unwind a `panic` (and can only be used inside a `defer` block), but panics are highly discouraged from being used as flow control and treated as errors, making a distinction between error conditions and exceptional (panic) conditions. Course there's nothing stopping you from assigning all errors in go to `_` and ignoring them either. But the convention of handling all errors immediately and explicitly in go does seem to be a really good idea overall, and does force you to actually think about what the errors mean at the time rather than just passing the buck downstream.
any reason I should use yours instead of http://go-colly.org/ ?
&gt; Part of parsing data is interpreting it correctly. Parsers are not interpreters. Interpretation comes *after* the parsing step from the machine representation (an AST, perhaps) generated by the parser. In this case, it is entirely your choice if you interpret the parsed results as mm/dd/yyyy or dd/mm/yyyy. The parser don't care. It is not a parsing concern. The input is valid either way.
I can’t recommend this anymore. They have horrible, critical flaws in their application that they don’t appear to care to fix or even warn you about before you try it. They used BlueStore to back it, and due to the way it is configured, BlueStore only writes but deleted data is never cleaned up - this is literally inevitably going to fill your disks if you use it. https://github.com/rook/rook/issues/1397
By built-in, I made automatic really. Or at least, maybe you should be able to ask for the stack for an error at a given point? Sort of like how panics are able to give you a stack trace too, at the time of the panic.
nice touch with the readthedocs, keep up the work.
Perfect! Thanks for pointing this out.
What you are talking about is the "Go Path". This is where all your go projects should be located and where go will install all libs or programs that you install with "go get". For me this is ~/Projects. Each has their own folder inside the ~/Projects/src folder. Usually this project folder will be named after the URL of the project. Lets take the go debugger delve as an example: The source code is located at github.com/derekparker/delve so go get will download the project to ~/Projects/src/github.com/derekparker/delve on my system. The OP was talking about the file/folder structure inside the Project itself. For example inside the folder ~/Projects/src/github.com/derekparker/delve I will find among others a cmd, a scripts and a vendor folder. Hope that helps.
go documentation for GH repos is bad
No problem. Btw, how do you measure dB, any library for that?
The vast majority of that "1.2k+ lines" of code in the dependency are tests. Once you disregard that, the dependency is a very manageable 416 lines of which over 20% amount to comments. 
&gt; The claim that in Go you really handle errors as opposed to other languages, is a fallacy that must die. I never claimed this. I don't think anyone has every claimed that you don't or can't handle errors in other languages. My argument is about how the error value check is not actually simple language boilerplate, and why that is a good thing. The main hypothesis is that when people complain about `if err != nil { return err }` boilerplate it's often because they're not handling the errors, not because it is actually boilerplate. Following that, when people do handle the errors "properly" in Go they tend to (and this is anecdote) not consider the error handling conventions as boilerplate any longer. &gt;I understand you may prefer writing all the error handling plumbing by hand This is where we disagree. It's the belief that the error check is simply "plumbing" that I believe causes one to say Go error handling is "verbose boilerplate", to quote many person. I don't see how checking an error is, in principle, any more "plumbing" than checking for an exception. You should treat errors as values and handle them like any other value. Do you consider your business logic to be "plumbing"? If so, then I concede. Nevertheless, there are many reasons why the exception model is poor, and I'd rather not repeat those arguments here. I'm not here to claim that Go does errors better than other languages. I'm here to claim that Go's idioms around error handling are not considered verbose when you "do it properly", with respect to Go's semantics. 
thank you very much, I am gonna need this.
 for _, fn := range []func() error{a, b} { if err := fn(); err != nil { return err } } return nil
[removed]
Why does the package loc matter? Only the lines that are used will be compiled into the final binary. Anyway, it's often better than "error doing foo stuff: error doing bar stuff: error doing baz stuff: ...". This is especially true if you log as JSON and use a tool that understands JSON to query your logs. I get the desire to omit the dependency, but it's truly useful and the std lib offers no analog.
This could be solved by making the function accept func() error and then calling it with errOR(a, b, c). Of course, supporting functions with arguments or return values means jumping through closure hoops, which defeats the purpose.
This is some expert tier magic going on. I'm pretty impressed, did not known this particular pattern to allow inheritance in a seamless manner in go. Well played.
Nice example to test concurrency in go.
gometalinter is my favourite one.
this is your project? Jumping Hash is very promising. What is gateway needed for?
Do you use a supervisor mainly on a server, or you prefer it to run multiple processes on a desktop?
&gt; Then you start wrapping errors with context and you realise there's actually nothing to DRY up, you were simply choosing not to handle the error correctly before. Could you elaborate on that point a little more? I'd say I'm somewhere between novice and intermediate Go development skill, and at an abstract level I understand the "add context to errors" bit, but I"m not 100% sure how that looks in actual Go code. I've seen loads of libraries/toolkits that let you wrap errors or have fancy error value chains ( for building custom stacktraces, effectively, I guess ) but I've yet to fully realize a meaningful implementation of this behavior/pattern.
I don't disagree on the usefulness of pkg/errors. But in my opinion it is way overused without strong reason. You do not need stack traces for good error handling.
Libraries that scan *every* class in the system, like Jetty. If you combine that with something like Jooq, the Jetty class scanning will happily trawl through thousands of Jooq-generated classes looking for web service entry points before continuing. It takes FOREVER.
&gt; Aside from stack traces, how would you provide the rest of the functionality of pkg/errors in 5-6 lines? I was thinking about the aforementioned example. To create a custom error that holds the cause, you need around 5-6 lines. I am not sure what else you need. If we are to also count a function that checks the error maybe we go up to 10 lines or something.
&gt; but it's truly useful and the std lib offers no analog. If we are talking about the stack traces feature then yes I agree. But without that the standard library easily delivers. I am don't arguing about the usefulness of pkg/errors.
Even if we omit the loc, in my opinion it is yet another dependency that the majority is blindingly importing in their projects without good reason. The worst offenders are libraries.
&gt; What framework would you use for new project? None.
Interestingly, the core Go team found that [stack traces weren't all that useful in the presence of meaningful errors](https://commandcenter.blogspot.com/2017/12/error-handling-in-upspin.html). &gt; For those cases where stack traces would be helpful, we allow the errors package to be built with the "debug" tag, which enables them. This works fine, but it's worth noting that we have almost never used this feature. 
There is a [good article](https://commandcenter.blogspot.com/2017/12/error-handling-in-upspin.html) from Rob Pike and Andrew Gerrand about error handling and wrapping context.
Stop trying to workaround, this is really bad from the start!
[You're technically correct.](https://www.youtube.com/watch?v=hou0lU8WMgo)
Honestly, try the standard library first. When you find things repetitive, then maybe reach for an assertion library (I prefer to avoid them due to type concerns, but it can make writing tests feel cleaner). Every BDD I've seen in Go is overly verbose, littered with syntaxt to force things to work, and have to hack things to allow for parallel or concurrent testing. It always feels like a square peg in a round hole. Investigate table driven tests. Remember, tests are not special. Tests are code. You shouldn't need a domain specific language to test. Just write Go.
Basically I'd say the "psychological forcing" is in that you have to purposefully ignore go errors by typing comma, underscore every time. In a language like C# ignoring them is much easier than in go. In go you have to *explicitly* not take that error
Nice, looks like a good read. Thanks for sharing.
Or, if you're not writing to disk: n, _ := strconv.ParseInt("12345678901234", 10, 64) buf := &amp;bytes.Buffer{} binary.Write(buf, binary.LittleEndian, n) // buf.Bytes() has your []byte
 reflect.ValueOf(a).Pointer() Might work. 
`reflect.DeepEqual`?
Nice Talk Thanks
For unit tests i use stdlib testing. And i am happy with it. Now I am starting to write integration tests and will need to share them with the team. Thanks for persuading to stick with standard libraries. 
That compares values, does it not?
Along with the upspin article, I'd recommend [the two sides of an error](https://hackmd.io/s/B1NrW6_dM). Here's some real code that I wrote to demonstrate adding context to errors: https://play.golang.org/p/ViDhtvPP_MB The program downloads any URL links you feed to it (concurrently, in true Go fashion). This is not advanced or sophisticated error handling, but when an error occurs you'll be able to instantly pinpoint what the error is and where it occurs instantly. Furthermore, there's no instance in this code that can be made DRYer. The errors are just handled. 
ParsePornHub() in the examples :O
This is a little complicated to answer, but I will try. - You can not have multiple packages in the same directory (with the exception of &lt;something&gt;_test packages that can be in the same directory as the &lt;something&gt; package). - You can have `&lt;gopath&gt;/src/hello/main` directory, but you it is not recommended. - The directory names should line up with the package names usually. With the only exception being the main package which should be in a folder named after the executable name. You can have the package main in the folder main, but then you would need to have flags for `go build` and it would break `go get`. - Instead of `&lt;gopath&gt;/src/hello/main` it should probably be `&lt;gopath&gt;/src/github.com/&lt;githubuser&gt;/hello/cmd/hello` if `hello` is something that can be used as an executable, but also as a lib or it should be directly in `&lt;gopath&gt;/src/github.com/&lt;githubuser&gt;/hello` if it is only a executable. In this folder should then be the package main of the "hello" executable. This allows users to install my `hello` programm by simply running `go get github.com/&lt;githubuser&gt;/hello` or `go get github.com/&lt;githubuser&gt;/hello/cmd/hello`. It is a little strange at first, but I think it makes a lot of sense once you get used to it. If I would like to create a executable with the Name "hello" that uses some models in the models package then I would create a structure like this: &lt;gopath&gt;/src/github.com/&lt;username&gt;/hello ├── main.go # Package main with main() └── models # user and greetings are both in Package models. ├── greetings.go └── user.go This executable can then be installed by anyone by running `go get github.com/&lt;username&gt;/hello` and the `models` package can be imported with `import github.com/&lt;username&gt;/hello/models`. Alternatively you could also layout the project like this: &lt;gopath&gt;/src/github.com/&lt;username&gt;/hello ├── cmd │ └── hello │ └── main.go └── models ├── greetings.go └── user.go Which can then be installed like this: `go get github.com/&lt;username&gt;/hello/cmd/hello`
Ocaml
I just panic whenever I don't plan to handle an error. It makes my own app much cleaner and easier to deal with. 
I'm curious, how slow are we talking? Like "out of the question, it's basically a snail" or "you know, if it was just tad faster it might be usable". I've never worked on any real-time code. 
os.Exit(0)
+1 for &amp;MySlice{} or [b := &amp;a](https://play.golang.org/p/U1-Vjm37ot0). But either one of these is probably the wrong solution to an XY problem.
Thank you. That explains a lot. For the most part I think this is how I assumed it would be, though the whole main package and where that file resided through me a bit coming from Javaland. So I take it the alternative cmd/hello/main.go is not common.. it strikes me as a little odd vs the first way of doing things? I also assume that the src/path/hello/main.go means hello is the name of the executable. I assume you can change that with some command line options if for example you were using the Java like syntax of the main directory being say your company/project name, but the actual product changes names by the time it releases.. but you dont want to mess up any potential dependencies (not sure there would be any) on the current name of the main project directory? Thus, src/github.com/user/company-name/project-name is the root, but project-name is really company-product-name, you wouldnt just rename that directory and everything works right? I mean you could I guess if nothing else depended on it, but typically I would assume there is a way to offer the actual executable output name when building it. I can look this up btw.. just struck me when thinking about what you are saying here. So I see most projects are github based. I assume that is just the norm, but it is perfectly OK to not post my code out on github.. and thus it would be /src/internal-company-dir/project-name/main.go that is OK I hope 
How are you using the cmd folder? Did you know that's what what you will be doing start of the project. In my experience, I refactor because I found a better way to do things. It's always better to start the project running, knowing I can refactor later, then trying to have everything perfect the first time. Three hours refactoring is also on the long size. If everything is properly encapsulated, which comes with experience, the refactoring to a different directory structure is just a type naming change. If pulling apart code that should belong in different packages is difficult, than that is definitely a code smell.
I literally just wrote [this little program](https://play.golang.org/p/84sdS4KopCG) in response to a request for an example of handling errors. It has no dependencies outside the standard lib. It includes an error wrapping implementation. It's very simple, but I think it gets you quite far. Perhaps it's of interest. 
Nice, I was hoping this project was still going to be moving forward since I was so stoked when I first came across it! Just some quick user experience notes on some of the various Kubernetes deployment tools that I've tried for whomever might be interested in the topic: I'd been excitedly using Kubicorn (after switching from kops) for a while and was definitely digging it for quickly spinning up test clusters on various cloud providers, but I ended up wanting to try to get my CoreOS "Container Linux"-based kubernetes clusters be [self-hosted/self-bootstrapping](https://github.com/kubernetes-incubator/bootkube) and HA, which (at least when I last checked) there didn't seem to be the ability to easily do via Kubicorn. I ended up stumbling on to [Typhoon](https://typhoon.psdn.io/), which did cover that use case, with the added bonus of also supporting k8s on bare metal. I see that some other folks might be looking for [bare metal support on Kubicorn](https://github.com/kubicorn/kubicorn/issues/556) as well now.. IIRC some of what had most piqued my interest in Kubicorn was the idea of potentially being able to easily swap from one cloud provider to another along with easier/automated scaling and disaster recovery. Correct me if I'm wrong, but when I'd poked around a bit at the Cluster Lifecycle SIG docs/hangout-vids/etc a few months back it appeared that parts of Kubicorn's functionality seemed to be dependent on the Cluster API stuff getting sorted out--wasn't sure how that was going--so it's great to see this announcement :) 
That’s the next bit.. I’ve been looking at various resources where people are just piping out to Sox [example](https://github.com/mmornati/ruby-noise-detection/blob/master/noise_detection.rb). I suppose that Ruby script is basically what I’m looking to do, but wanting an exercise to learn with.
Slice, maps, and functions are not comparable in Go per the spec: https://golang.org/ref/spec#Operators So you can compare by value, or don't compare it at all. 
Thank you, Master!! These suggestions are very useful to me. One more thing, if you turn on the flag `failOnConflict`, you'll see that the transaction fails. The reason is that the `key` is being written by a different consumer goroutine. In which case, we have an option to retry the transaction. My question is, whether it's the only way or are there better ways to ensure that updates to a key are only sent to the specific consumer thus preventing conflicts?
It just depends wildly on what you are doing. Could be just a couple of % slower, could be 10x slower. 
`pkg/` already has a meaning in Go and that ain't it
So what's the benefit of `errors.WithMessage` over `fmt.Errorf`?
&gt; and other Go materials One of the best posts explaining this idea I've seen is by Andrey Petrov: [Code boilerplate: Is it always bad?](https://medium.com/@shazow/code-boilerplate-is-it-always-bad-934827efcfc7)
"Knock knock!" "Who's there?" "..........................................................................Java applet!"
My point was that, comparing values was *not* what I wanted to do. I was trying to compare the pointers, basically. 
A slice is a pointer to an initial element and two integers for the length and capacity. Therefore to compare two slices for "identity" you'd need to decide what aspects of the slice are meaningful for your comparison, and then figure out how to compare those aspects. For the pointer to the first element, you can obtain the same pointer value (but with a different type) using &amp;slice[0], to take the address of the first element. For the length, you can use len(slice). For the capacity, you can use cap(slice). If you want to compare all three of these aspects then you could write this: if &amp;a[0] == &amp;b[0] &amp;&amp; len(a) == len(b) &amp;&amp; cap(a) == cap(b) { // ... } This is not a "normal" operation that your average Go program would do, so there isn't a convenient syntax for it. I expect there's probably a different way to achieve your goal here within normal Go idiom, if you're willing to share *why* you are trying to compare slices (i.e. what's the *real* problem here?). 
I believe that aspect of the spec does not apply in this situation. An empty slice is *not* a zero-size value, but rather a pointer and two integers. The special behaviors for zero-size values apply to empty arrays (like [0]int) and empty structs (like struct{}). For example: var emptyArray [0]int emptySlice := emptyArray[:] fmt.Println(unsafe.Sizeof(emptyArray)) fmt.Println(unsafe.Sizeof(emptySlice)) 
GoConvey, imo. It's very minimal, with a nice assertion library.
Just to nitpick (slightly), real-time doesn't guarantee speed, as all real-tme guarantees is that _if you're running on bare metal_, all function calls will take a determined amount of time to complete. So if in testing `a()` takes 250ms, it will _always_ take 250ms. No more and no less. It's useful if you have to take action on passing input every x ms, so for example, if you have the following code: for ;; { x,y := getCurrentPosition() vec := getTurnDirection(x,y) turn(vec) } and you know that you have to adjust trajectory every 250ms, you would need some kind of RealTime Go, or you risk a GC at the wrong moment. But if you don't care that hard about latency (which is sort-of true in any multitasking OS - you have no guarantee that Linux won't preemt your code at any time), a GC can be faster (it can postpone cleanup to where your code isn't doing anything anyways).
One of the slides says: MOV R1, R2 // R2 = R1 Which is wrong. The MOV instruction moves the second value into the first, so it would be R1 = R2. Unless I'm missing something here, the talk isn't off to a good start.
Golang is a widely accepted alternative that's actually Google friendly It really doesn't matter, people know what you're talking about. 
Generic marketing post without barely scratching any kind of techniques employed besides broad mentions to "models" and "our algorithm". Also, there's not even a single mention of Golang or any simple hint of a CLI, server or anything. Might as well have used Pascal and we wouldn't know. Clickbait.
&gt; I believe that aspect of the spec does not apply in this situation. &gt; An empty slice is not a zero-size value, but rather a pointer and two integers where the "length" integer happens to be zero. An empty Array is, though. So if the underlying array is empty, it totes does. I agree that checking for length is not enough, strictly speaking, you should also check for capacity. But in any case, I think it is sufficiently unclear, what constitutes "self" in the case of an empty slice (much less a slice with capacity zero). Anyway, here, have a cookie :) len(a) == len(b) &amp;&amp; cap(a) == cap(b) &amp;&amp; (cap(a) == 0 || &amp;a[:1][0] == &amp;b[:1][0])
https://www.reddit.com/r/golang/comments/840mtv/an_r_package_to_embed_golang_in_r_and_r_in_go/
&gt; So I take it the alternative cmd/hello/main.go is not common Actually that is the more common one currently I think. It is a little bit odd to me as well, but it allows for multiple commands in the same repository and it makes it more easy to change the command name later on. There is the `-o` flag of `go build` where you can pass in a executable name to use instead of the default behavior, but this kind of breaks `go get`. That could be OK for some projects I guess. Depends on what it is. Instead of hosting on github you can also use bitbucket, gitlab and even your own domain if it returns a "go-import" meta tag. It also works with Private git repositories. Instead of the Repo URL you can also use any folder name you like, but that will break `go get` and everyone that wants to install it from source or wants to work on it will need to copy the source files in this exact folder manually. Why am I so adamant about not breaking `go get` you might ask: It is an absolute pain to explain to another developer how to install/compile the project if you break `go get`. I made a internal dev tool for our company in go once that broke `go get` and despite writing a step by step installation guide most would still try to compile the project in a different folder (which simply fails). The next tools I did where not breaking `go get` and it was so much more easy to get the team to install these tools. Having your project be go gettable is a huge benefit. 
thanks but that's not quite what I'm asking, I want to use shared libraries directly, not trough a message system or websockets.
No worries mate, have an upvote!
Are you sure? Examples from the documentation seem to agree with the slides: MOVQ g(CX), AX // Move g into AX. 
https://www.cs.uaf.edu/2006/fall/cs301/support/x86_64/ First line.
&gt; I'm somewhere between novice and intermediate Go development skill This isn't so much a language skill as it is a distributed system design skill. When an error is a value returned by a function, life is simple, you can lean on the language to handle things for you. When an error is some vaguely-defined blob that can be emitted from one of hundreds of different processes running across tens of thousands of nodes, you need to add a little context... 
&gt; return fmt.Errorf("doing a stuff: %v", err) Burying error context in a human-readable string isn't exactly "a better way"... unless your intended use case is that humans will sift through all your application's error messages for signal. This doesn't scale up very far...
Sorry, forgot to link the documentation I was quoting from: https://golang.org/doc/asm It mentions that it follows the input style of Plan9 assemblers: https://9p.io/sys/doc/asm.html &gt; they share many properties such as left-to-right assignment order for instruction operands
Wow… Why would they swap the arguments around like that. Seems like it would create more issues than it's worth. TIL.
&gt; Burying error context in a human-readable string isn't exactly "a better way"... When you take my answer out of context of course it isn't. But on a function that can return 3 different kind of errors, adding some extra info to the message through `fmt.Errorf` is better than returning `err`. If you want something more elaborate, return a custom error type. But OP did not ask for that.
sorry, Maybe this is better https://purrple.cat/blog/2017/06/09/go-packages-in-r-packages/ see more: https://purrple.cat/tags/go/
 1. Saw "New Era of Go Package Management" in the title 2. Expected a post about vgo 3. Read a post about dep 4. Felt mildly disappointed
&gt; Golang is a widely accepted alternative No it isn't. The language is called Go. You may use golang as a search term or SEO tag but writing Go as Golang especially in documents, is as wrong as writing Ruby as Rubylang and Java as Javalang.
&gt;You may use golang as a search term or SEO tag That's what I said. &gt;but writing Go as Golang especially in documents, is as wrong as writing C as Clang, Ruby as Rubylang and Java as Javalang. Didn't say that. Also, look at what sub you're on. &gt;but you said widely accepted Yeah, whatever. Semantics.
Maybe it would help if you told us *why* you’re attempting this?
Upon further research, here's what I found: https://en.wikipedia.org/wiki/X86_assembly_language#Syntax `mov src, dst` (as seen in the slides) is the AT&amp;T syntax. `mov dst, src` is Intel syntax. The GNU assembler uses AT&amp;T syntax by default, while a great deal of other assemblers use Intel syntax.
the best kinda correct
You could compare fmt.Sprintf("%p", a), but that feels dirty. 
OP is masking redirects to with an affiliate code attached.
&gt; Imports are queen What? 
I understand the go get thing.. makes perfect sense. Problem is, some of us still work on proprietary/internal code that we cant put out on public forums. I love the concept of open source and for some things it makes sense. Unfortunately for many of us small teams/individuals who are trying to build something to make money off of, open source isnt a viable option. I also want to use it for my own services that one day I hope to put in the cloud and make some money off of, so I can continue to work on my stuff. That is a ways off. Still, what I work on for the short term isnt going to be used by anyone.. if it gets to that point I would refactor it at that time. So, if I dont need anyone else to use my own code..e.g. its a server based application, not a library or being depended on by others, then it is ok to use a private repo and use local paths relative to the root right? 
This can get confusing if `cap(slice) != len(slice)` ex. https://play.golang.org/p/P3eC90q0xIy
I see a lot of people do this. I think separating the webserver and the PHP back-end makes a lot of sense as you can scale them separately. Also, if you're interested in slimming down Go application's container size, you might want to look up building your container "FROM scratch". I've seen images as small as a couple of MB that contain fully functional Go services.
The Go compiler is said to produce static binaries but it's not always true, for example on macOS the binary may be linked against libSystem and frameworks such as CoreFoundation or Security (depending on what packages are imported).
You can use go get with private repositories. All my go code is properitary/internal and I only made the mistake of breaking go get only once. I also work in a small team (Tech StartUp) and I am working on server applications (technically embeded software but the scale and architecture is more similar to a Web Application Backend or microservices). I would still strongly recommend at least trying to keep the project compatible with go get. Which is fairly easy to do if you have your code in any kind of git repo. In the end it is your decission if you want to ignore go get. It is possible to work without it. Importing relative to the root is not possible I think. The import name is always a path relative to the gopath. Technicaly it is always a absolute path minus the gopath.
Good one. BTW, the payscale study URL goes to your website !! 
The plugin package isn't cgo but allows usage of binaries with a main package and exported symbols in that package. It isn't available on Windows. It's like c-shared but can assume that the library is Go.
It's not the language's average-case performance that matters. Real-time performance is about *worst-case* runtime. The definition of real-time I've heard is that correctness of a routine's execution depends not only on its output values but on the time at which those output values are delivered. It is typically defined in terms of deadlines -- i.e. "we gather sensor data at time T=0 microseconds and need the results calculated by T=100µs". Further, "hard" real-time is realtime where even a single missed deadline is considered a failure of the system, whereas "soft" real-time is realtime where missing deadlines is bad but not considered a total failure. For example, an airbag deployment controller is hard realtime (a late-deployed airbag can kill someone) but a videogame is soft real-time (a frame rendered late is not a complete failure but degrades the quality). Most realtime systems I've observed lie between these two extremes. In practice there are very few GC's that provide hard realtime guarantees, and none that are very practical to use. The ones I am aware of are all for Java, and are some combination of difficult-to-use or high-latency. Azul's GC claims zero pauses but puts strong requirements on its runtime environment (both hardware and software) and code style, which make it difficult to use. Jamaica VM, which has fewer requirements on its runtime environment, has long worst-case pause times (on the order of 15 milliseconds). I've heard good things about Go's GC latency but haven't tested it myself. It might be okay for the softest of realtime tasks (such as a video game). However, its GC does not — and is not designed to — provide worst-case bounds on its execution time, so Go code (with the usual implementation of the language) cannot be guaranteed to meet deadlines as needed for hard realtime systems. From what I've seen, 100 microseconds is a fairly typical deadline for robotic systems (10% of the loop time of a 1 kHz control loop), though it varies a lot from system to system. &gt;1ms pauses are a no-go in that environment. Although I haven't tested it myself ­— results under high load on Linux are typically much worse than results when the system is otherwise unloaded — the first benchmark result I found searching "go latency benchmark" shows pauses in excess of 7 milliseconds: [Golang’s Real-time GC in Theory and Practice](https://making.pusher.com/golangs-real-time-gc-in-theory-and-practice/). So to answer your question, for the applications I used to work on Go is *at least* 70 times too "slow", and there's no guarantees that it won't actually be worse (because the garbage collector is not designed to make hard deadlines).
Here's more nitpicking: &gt; real-tme guarantees is that *if you're running on bare metal,* all function calls will take a determined amount of time to complete. So if in testing `a()` takes 250ms, it will *always* take 250ms. No more and no less. No, it places an upper bound on runtime, and you can have a real-time operating system (RTOS). For example, hard realtime code — running on a RTOS — may take an average of 10 microseconds but only guarantee that it always takes less than 30 microseconds. If that code is required to run in 20 microseconds then that's not good enough, but if its deadline is 100 microseconds then it is. &gt; But if you don't care that hard about latency (which is sort-of true in any multitasking OS - you have no guarantee that Linux won't preempt your code at any time) RTOS's are typically multitasking OSes, so "any" is an overstatement. Also, the PREEMPT_RT patchset allows you to make Linux hard realtime capable.
Taking this line of reasoning one step further: I don't understand why you have to copy/paste the name of the function you just called into an error return immediately afterwards when a stack trace would have done that for you automatically. I'm not detracting from your solution in any way; I do agree this is the idiomatic Go way to do things. But when people say that honestly don't want stack traces, and then their error messages look like a tedious, bug-prone, manual recording of the stack frames, I do wonder what exactly is going through their heads. If you have extra meaningful information to give, by all means do. But 99% of the "additional context" I see added to errors in actual code is something to the effect of "when calling f: ..." That's just a crappy stack trace.
How is it "blindly"? They wanted to work with errors, so they took a dependency on the errors package and used a function that does what they need.
&gt; In go you have to explicitly not take that error But you can just forget to check it. I have _more times than I'd like to admit_ been refactoring and/or been distracted in mid-code-sentence, and ended up with something like this: err = a() err = b() if err != nil { return err // or log or panic or whatever } No warnings. Pain in the butt to track down what's going on if `a` fails. Sadface for me. :(
That's fair. I spent basically the first 12 years of my development evolution with Python which I think is fair to say doesn't have distributed systems/parallelism in mind. I still have a little difficulty wrapping my head around the full practical usage of goroutines and channels etc etc. I get the abstract concepts of "you push values into channel X and then whoever has access to channel X can pop values off and do stuff" but the practical implementation of waitgroups and sentinel values and so on are not something I've had opportunity to work with at length.
Primarily readability. Also, if you have a big application, you will invariably need to access the stack trace in some places of your code, in which case you will need `errors.Wrap` anyway. So better to be consistent. There is also a performance cost with using the `fmt` package because it has to access the pp buffer pool and do dynamic dispatches due to `interface{}`. The `WithMessage` call is much faster. But this is only comes to play when the error is in your hot path. Otherwise it's a premature optimization. For small applications, `fmt.Errorf` should be fine. But if you are writing code for your company in a reasonably big codebase, my recommendation would be to use the `pkg/errors` package.
maybe that will help: https://medium.com/solo-io/building-hybrid-apps-with-gloo-1eb96579b070
&gt; The MOV instruction moves the second value into the first, That's not correct. It's the opposite. Go assembler moves from left to right. Each assembler uses its own convention. This is what Go uses.
&gt; I still have a little difficulty wrapping my head around the full practical usage of goroutines and channels etc etc. Even those of us that can wrap our head around it... tend to avoid it. It's an awesome feature, does cool things without having to write much code, but it makes a program exponentially more complex. And complexity breeds nasty bugs. In most cases, you should never need to use a goroutine or channel... don't worry about it for now. Go write code!
That's the assumption I've been working under. I definitely know enough about programming and software design to understand that parallelism, even in a 'native' environment, introduces...let's say disproportionate complexity. Doesn't mean I don't want to have a better grasp of the techniques, if/when they do become optimal/necessary. Thanks for the response, though, I always appreciate constructive feedback.
Could you expand a bit on this point - "Issues with marshalling JSON objects from Redis" ? What are the deficiencies that you found in the standard json package ? If it's a large response, I would assume the streaming decode functionality of the json decoder would suffice for this. Or are you saying the standard json decoder was not fast "enough" for your usecase ?
Thanks for the informative response! This makes sense. Hard-realtime software sounds like you need balls of steel to deploy. So it's safe to say Go is about an order of magnitude too slow in the best case scenario. Furthermore, it sounds like adding such hard-realtime guarantees may, in fact, blow out the GC pause times and put many unwieldy constraints on the execution environment. Meaning it's not as simple as "make it faster". Thanks again :) 
I think once you understand the slice is just a "view" of an array, `cap` and `len` start to make sense.
Dep is a dead man walking until vgo. 
&gt; If you are in the plumbing business, yes. Ha! Got me :D Honestly, I don't want to comment on exception-based language. I will say this: that much of the time no, errors are not exceptions, and the program should not exit by default and the implication that a stack trace is actually what you want to see most of the time is fallacious at best. &gt; I would say however that error handling in Go really is verbose This is fundamentally what I disagree with. The error handling is not actually "verbose" when done "properly". This is naturally anecdotal, and the word "verbose" is mostly subjective. I don't expect to convince you, but I am quite confident, based on the general sentiment I've seen, that Gophers who correctly handle errors in Go don't seem to consider it very verbose at all, and there's a correlation between experience in Go and this opinion. I think there's a basic phycological mechanism that drives this opinion of verbosity from newcomers, not a technical one. 
&gt; How is it "blindly"? They wanted to work with errors, so they took a dependency on the errors This is exactly my definition of blindly. You want to work with errors? Then work with them. If *after* working with them you discover that you *really* need an extra feature like stack traces that you cannot have without considerable effort on your own part then sure reach for a dependency. In my opinion, dependencies must worth their weight in gold. Do not prematurely add them in your codebase for features that you *might* need in the future or because they are nice to have. Vet your dependencies. Keep the dependency graph small.
&gt; I don't understand why you have to copy/paste the name of the function you just called into an error Because this is a contrived example. Without knowing what a, b and c do, it's not easy to write a good error message. &gt; That's just a crappy stack trace. Not really. Ideally we are trying to construct descriptive errors that [in just one line](https://commandcenter.blogspot.com/2017/12/error-handling-in-upspin.html), they perfectly describe what happened. 
These numbers are not very interesting to me. I won't build a massive API with the scale of something like Pornhub. I would be much more interested in time spent developing, SLOCs, number of libraries (or other dependencies) involved, difference in tooling, what devs said after they built it in Go compared to PHP etc.
Concurrent code can be hard to wrap your head around. 
&gt; What is the minimum amount of string formatting I should do by hand before I take a dependency on fmt? How far down the path of manually parsing input to my web app should I go down before I take a dependency on json? I am talking about 3rd party dependencies. The ones that you actually have to manage. &gt; and if a highly regarded package has a function that does precisely what you want, that should be your first stop. [No it shouldn't be your first stop.](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=9m28s)
The article you link puts things on multiple lines when there are nested errors: client.Lookup: ann@example.com/test/file: item does not exist: dir/remote("dir.example.com:443").Lookup: dir/server.Lookup: store/remote("store.example.com:443").Get: fetching https://storage.googleapis.com/bucket/C1AF...: 404 Not Found That... that's a stack trace. To be fair this example is not a "crappy" stack trace. It's a very nicely formatted stack trace that also helpfully includes the values of parameters for each function call (but unfortunately doesn't include line numbers, making it slightly harder to look up), but that is unmistakably a stack trace. I feel like I'm taking Mugatu's crazy pills, because I read that whole article, I've been using Go professionally for years, _and I still just don't get it_.
Thanks for the info. Initially I'm not convinced, but Rob Pike is obviously a smart guy who knows what he's talking about. I'll file this away to think over it some more and see if I change my mind.
Interesting alternative. I think I got into the habit of putting the `if err` check on a different line because the VS Code snippets make it faster to write that way (and--say what you want about laziness--writing it out manually over and over was _killing_ me). I'll see if I can twist the snippet into making that pattern convenient. Regardless, it's annoying that none of the tools warn about the case I mentioned, since it seems pretty straightforward to identify and it's almost certainly a bug.
No, that's is not a stack trace. *This* is a stack trace: javax.servlet.ServletException: Something bad happened at com.example.myproject.OpenSessionInViewFilter.doFilter(OpenSessionInViewFilter.java:60) at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157) at com.example.myproject.ExceptionHandlerFilter.doFilter(ExceptionHandlerFilter.java:28) at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157) at com.example.myproject.OutputBufferFilter.doFilter(OutputBufferFilter.java:33) at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157) at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388) at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216) at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182) at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765) at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418) at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152) at org.mortbay.jetty.Server.handle(Server.java:326) at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542) at org.mortbay.jetty.HttpConnection$RequestHandler.content(HttpConnection.java:943) at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:756) at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:218) at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404) at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228) at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582) Caused by: com.example.myproject.MyProjectServletException at com.example.myproject.MyServlet.doPost(MyServlet.java:169) at javax.servlet.http.HttpServlet.service(HttpServlet.java:727) at javax.servlet.http.HttpServlet.service(HttpServlet.java:820) at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511) at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166) at com.example.myproject.OpenSessionInViewFilter.doFilter(OpenSessionInViewFilter.java:30) ... 27 more Caused by: org.hibernate.exception.ConstraintViolationException: could not insert: [com.example.myproject.MyEntity] at org.hibernate.exception.SQLStateConverter.convert(SQLStateConverter.java:96) at org.hibernate.exception.JDBCExceptionHelper.convert(JDBCExceptionHelper.java:66) at org.hibernate.id.insert.AbstractSelectingDelegate.performInsert(AbstractSelectingDelegate.java:64) at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:2329) at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:2822) at org.hibernate.action.EntityIdentityInsertAction.execute(EntityIdentityInsertAction.java:71) at org.hibernate.engine.ActionQueue.execute(ActionQueue.java:268) at org.hibernate.event.def.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:321) at org.hibernate.event.def.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:204) at org.hibernate.event.def.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:130) at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.saveWithGeneratedOrRequestedId(DefaultSaveOrUpdateEventListener.java:210) at org.hibernate.event.def.DefaultSaveEventListener.saveWithGeneratedOrRequestedId(DefaultSaveEventListener.java:56) at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.entityIsTransient(DefaultSaveOrUpdateEventListener.java:195) at org.hibernate.event.def.DefaultSaveEventListener.performSaveOrUpdate(DefaultSaveEventListener.java:50) at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.onSaveOrUpdate(DefaultSaveOrUpdateEventListener.java:93) at org.hibernate.impl.SessionImpl.fireSave(SessionImpl.java:705) at org.hibernate.impl.SessionImpl.save(SessionImpl.java:693) at org.hibernate.impl.SessionImpl.save(SessionImpl.java:689) at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.hibernate.context.ThreadLocalSessionContext$TransactionProtectionWrapper.invoke(ThreadLocalSessionContext.java:344) at $Proxy19.save(Unknown Source) at com.example.myproject.MyEntityService.save(MyEntityService.java:59) &lt;-- relevant call (see notes below) at com.example.myproject.MyServlet.doPost(MyServlet.java:164) ... 32 more Caused by: java.sql.SQLException: Violation of unique constraint MY_ENTITY_UK_1: duplicate value(s) for column(s) MY_COLUMN in statement [...] at org.hsqldb.jdbc.Util.throwError(Unknown Source) at org.hsqldb.jdbc.jdbcPreparedStatement.executeUpdate(Unknown Source) at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeUpdate(NewProxyPreparedStatement.java:105) at org.hibernate.id.insert.AbstractSelectingDelegate.performInsert(AbstractSelectingDelegate.java:57) ... 54 more Granted, Go's stack traces are usually not as verbose because of our culture. But just a few goroutines and some complexity and they easily become tedious to work with. Not to mention the lack of confidence a user feels towards software that throws stack traces at them. &gt; I've been using Go professionally for years, and I still just don't get it. This is an excerpt from [The Go Programming Language](https://www.gopl.io/) book: &gt; When the error is ultimately handled by the program's main function, it should provide a clear causal chain from the root problem to the overall failure, reminiscent of a NASA accident investigation: &gt; genesis: crashed: no parachute: G-switch failed: bad relay orientation
pretty good tool, one thing that nmap could not do
If you are developing a main package that would become a library, using exported names makes sense. Another situation making sense, is when implementing interface that requires capitalized methods.
It's notable to mention that plugins compiled for the plugin package...are also in the forms of .so files. 
API testing is becoming a necessary aspect for enterprises of all shapes and sizes. So, it becomes critical to add API testing to your QA processes. Failing this, a business can face a situation where they may find themselves struggling with expenses due to performance issues and delays in production. If done right, API testing leads to reduction in costs, time and efforts. With quicker feedback and results, API testing enables a business to reap maximum ROI. To identify the best scenarios for API testing and how you can achieve the most comprehensive test coverage, join this free webinar, 'The Future of API Testing - Trends and How to Propel Your Testing' on Tuesday, March 27, 2018 at 11:30 AM PST. Register with the following link: https://info.qasource.com/signup/the-future-is-api-testing
You could always use pointers: a := []int{1, 2} p := &amp;a c := []int{1, 2} if p == &amp;a { fmt.Println("do stuff") } if p == &amp;c { fmt.Println("this should fail") } [Playground link](https://play.golang.org/p/yYtO8ZzHoj9) 
Maybe the fact you need to create perfectly matching go objects to decode data into? If json data is changing this is a problem. I was put off by this but found another json lib that works in more traditional way
&gt; No, that's is not a stack trace. This is a stack trace: I hope you said that with a Crocodile Dundee accent, because that's definitely how I'm imagining it. Personally I don't feel like the Java example and the upspin example are all that different. They're both fundamentally ordered lists of things that were done to arrive at the error. I guess that's the difference in the end; Go is putting a huge emphasis on conciseness. I'm putting a lot of emphasis on not having maintenance work to keep the context from getting out of sync during refactoring. I can learn (and have) to scan that wall of text, and it only took me a few seconds to pick out the meaningful parts of the Java error. I don't currently have faith that any amount of familiarity with Go will make me confident against the implied maintenance work of keeping error context in sync when code is refactored.
I have never seen any value in the systems watchdog in go, services either panic and die anyway or, much more rarely if they do dead lock only part of them does and they continue to serve simple requests anyway - you just grow in the number of goroutines running. I have never seen a complete deadlocked service. Basically you cannot just throw in a watchdog without truly understanding your application and how it could possibly deadlock and if you know this then you can prevent the deadlock. The notification of startup is very useful however.
I believe `pkg-config systemd --variable=systemdsystemunitdir` is intended for actual distro packages. Your own files should go in `/etc/systemd/system`
I saw the one paragraph, but I don't feel this is enough to emphasize how difficult it is to do correctly. Sadly, most people will just copy paste your last example which does not really add any value to a typical go service (for the reasons I mentioned). It would be more better if you could expand that paragraph into a final example showing a complete solution with basic possibly contrived health checks.
I use it to protect an open API against DOS. If you have an operation that's computationally rather expensive, you can require a proof of work from the client before running it. The goal is to make sure that the client has to do at least the same amount of work that you are doing.
Outrageously exhausting!
There is `map[string]interface{}` for that. Can you explain what do you mean by the "traditional" way ? AFAIU, you _have_ to de-serialize json to a struct. If your json format is changing, you need to use `interface{}`, even ffjson cannot help you there.
The last example transforms a classical "external" healthcheck (that you could ask your load balancer to do) into an equivalent internal healthcheck. It's pretty basic, but it has some value as instead of just triggering an alert, it would solve the issue by restarting the service. What is missing, however, is an example of passive healthchecking where various goroutines report for healthness to a watchdog component.
I see `map[string]interface{}` even in my dreams now ;) I mean using library such as [gjson](https://github.com/tidwall/gjson) that doesn't deserialize json into struct. In this case it's using custom path syntax to get values.
But as it stand it just goes to the index page which will be very unlikely to show any real problem with your application - all the health checks we use explicitly call a separate status page as most index pages are too simple to correctly detect the health of an application (and nor would you want them to). The only time I have seen an external health check on the index page be useful is as a basic check to see if the webserver is running yet or completely crashed - both of which systemd is aware of and a watchdog is not needed. Adding examples of health checking would be a valuable addition.
thank you for this, I´ve studied the code and found no low level signature primitives. I'm guessing they might be imported from other packages.
"Our main goal being efficiency (speed) and as we discovered, the standard JSON package isn’t feasible for our particular use case."
OK, understood. And I agree.
I'm just starting off with putting my `main.go` in a cmd/appname folder and then developing from there, so it's not a *huge* impact, comparatively. There's [pendulum](https://github.com/titpetric/pendulum) and [go-web-crontab](https://github.com/titpetric/go-web-crontab) and [sql-as-an-api](https://github.com/titpetric/sql-as-an-api) for example of such small projects that start of with the cmd folder there. I usually refactor because I want to add more executables that do other things, so I don't mix everything together. Starting with `cmd/` from the beginning skips this kind of refactor, as everything is already in place. I have my build scripts pick up everything under `cmd/` so that all the binaries are built when I add new cmd folders over time.
A small remark: &gt; The classic way for an Unix daemon to signal its readiness is to daemonize. Note that this used to be done this way, but is actually not a very good idea. For a while now, the common approach has been, let something else take care of that if necessary. On Debian/Ubuntu platforms, before systemd took over, this was done using `start-stop-daemon`, which handles running a process in background, PID files, and generic interaction with the init system.
The proposed "date parser" returns a time.Time object. That's raw data that has been interpreted. Your argument is just plain wrong.
gotcha. Thanks.
I think you're missing the point OP is trying to make. Readiness signalling by **late daemonizing** isn't just "lol you reimplemented start-stop-daemon"; you're keeping your program in foreground *until it is ready to serve requests*. start-stop-daemon **cannot** do this; it immediately forks to background. If you start several daemons in a row without readiness signalling, the later daemons will be started before their dependencies are actually initialized and servicing requests. Now, do you need this feature? It depends. Most of the time you need to be able to deal with external daemons failing anyway, so it's not a big deal, but sometimes it's a nice convenience feature. *If you don't need readiness signalling*, you don't need any systemd-specific integrations in your Go programs (and in non-Go code, you can continue to use late daemonizing). If your program exits with a non-zero return code on errors, and doesn't daemonize at all, systemd and start-stop-daemon are idempotent.
My favorite is vim with [vim-go](https://github.com/fatih/vim-go).
&gt; How exactly does context get out of sync during refactoring? The main way would be renaming or moving the method or class during refactoring, and not remembering to update the `const op...` line accordingly. Or copy/pasting the method and forgetting to change op in the new one. Changing the parameters of a method might also generate extra maintenance, but the compiler might at least help you out there. Other maintenance work comes from my perception that the context provided by this wrapping is simultaneously partially redundant and also incomplete. if err := authorize(user); err != nil { return errors.E(op, user, errors.Permission, err) } The errors.Permission type isn't adding any information here. In this isolated example it's exactly equivalent to saying "authorize failed," and now you have to remember the mapping of authorize==Permission, and make sure you use Permission anywhere else authorize gets called. If Permissions is used elsewhere, then it's actually _hiding_ information. Perhaps I'm missing something, but it looks to me that if both `authorize` and `loadProfile` can cause the Permission error, you now can't be sure from this context what actually happened. Now you have to add in more context to keep them separate, and every time you add or move an error-generating call, you need to compare it with all of the other error generating calls in its destination and make sure they are sufficiently distinct. All of that is maintenance work that would have been unnecessary/automatic if the errors carried stack traces.
My favourite code editor is vim with vim-go because i develop on Linux, OSX, and raspberry.
Vim and vim-go for me too, fantastic plugin.
VSCode FTW
When I linked the article about error handling in Upspin, it was to make a point that you can easily create good error handling specific for your project without depending on stack traces. One of the simplest forms of error handling we can do is something like this: return fmt.Errorf("deleting user %q: %v", username, err) I don't see how this can get out of sync. Following this pattern, in combination with other good error handling practices like custom error types. we can end up with descriptive error messages that allow to easily understand what the problem is and where it happened in our code. 
&gt; The proposed "date parser" returns a time.Time object. That's raw data that has been interpreted. Or is `time.Time` simply a convent structure to hold the machine representation? I mean, from a theoretical point of view, what's the practical difference between using a `time.Time` structure or some other kind of AST? It only claims to be a *parser*, not an interpreter. Your interpreter is quite free to flip the month and day values around, if that is how you want to interpret the value.
VSCode
Another one for vim (or really neovim). My problem is once I learnt the vim keybindings I cannot use an editor that does not have them. I tried atom for a while - required plugins (vim support, go support etc) eventually made it bloated, slow and unstable. So I moved back to nvim. I tried vscode for a while - but required plugins (vim support, go support etc) eventually lead it to sometimes getting confused about my undo history and clobbered (losing work and forcing me to reset via git) my code about 5 times (one every month or so) before I moved back to nvim. I have tried various other ones but always end up going back to nvim due to their lackof support for vim keybindings or just becomming unstable/slow or lacking support for some language.
https://www.techempower.com/benchmarks/#section=data-r15&amp;hw=ph&amp;test=plaintext&amp;l=hr9nun
Seems fixed now.
And for building Go app images, they could also look into docker multi-stage builds, so they build the full app in the official Go container, and then copy that to the final-one.
VS Code. The Go extension is great, performance is okay, and the UI works great for me. In the past I've used neovim (but eventually I just liked the GUI of VS Code too much) and Sublime (also great, faster than VS Code, but if you want to use it at work, you always have to convince people to buy a licence — one shouldn't really use their private one at work — and that's just annoying). 
👋🏻 I use it for generating sdks but not for user interface stuff. 
It's been a long time since I've touched PHP, and there are probably a lot of frameworks and tools to facilitate writing an API, but it never struck me as a language suited for this to be honest. Go would be a much better fit.
IntelliJ Ultimate. It's a sluggish, RAM-heavy monster, but I am in the process of rewriting an aged PHP app into Go so I need good syntax support for both, and it is the only JetBrains product that does that. I was a PHPStorm user for years before I started programming in golang so I am very familiar with it, and I really like the integrated tools such as the amazing refactoring, testing, Sql Workbench, diff tools, local history, etc.
I'm also using vscode it seems to have become the defacto standard editor for Go ... I'm wondering why other editors like Brackets or IDE's like JetBrains Goland aren't rising up in popularity everytime I surf the web I see at least one Goland ad somewhere... 
&gt; but if you want to use it at work, you always have to convince people to buy a licence IMO it is a non-issue in professional web or software development. $80 is less than a few hours of work for a lot of Go developers, and if it is the best tool for the job, it would land up saving the company this many times over. I bought ST3 just so I can open and refactor 8MB CSV files which I regularly had to do funky stuff with for a previous project.
GoLand. Has alot of power / functionality, debugger if needed on those rare occasions, javascript / jsx / webby, git integratiosn, docker integrations, terminals, db integrations all sorts. Sometimes all the tools in one place can be bad, but I find it can be handy if you are working on a couple projects at a keystroke I have a terminal in the root of the directory, or connecting to my local db to check stuff etc with 0 time. 
It's never (at least for me) a problem of spending $80, it's about getting the paperwork through. Around the third time I just couldn't be bothered with it. 
emacs
I'm well aware of the late daemonizing and issues surrounding background processes, readiness indicators, ... But I can guarantee you that a lot, if not most of home-brew self-daemonizing software does this wrong, certainly when trying to do late-daemonizing. I've seen tons of stuff going wrong because of this, and fixed a lot of SysV-style init scripts to work around issues, with silly stuff like waiting for a port to be opened, see if processes are still running, ... Yes, `start-stop-daemon` isn't the end-all solution, but it does proper forking catching all corner-cases, [like this](https://stackoverflow.com/questions/881388/what-is-the-reason-for-performing-a-double-fork-when-creating-a-daemon) - but the init script then still has to handle errors etc - which is always messy, but better than having a shitton of zombie processes on a production server because some 'rockstar' developer was convinced he knew what he was doing. I was just commenting on the 'classic way', which is this way due to init systems being a crappy and neglected for a long time. Not that I'm a fan of systemd, quite the contrary, but that's the one thing they do right. Not too happy about how the system-related management is done, but when it comes to managing the services themselves, the end-result is very good. &gt; If you don't need readiness signalling, you don't need any systemd-specific integrations in your Go programs (and in non-Go code, you can continue to use late daemonizing). Or if you're not running systemd. Let's say on Windows, Mac or *BSD, but afaik, it should check for the `NOTIFY_SOCKET` env var to indicate it's readiness, so that's usually not an issue, but I'd still do the whole notification stuff in a separate file only compiled on Linux tbh - since the `go-systemd/daemon` lib doesn't seem to care.
+1 for VS Code with the go extension. The interactive debugger is wonderful, as is the integration with the formatter, linter, and with go's native unit tests (one-click running or debugging of individual tests).
Ah, I understand. Yeah, that can be a pain in the ass. Luckily I have always worked at small enough outfits where everyone is on a first name basis with everyone else, and so pushing through something like that would be a simple matter of sending an email to the office manager with proof of purchase. I did some freelance work for Havas back in the day, and the amount of people that my invoice had to go through before it got paid was ridiculous. And don't try and get anything done on a Friday afternoon...
Ah interesting, I will make sure to keep your package in mind if I ever run into problems similar to yours.
Goland here. It does a really great job of understand Go, and provides me with the utilities I need like file watchers to run goimports and that sort of thing. It does a great job of catching potential bugs too. I have 16GB of RAM, I don't mind giving 700MB to my editor. I'd give VSCode a go, but I use JetBrains IDEs for quite a few things. If I did make the move to VSCode, I might actually really like it, but then again, I also work with Java / Scala sometimes and IntelliJ is just awesome for that.
Same here but of late I have been using the vim plugin for goland.. not perfect but it does help
Another one for emacs.
I'm disappointed that I still have to battle daily with any package management tool that's currently production ready for Go. Glide is abandoned, and as a result has some weird bugs. It also doesn't let you update packages if they won't compile - I don't care if they won't compile when I download them, I want to download them so I can see what I need to do to update my code! Dep is similar, but works better overall, but again, tries to do too much to "protect" you. I know you can turn some of this behaviour off, but you are still left with what Glide does, it won't let you download code that won't compile (e.g. missing package for example). I really hope that vgo solves this problem. I think that the semantic import versioning should solve it if people use it correctly, because it will mean the old and new package can co-exist during that refactoring period. Right now, any time that happens it's a really horrible process that I end up needing to go through. I have to wipe out my vendor directory, and revert to using `$GOPATH` until I've done refactoring, because if any mix is used then things start to complain about incorrect types being used (e.g. type in vendor directory expected, but got on from `$GOPATH`, or vice versa). The thing that still frustrates me about this particular problem is that all of these tools have had this problem when other languages have had better solutions without these issues for years.
Interesting. Gin seems like the more popular framework and apparently the faster framework but I’ve been using Echo because it has much better documentation. 
Same, I've used mostly react native with the apps I developed and its getting good, especially when using expo. But still, java script :/
GoLand / IntelliJ is the third most used editor for Go, according to the latest Go Team survey. Vim is the second VS Code is the first. I think it matters who you speak with, and if they don't mind paying for tools or not.
I have used both. Currently (having to) use PHP at work. I believe and want to argue that development cost with Go may even be lower for a lot of use cases but I don't know which in specific. I have not enough free time to try out implementing a whole system that would be valuable enough to provide a meaningful example for this argument. There is a difference between saying "writing an API" and actually writing an API - and my coworkers, understably, are only interested in the latter.
I highly encourage you to try the upcoming release in this case https://blog.jetbrains.com/go/2018/03/12/goland-2018-1-eap-5-dep-integration-smarter-auto-imports-scratch-files-faster-rename-and-find-usages-and-more/
I actually had less luck in small outfits — it's not much fun being the first person to ask for someone non-standard, and the company struggling to figure out how to properly buy something from a company that's not local. Large outfits usually had some "extravagant" developers, and the paperwork was annoying, but at least clearly defined. 
Thanks for the hint I will try it!
Why not just Type=simple and exit on error?
Again, your argument is incorrect. Time is a numerical value. It's seconds and nanoseconds. There's no "flipping of month and day". The parser interprets string data as a value in seconds and nanoseconds. So please, stop arguing that "time.Time" is some loosely interpretable structure. It is not.
Yes, I just wanted to confirm whether indeed that was the issue OP faced or was it something else.
&gt; Time is a numerical value. `time.Time` is [very much a structure](https://golang.org/src/time/time.go?s=5813:6814#L106). &gt; There's no "flipping of month and day". Come on, [don't be silly](https://play.golang.org/p/DabvgChb1Fu). 
Vim all the way
tmux + neovim + [vim-go](https://github.com/fatih/vim-go) + [vim-delve](https://github.com/sebdah/vim-delve)
Perhaps you used one of the variable-length encoding functions by mistake?
I recommend to use on the server. but, the possibilities will spread depending on your idea.
You are using [PutUvarint](https://godoc.org/encoding/binary#PutUvarint), giving you [this resoult](https://play.golang.org/p/NHAYfLvL7gx), which is expected, as that's the [varint-encoding](https://developers.google.com/protocol-buffers/docs/encoding#varints) of 5000. Use `binary.LittleEndian.PutUint64` or `binary.Write`, as /u/dogestopmewow demonstrates to get fixed-width little-endian encoding.
How about if len(myMap) &gt; limit { ... }?
Yes, it now uses a hand-written recursive descent parser I believe.
package main import ( "fmt" ) func PrintHello() { fmt.Println("hello world") } func main() { PrintHello() } with go build -buildmode=c-shared -o simple2.dll simple2.go but i can't load the dll, is it 64bit DLL? 
I strongly recommend using [PGP](https://godoc.org/golang.org/x/crypto/openpgp) to encrypt your data, unless you have *really good* reasons not to do so and know what you are doing. Crypto involves a lot of subtlety, using a battle-tested standard protocols, algorithms and implementations will save you. &gt; Say like, it always takes 2 seconds to decrypt the data, reguardless of the machine speed? That is impossible.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://godoc.org/golang.org/x/crypto/openpgp) - Previous text "PGP" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
Thought about that first, but then, if the service ended up serving more users than i planned (say), cleanup could be running all the time. I would have to be readjusting the limit from time to time...
You can do this with Go too with the [`-buildmode` argument](https://golang.org/cmd/go/#hdr-Build_modes)
Perhaps you could make the limit be a function of the number of users?
When you clean up the map, save a high-water mark that is, say, 1.5-2x the size of the cleaned-up map. Then, use that as the limit for future checks.
&gt; The yacc tool (previously available by running “go tool yacc”) has been removed. As of Go 1.7 it was no longer used by the Go compiler. It has moved to the “tools” repository and is now available at golang.org/x/tools/cmd/goyacc. https://golang.org/doc/go1.8#tool_yacc The first version of Go written in Go (self-bootstrapped) was [1.5](https://golang.org/doc/go1.5#c).
You probably want a DLL to contain a go package other than main. You can do some trickery to run a DLL on its own, but generally you run an exe that calls into the DLL. https://stackoverflow.com/questions/3044395/how-do-i-execute-a-dll-file
Why not just do it every Nth run? if run%N { // code } run = run % N + 1
You could use [sync.Once](https://golang.org/pkg/sync/#Once) to make sure the cleanup code runs exactly once regardless of how many times it is called.
``` if counter++; counter % 100 == 0 { /* code */ } ``` or ``` go func() { for range time.Tick(1*time.Minute) { // code (take care to avoid data races!) } }() ``` or ([shameless plug](https://github.com/CAFxX/gcnotifier)) ``` go func() { for range gcnotifier.New().AfterGC() { // code (take care to avoid data races!) } }()
There is no way for us to tell from the information given. Did you build it with a 64-bit Go compiler? Set the `GOARCH` environment variable to "386" if you explicitly want to build a 32-bit x86 binary. Otherwise, Go will IIRC assume that your target is that of the compiler.
Intellij IDE Goland. Much improved and is part of the Ultimate pricing which we use for Java and web as well.
ram heavy sluggish? Are you loading 100s of source files at once? Mine is crazy fast and touches only a couple GBs of ram when I have 3 instances open with 3 different projects, while running our spring boot app (in one). Near instant speed except when it indexes. Are you on an old laptop with low memory? As a developer I would hope you are working on a machine with at least 8GB but more so 16GB ram or more. I do know years ago when I only had 8GB everything was slow because OS, browser, ide, and more all running didnt leave much memory for anything else. 
Give Goland a try.
I really enjoy [chi](https://github.com/go-chi/chi).
Goland, which is IntelliJ's standalone Golang IDE. It does use a lot of RAM like another person here said, but I think that in my experience, nothing has come close to a complete tool like it has. It has automatic imports, and if you dont have the import, you can have it "go get" it. Also you can have it auto optimize imports and "go fmt" on save. 
I know this is probably against the norm, but spend your own money and write it off on taxes. I buy my own keyboard, mouse, laptop, monitors and IDEs because I want to enjoy working the way I do best. For the money we typically get paid, to me its well worth spending on my own stuff and not being stuck with most offices measly not so great options. Especially when it comes to keyboards.. nothing beats a 2 piece split key mechanical keyboard. Those old style one pieces where you cramp your wrists to type.. no thank you. But no company I have ever worked for offers these cause they cost around $300. I dont get it.. so what.. you pay more in a few hours.. why not offer good quality keyboard and mice, and chairs, monitors and desks. A sit/stand desk is $400 to $1000. Even in start up mode, at least offer the developers maybe a day off paid if they buy their own stuff or something. 
[Yes.](https://texlution.com/post/golang-canonical-import-paths/) Also read [this](https://golang.org/cmd/go/#hdr-Remote_import_paths).
It will come.. it is a relatively new bit of kit.. I have no doubt given IDEAs resources and the popularity of Go especially how fast it is growing compared to other languages.. they will add all sorts of goodies sooner than later. IDEA doesnt sit around. They surpassed Eclipse.. and they charge you for it.. as well as other products they make are fantastic. So just trust that they will continue to add features/capabilities sooner than later. They want to become the #1 Go IDE.
I did not know about the `import "path"` comment. Thanks.
Is there no way to tell it on the command line to use 32-bit or 64-bit? I cant imagine you have to define an env variable to get it to switch.
Never thought of running a DLL.. always felt they were libraries. Can you build DLLs in Go that Windows apps use? I would assume so, just not sure if you have some special "export" like syntax in go functions that indicate they can be called by other applications that link them? I ask partly because I know several windows apps that use DLLs as plugins.. curious if you could actually write a plugin in Go. If you can, is there a way Go can call in to other DLLs as well? 
`simple` services are considered started as soon as the program is invoked. If it immediately crashes because of a configuration problem, you still see a success code until you check later. It's also too late to prevent dependent services from starting. If it takes a long time to start because of a slow database and doesn't open its listening socket right away, then dependent services might already have started and tried to establish a connection. `notify` type services are the same as `simple` except that systemd will wait for the `ready` callback before considering it started.
not entirely relevant but rob pike had a nice talk on writing a lexer in Go: https://www.youtube.com/watch?v=HxaD_trXwRE&amp;t=1579s
Very relevant to be honest.
hmm i just found i downloaded a 64bit gcc……
It's great if your project structure works for you. Definitely keep it as simple as possible. Having said that I do have a few comments... Vendoring is a pretty common and widely used concept. You are lucky you don't have to use it. Others are not so lucky :-) There's a bit of confusion here around the '/test' directory. The repo doesn't say that you should put unit tests there. There's more to testing than unit testing though. The '/test' directory is where you put the extras you need for testing (additional tools, data, etc). The '/docs' directory is not a replacement for the inline godoc documentation. It's meant to be used in addition to what you can accomplish with godoc. The '/internal' directories are useful for libraries and apps equally. You'll be surprised when and how others will try to use your code :-)
Have you seen the Kubernetes and Docker code? They use the '/pkg' concept quite a lot...
Maybe better to make it a function of the delta of map size. Save the old map size and check the current map size. If more than a threshold, then delete. Similar to /u/thequux's solution.
It's a set of common 'patterns'. These are not standards coming from the core Go dev team. They are unofficial / defacto standards that emerged naturally in the Go ecosystem. Feel free to do your own research and look at the top Go projects and you'll notice the same patterns yourself. 
Yes, those are so-called vanity import paths, and you can create your own. It is documented in the second half of https://golang.org/cmd/go/#hdr-Remote_import_paths section. Also, it’s worth mentioning that the Go compiler doesn’t deal with this, the `go get` tool does. The Go compiler just finds Go packages on disk, in your GOPATH workspace where `go get` has placed them.
&gt; I know this is probably against the norm, but spend your own money and write it off on taxes. That sounds like a lot of work. I mean, at home, sure, I have that (even Sublime, though I don't use it much anymore). But at work? And when I change work but keep my software? I don't even want to think about it. It's different as a freelancer, of course, but that comes with all the problems of being a freelancer. &gt; A sit/stand desk is $400 to $1000. Bringing those with me into an office is a lot bigger problem than any tax regulation. It _is_ actually annoying that it's so rare for a company to invest into those, they really do pay for themselves. 
BTW Goland is not free and VScode is aggressive in pushing plugins and improvement for Go compared to Goland
So in the example above, `go get` would place the file in `$GOPATH/src/upspin.io/cloud/storage/disk`?
I prefer vim with fatih/vim-go, ctags and few custom vimrc flows... it works nicely, also because I like to use same code editor in all my workspace unless it doesn't suit the programming language even with customization
Precisely. You can try it. Do: ``` export GOPATH=/tmp/new go get upspin.io/cmd/upspinserver tree $GOPATH/src ```
Yeah that works as well, albeit requiring a new variable. BTW isn't it actually ``` if run % N == 0 { //code } run = run + 1 % N ``` 
I've only done it in C++, so I'm not sure :) My educated guess is that Go exports types and functions from a package that it would normally export -- first letter capitalized -- and you don't have to mess around with the [`__declspec( dllexport )`](https://msdn.microsoft.com/en-us/library/3y1sfaz2.aspx) fun stuff that you do in C++. [Here's a short example in *nix world](http://snowsyn.net/2016/09/11/creating-shared-libraries-in-go/). Maybe that's good enough to get started for Windows?
Yeah that works as well, albeit requiring a new "global" variable.
If I do not really want to handle an error I use a checkError() function: func checkError(err error) { if err != nil { log.Fatalln(err) // Alternatively, use panic(err) } } Makes writing the program itself easier, e.g. your code could look like this: … a, err := someFunc() checkError(err) b, err = someFunc() checkError(err) …
I use gomobile for couple of my projects, just `bind`, not full native Go app. Library is compiled as `c-shared` and JNI bindings are generated for you. Then you just import library and use it in Java. This way UI is in Java and all network calls are running from Go lib. You can also wrap some interesting C libs, compiled statically with your lib, much easier then to write JNI wrapper yourself for example. I don't like HTML apps, not on desktop and not on mobile. 
GoLand supports debugging tests for almost a year now, if you have any problems with them, please open an issue on the tracker https://youtrack.jetbrains.com/issues/Go and someone will help you. 
*gasp*. You just made me so happy :D. My current job has be working in Java, but I'll be working in Go again soon!!! This is the best thing ever!
Not sure how quick the Go plugin for VSCode is, but for GoLand there are two tracks: stable, gets released around 3 times a year, with patches between releases and EAP where you get less stable releases that may contain bugs from time to time but they get released almost weekly. I would invite you to have a look at the blog https://blog.jetbrains.com/go/ to see the changes that are done weekly to GoLand and see what the next stable version will feature.
You are missing `import "C"`, main() can be empty, and you must `export` function you wanty to be avialable in .dll, like this: ``` //export PrintHello func PrintHello() { fmt.Println("hello world") } ```
Try TypeScript .. makes it all more fun
do you have a repo to show?
Sure, you can check https://github.com/gen2brain/crtaci and https://github.com/gen2brain/bukanir . Both have library that is compiled with `gomobile` and used in Android project. Also, both have desktop app, with Qt bindings. Bukanir Android app is currently broken, I want to rewrite torrent part to native Go now that lib for that exists. Those are first projects where I started using Go so code can be strange at many places. Also, I never programmed with Java before that, but it is not that difficult.
Should be noted that it has to be done w/ MinGW+gcc sadly.
Not sure if this is what you are looking for, but I gave a talk about gomobile (mostly the *bind* option, to make your logic in Go, but your UI in java or something else, like react native) at FOSDEM last year, ([video](https://www.youtube.com/watch?v=OaSkOjew1D4) , [slides](https://talks.madriguera.me/2017/fosdem2017.slide#1) ) it might be a little outdated, since a few things have changes (minor details). I also have a few examples/related code : * https://github.com/conejoninja/MyGoApplication * https://github.com/conejoninja/gobindings We have a [Go + React native app](https://github.com/F7U12Team/password-manager) too (sorry, the react code is minimized). For a "full go" app, as far as I know, you need to rely on openGL, maybe something like [andlabs](https://github.com/andlabs/ui) or [nuklear](https://github.com/golang-ui/nuklear) works, but I didn't try any of them
Yeah that's an interesting one thanks, been on my list to try for a while should really make the time!
I like LiteIDE
Vim.
Sublime Text with neovim key bindings + a package for Go autocomplete, build and stuff. Started with Gogland (that was the name during the beta), moved to VSCode with a Go extension, then neovim on my terminal with a Go plugin and finally settled with Sublime. I think an IDE like Goland is good if you're new to Go and doing a project wholly based on it, but sticking with a text editor with familiar key bindings and separate language extensions takes care of almost everything.
Cryptography is a field littered with land-mines, where the slightest innocent misstep can cost you dearly. See padding oracle attacks for a sense of how easy it is for something seemingly secure to accidentally leak everything. As much as is possible, stick to established code and projects to do the lifting for you.
Honestly, and no offense to you, but I am baffled why any developer today wants a macbook with its limited ram and expansion options at 3x the price of better hardware. Windows 10 is rock solid, and once you are in IDE land, the OS UI is non-existant anyway. Or do what I do, fire up a few VMware player linux envs and go to town. I have a laptop with 64gb ram, 4 ssd drives (to be fair it was a desktop replacement a year ago, but also 1/2 the price of a loaded macbook pro that didnt come close to the performance of this). I just dont understand the need to be stuck in their ecosystem and limiting overpriced underperforming hardware. I switched to a desktop for day job work, and laptop only when i am on the road. As a developer I need to have a system I can count on to not slow me down. Seems most developers (again not trying to offend) have this need to own a macbook because they feel the OS is so much better. The OS is just the OS. I need my tools to perform, and that means I need SSD and RAM.. could care less about the OS. 
You think 8GB for OS, browser (known to be ram heavy), IDE, and running some sort of application (usually an application stack that is ram heavy on its own) is enough today? I mean, hey.. more power to you if you work in that range and things are good. Not me. For microservice work I typically am running multiple dockers for db, messaging, logging, server/api, and more. If you are able to work on small projects and dont need browser and other things open at the same time (or in my case dozens of tabs), more power to you. 
yep that's very handy :)
this benchmark always confuses me a bit tbh. Comparing Go there to PHP and NodeJS... i'd say Go is faster, but those benchmarks don't reflect that at all. I need to look at how the benchmark is actually made to see why Go is doing so "bad" there.
That's cool! To me, reducing code bloat is like a sport, if you enjoy optimising code. In the past week I managed to add features and still reduce the file length to about &lt;1900 lines. And there's still more to make simpler. Hopefully, one has learned to code better from the experience.
Hi, now after more than a week, there's support for colour PNG, JPG and GIF images. It also draws transparent PNGs, but you have to specify the background colour to use. 
As a long time go dev, my advice is to ignore the import path and trust `git ls-remote --get-url` and `git rev-parse HEAD`
PHP was never a fair comparison. It would be interesting if you compared other options e.g. Node vs Scala vs Rust vs Go etc.
&gt; 3x the price of better hardware Purely spec wise, yeah. The MacBook Pro still has one of the best screens, trackpad, I/O speed, and overall build quality out there. But don't forget it's an ultrabook. The "Pro" in MacBook Pro is a misnomer. I would prefer a slightly thicker machine with faster hardware, upgradable RAM, and bigger battery life. But I digress. I generally agree with most of your points, but for 99% of the time (while Slack and Chrome are using up a lot of RAM) the processor is idling along and I don't notice any slowdown in my workflow except resizing specifically IntelliJ Idea on my 4K display - (which to be fair is a Java app which OS X is rendering out at 5120x2880 and scaling down by a factor of 4, and any PC without discreet graphics would stutter slightly) I have a dedicated gaming desktop PC with an RX580 8GB, 32GB RAM, Dual SSDs, Core i5 (soon with water-cooling) etc sitting unpowered about 5ft from me right now - I still choose my MacBook Pro with external monitor, KB and mouse over that because 99% of the time I am not noticing the difference in performance (Go compiles very fast and that is what I spend 90% of my time coding in) and I have been using OS X for development work for the last 10 years. Perhaps the IDE takes a couple more milliseconds to highlight that I redeclared a variable, its not consequential.
PHP? 
Nice! 
yeah, not related to Echo vs Gin. Sorry :D
Well you lucky son of a.. 90% time in Go! I am basically .09%.. learning. Wish I could be full time on it! Yeah, I hear you.. Go seems to compile pretty fast. I actually have done basically hello world examples and a test payment process thats it. So I see your point. Still.. fire up that desktop man! :D For me, I run multiple docker instances with various things for our server setup, not even scale running yet, just individual instances. This sort of thing crushed my old macbook with 16gb ram. When not running all that, it was fast enough for development. I actually develop inside of vmware player with linux, and it is rock solid fast even the GUI. Every now and again I get a 30 second or so pause and have no idea why.. can only assume it is some sort of memory cleanup routine or something. On my laptop it is smooth, but on my desktop which is threadripper, 64gb ram, 1070 gpu, I run 3 VMs, each with multiple dockers, a game or two, browsers, etc.. doesnt skip a beat. Such a beast of a machine. I would need to bring it with me if I ever have to go back working in an office! 
I dont even see them on the benchmark
That is not necessarily true.. an API microservice that handles 1000s of requests each taking a little chunk of ram could take quite a lot of ram across many threads. Hopefully some sort of load-balanced auto-scale is in place to keep tabs on processing/ram consumption per instance and can fire up new ones automatically when certain thresholds are reached. How do you deploy your applications? How do you scale them instantly in the case of a sudden spike in activity?
Can you explain in detail more of your problem? Where does software run, where is the ciphertext stored and what is the destination of the plaintext? This is my field and may be able to point you in the right direction.
do yourself a favor and learn vim.
I use vscode myself because I'm an amateur programmer and I like how it detected and installed go relative plugins.
To elaborate on his time based answer, all hashing functions with sliding computational must be deterministic so they use number of iterations rather than time. However most interfaces to these crypto primitives have time based key generation options to get a decent time cost relative to your target hardware. LUKS on Linux for example has a iter-time option which gets you reasonably close to your goal.
No, my answer was specifically to their question of "it always takes 2 seconds to decrypt the data, reguardless of the machine speed?". That is literally impossible. It would violate thermodynamics. You can make a decryption incur a certain, non-trivial cost by setting an iteration number higher or whatever - but fundamentally, you can not prevent that a fast computer will run through it faster than a slow computer.
Honestly, I don't think I am ever going to give GoLand a fair chance as * I dislike their business model and licenced editors (even if they do have a free license), I much prefer to support a free/open IDE. * I dislike having to have like 5 different IDEs installed for all the different languages I use - I know they can give a better overall experience for a particular language but hate jumping between them. * I dislike running java applications locally (I know IntelliJ are better than previous attempts, I still hate managing JRE applications)
you can iterate over channel with `for v := range channel` concurrent reads from a map are safe only if there are no writes https://github.com/richardjennings/getsetdel/blob/master/server.go#L104 check https://golang.org/doc/go1.9#sync-map out 
VIM hands down. not just is because is awesome and I can run it remotely and on my console, super light and powerfull but also to add is free software as in freedom, so I feel ethically and morally sastified.
Yes, programming is hard, I think we're all on the same page there. Ain't an excuse to toss your work at other people...
Thank you for the answer.
Hi thank you for taking the time! &gt; concurrent reads from a map are safe only if there are no writes Totally makes sense now you point it out. I have updated the code to take the value from the map before giving it to a go routine to handle. &gt; check https://golang.org/doc/go1.9#sync-map out "or (2) when multiple goroutines read, write, and overwrite entries for disjoint sets of keys" This is really interesting. I had intended to have one command handler go routine so that operation are sequential. Sync-map looks like it could be more efficient. Thank you. &gt; you can iterate over channel with for v := range channel If I understand correctly, this would be better because range will end when the channel is closed, so no need to check explicitly? Cheers
Just use multi-stage builds and copy to alpine. Alpine is worth the extra 3mb.
Isn't grpc the new protobuf?
So to explain: I need to encrypt some mnemonic Code that can be used to create private seeds for a crypto token. The data will be stored in a boltdb and I want to secure the data of course. The dB will be on a local machine only and not reachable from the internet. What I want to achieve is, that no one, not even me can decrypt the data. Only the user, who will have his 8-10 char long password can do this. I won‘t store the password on my system, but let the user enter the password every time I need to decrypt the mnemonic. If the user looses his password, I will recreate the account from the mnemonic he has saved. But of course the encrypted data will be accessible from different people (admins, developers, etc...) and I want to secure the data in a way, that even if one uses a big bot net no one can decrypt the data (let’s say the next 20 years)
&gt; WTH is 39 i have no clue? You have plenty of clues, you just gotta dig for them. Start with the function you used to encode, and check out the function's source code. That'll tell you exactly what happened.
You could use another switch statement or store your colors in a slice and use a random index into the slice. Also you shouldn't reseed your random number generator every touch event. Just once is plenty.
forget about ram usage, focus on features IntelliJ IDEs aren't just code editors, try it, 1 month free trial, you'll understand why it can help you being more productive
just like you charge your clients i guess
Grpc is built on top of protobuf. It enables you to create rpc clients and servers which exchange protobuf data as request and response. Or streaming
Ahh, I see what you are saying. The pointer *in* the slice is not guaranteed unique if the size is from a zero-length array, because the pointer to the array itself is not guaranteed unique. A great point! Sorry I misunderstood you on the first read.
GoLand. I found it to have the best auto complete. Also all of the other wonderfulness that is in all IDEA ides
I've never had any issue with it's memory usage or speed. From my experience It kicks the snot out of most IDEs in that respect, except for Sublime Text. 
Messing with parts of the fs that is really only managed by your distribution's package manager is bad practice, IMHO.
ProtoBuf is a format to represent data with. gRPC is for developing RPC systems using ProtoBuf for the messages.
Not the speed of the IDE itself, that is snappy, but rather the rendering with large window sizes at high-dpi. Unfortunately my project that I am working on at the moment is a hodgepodge of PHP, Node, and GoLang and I have a lot of various files open at all times so I land up with this: https://imgur.com/a/Xng99
Would you consider opening an issue following the steps here: https://intellij-support.jetbrains.com/hc/en-us/articles/207241235-Reporting-performance-problems and providing more details? The authors would surely appreciate it. Thank you.
&gt; If I understand correctly, this would be better because range will end when the channel is closed, so no need to check explicitly? correct
Will do!
Thank you! 
So I would assume writing code in C for speed and using JNI might be useful for some things, and Go as I understand it is a little faster.. but given that android is already JVM and heavy.. would adding go with its own VM embedded be wise? What code would you write in Go that couldnt be done in Java that you also wouldnt use via C/JNI? I love the idea, just curious why the added weight and complexity of using go for parts of an app when Java is.. for the most part, easy enough to use for the whole thing?
&gt; Kotlin-Gradle plugin.... meaning you never have to code in Java or Groovy again You still have to write your build scripts in Groofy. 
Of course, being productive is what matters at the end of the day.
I honestly rather like the random solution. It doesn't depend on external or global state. It just has a 1% chance of running. I've seen other cleanup code do the same thing for triggering a cleanup of stale records, albeit at 2%.
&gt; Windows 10 is rock solid Windows 10 is crap. I've got it installed on a lowend box for running an old printer and TV screen, which Linux can't handle. I also use it to tweak powerpoints for use on Windows which I create with LibreOffice on Linux. It's running v.1607, and always konks out when I try to upgrade to v.1709, even with a high-Gb usb plugged in. Today Microsoft broadcast a message to all v.1607 users saying no more critical upgrades after next month. Hope my installation survives Microsoft's dereliction of their service, and continues to do the bare minimum I need it for. 
I was thinking the same. I really enjoy seeing stuff like this, so thanks for writing about it! I've done my share of silly stuff too, which I really enjoyed, like [creating a service/API for reactions](https://godoc.org/github.com/shurcooL/reactions#Service), implementing various backends and clients for it, and then mixing and matching them... Maybe I'll convince (or trick) myself into writing up some blog post about it someday.
Any time I have more than one line with a repeated prefix declaration that can be grouped, I group them. So never var s string var i = getValue(123) and always var ( s string i = getValue(123) ) I dunno, totally personal preference, but I think it looks a lot nicer.
well, you have to reset the filter
Echo is the faster. At least in the benchmark linked In this post. Lower is better in that chart. 
Emacs + evil-mode is the best vim "emulator" you will find (I'm sure I'm not the first one to tell you that though)
Seriously — ternary operators? Lost me there
If your use of the ternary operator is just to make some bools print easier, consider creating a type and implementing the Stringer interface. When you use the `%v` formatting directive Go will use the Stringer (if it exists), and the default for the type if it doesn't.
Ternary operator is overkill for me.If expression is better.
Something to keep in mind is that we're mostly not on 80x24 terminal windows any more. Vertical space is still valuable, but it's not *as* valuable as it once was.
With `gomobile` you get .aar that you include in project. Doing network and API calls from Go is super easy, clear, clean, and performances are great. For example, I never touched Java at that time, and used it first with gomobile. It was very easy to send 15 http requests From Go and pass json results to Java gson in like 1-2sec. With Java, AsyncTask, Thread, classes, etc. not so easy, and I could never get results even close to that. It is probably possible to get similar results with Java, but with Go you don't even have to think and worry about that. And, you can use same library for desktop and web app, http server, etc. Lib does all the heavy work, and you just write UI code for different platforms. That totally makes sense to me and a big plus. 
Always wondered: Why tmux? If you're using tiling in your terminal to manage applications with TUIs why not just use a tiling wm to manage all your applications instead? I mean you're not developing on a remote machine are you? Genuinely curious.
the ternary operator rules!
Don't have much to say, but I clicked the link, read the readme, browsed the code, and admired your progress! I'm learning go myself and yours looks really nice!
How does this compare to https://github.com/corona10/goimagehash ?
I looked it over really quick on my phone and I'm also a beginner in go, but in your fetchIssues it returns a string and an error, but your error is never returned. It is printed to stderr and the program exits. Which defeats the purpose of returning an error in the signature. If your libraries or helper functions return errors, they should wrap their errors neatly and they should be handled from the main thread or execution logic. Let me know what you think. Good job! 
The go compiler (e.g., when running go build or go install) searches for packages in the following order: 1. vendor tree (if it exists) 2. GOROOT 3. GOPATH (from left to write) The compiler does not check the web, only what is on disk.
Minor issue: It is `brew install go`, not `golang`.
In our case, we already had a go package we used for a desktop application, we reuse that package for the android app. Saved us a lot of time.
`gometalinter --enable-all` I'm a madman.
so those functions assume one octet as 4 bits right? but still dont understand why they do this
What is the destination of the plaintext? It sounds like you want to be able to decrypt their data within a process within your system, but that conflicts with your goal that you want no one (not even you) to be able to decrypt your data. Basically if you are going to try to encrypt their data at rest you need to commit to doing it end to end, otherwise the complexity and effort needed to do it properly may not be worth the value it adds. If you accept this model and only perform decryption operations on the users clients then depending on data size, access patterns and client constraints like platform and general capabilities you may be able to leverage an existing technology. Best case scenario is a client and server differential sync of a psuedo block device akin to a luks container. Essentially all you are at that point is a dropbox. Here's some content from prior posts about this space that you can read through, and see how maybe your approach could potentially be a non-starter if you were planning something similar. There are a lot more comments around crypto for data at rest and general file system related security issues if you're so inclined. [link1](https://www.reddit.com/r/golang/comments/7h1qc3/file_encryption_tools_written_in_go_please_give/) [link2](https://www.reddit.com/r/golang/comments/6yoyar/go_implementation_of_data_at_rest_encryption/dmp8ss4/) [link3](https://www.reddit.com/r/golang/comments/72sx70/things_to_know_about_http_in_go_tit_petric/). But I would need a design doc or much more details about the flow of data to give much more information here, best of luck to ya!
+1, but I'm coming from Java where IntelliJ is the defacto standard. Goland is really nice - the code completion, auto imports as you mention.. 
The problem is that some of those are useless, like gas, or produce too many false positives to be useful, like errorcheck. I use GoLand, which has its own linters, but before commits I run go vet, golint, and megacheck.
All of that is true. I did say it was mad. I usually disable gas, the sql checker, as well as the line length checker, plus extra filtering to deal with linters which descend into vendor without being asked. I'm not so sure about false positives from errorcheck. If you mean errors from close functions, I'd rather handle those than not.
No, they don't. They encode an integer into a variable number of bytes, by splitting it up into groups of 7 bits and then using the 8th bit as a "continuation indicator" (similar to how UTF-8 works). And they do it, because it a) efficiently encodes small numbers - e.g. any value smaller than 128 encodes to a single byte - but b) doesn't restrict the actual possible size of the encoded value. They basically did some research and figured out that trying to keep the encoded data size down increases performance - you are spending more CPU cycles on decoding, but that is offset by using the caches better. Think of protobuf, which assigns a number to each field in a messages and then essentially encodes the message as a list of `&lt;field number&gt;&lt;encoded value&gt;`. Most messages are small and have only a couple of fields, so it's important that small tag numbers are encoded efficiently. OTOH you don't want to actually *restrict* the numbers of fields (Google internally uses messages with literally tens of thousands of fields). tl;dr: The varint-encoding simply is an encoding for integers that can encode arbitrarily large values while still being reasonably efficient for small values.
I do this to build 32-bit without changing my environment `cmd /C "set "GOARCH=386" &amp;&amp; go build"`
Yes, but I'm sure nobody handles errors from fmt.Printf, for example. Also your comment about disabling linters doesn't make sense since the previous comment says you enable them all...
I've never had gometalinter show me a warning for fmt, even with everything enabled. And I guess "I'm a madman" wasn't a strong enough hint that my answer wasn't completely serious.
I like Jetbrains GoLand.
Thank you, Christoph! I actually was also confused once, but they have an alias https://github.com/Homebrew/homebrew-core/blob/master/Aliases/golang so `golang` works as well. However, I'll include this nuance into the blogpost, to be comprehensive.
Any ideas why they put vendor directory into vcs? It is a library and will be ignored by go compiler. 
This is great, thank you! I have aimed for the absolute minimum functionality to make it easier to fully test and complete in a short time frame. Some points I am implementing immediately. Some other points, such as removing the heavy usage of channels I will hold off for a second attempt / version. 1. Thank you for pointing this out. I was unaware just how inefficient channels are in GO. I thought it was the idiomatic way of doing things. Following your comment I did some more in depth reading about channels and now see your point completely. 2. A fair point. 3. Agreed 4. I had forgotten about the second return value to be honest. This is a simple addition that adds usability without complexity. Thanks. 5. I guess I might have misunderstood terminating cleanly. If the client disconnects, an error will be returned either on read from or write to the connection. In ordinary operation, one of these errors is expected to happen and will break the loop. Perhaps this is not idiomatic? It is something to think about. I am keen to read any further thoughts you have. 6. Good point. Looking at the memcached protocol, it looks like they add END\r\n to indicate the end of the response. This definitely falls into the minimum viable feature list. Again thank you for your time. Much appreciated.
The stdlib mux isn't really too nice to use if you want to work with paths with variables in them, etc. (e.g. `GET /foo/{fooID}`). Using something like Chi is a good option IMO. It's a fast router, and it sticks to using the stdlib interfaces and whatnot which makes it very easy to swap in and out if you wanted to. As for ORMs, I've personally steered clear of them. I enjoyed using Doctrine in PHP, but I also knew the overhead that it created. Using it for everything didn't really make the code _that_ much easier, but it did make it a _lot_ slower, and less flexible compared to using raw SQL queries. If you want an easier time with the `database/s(ql` package, take a look into [sqlx](https://github.com/jmoiron/sqlx). It's a very popular package, with good reason, it does make a lot of things just that much simpler when dealing with databases. For such a small sounding project, I'd definitely stick to [keeping it simple](https://en.wikipedia.org/wiki/KISS_principle).
**KISS principle** KISS is an acronym for "Keep it simple, stupid" as a design principle noted by the U.S. Navy in 1960. The KISS principle states that most systems work best if they are kept simple rather than made complicated; therefore simplicity should be a key goal in design and unnecessary complexity should be avoided. The phrase has been associated with aircraft engineer Kelly Johnson (1910–1990). The term "KISS principle" was in popular use by 1970. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
For database interaction, you can think about using https://github.com/jmoiron/sqlx , is a very nice, and well tested library to deal with databases. If you're interested in another, you can give https://github.com/geo-stanciu/go-utils a try. (Disclaimer: I wrote it). Please view the readme to see if this is something you would like to use.
Any one tried this?
I believe GOPATHs come before GOROOT, unless that changed in the past few years.
Don't forget that there can be multiple vendor trees, checked from bottom to top.
So how do you compare RN vs Flutter?
Because it just works. We already have to worry about a fuckton of details to do our jobs - when the text editor politely informs me that I would benefit from having some go tools installed, oh and btw, just click here and I can do that for you.. its hard to use another thing.
Love these kinds of posts. If you can’t tell me 5 things that drive you batty about your language of choice, I ain’t got time for you. Also dearly miss ternary. 
This is a stupid and brittle solution, in retrospect I'm sure the speaker must feel like an idiot having given that talk. Everybody and his mother can write a trie which is how you solve path matching with route variables. Not with that dumb stuff. Imagine if some speaker told people "don't use arrays, use var1,var2,var3,var4,var5,...,varN, that's much simpler!". That's basically what the speaker is telling people.
Web link https://research.swtch.com/vgo-intro
It can be pretty straightforward if you've not got many routes, but I'd still not choose to spend my time writing this logic. It'll be more difficult to maintain and expand upon in the future too.
emacs with the following packages: go-guru, go-autocomplete, go-flycheck, flycheck-metalinter, go-eldoc, and obviously: go-mode 
I agree that Julia and Go are on totally different ends of the spectrum, and that makes them somewhat difficult to compare. Julia focuses on making code easy, while Go focuses on code being simple. There are two major advantages of Julia in my mind. The first is that focusing on ease is, well, easy, and so you can write code to do what you need with only a few characters. The second is that meta-programming can allow you to do some super cool optimizations automatically and have the code look nice. You do many of the same things in Go (not to the fullest extent, but enough) with interfaces, but the resulting code feels so complicated, because Go doesn't have the same ease of hiding that complexity. The major disadvantage to Julia is that it's complicated. Read the "Taking vector transposes seriously" thread ( https://github.com/JuliaLang/julia/issues/4774 ) and you'll understand some of the downsides to allowing metaprogramming and operator overloading with types. In Gonum, you can write mat.Mul(A.T(), b) to have A'*b be put in a matrix, or vec.Mul(A.T(),b) to have A'*b put in a vector. You have to type a few more characters in Go, but things like this proposed set of rules (https://github.com/JuliaLang/julia/issues/4774#issuecomment-269096052) aren't even a discussion in Go. Similarly, Go does not allow operator overloading, but Julia has something like 100 ( https://github.com/JuliaLang/julia/blob/c200b4cdb9620b6df369ae3c735cf3af30b6a47f/src/julia-parser.scm ). Because of this, the biggest upside to Go, in my opinion, is I find it much easier to read and follow code. Go is explicit in which functions are being called where, while in Julia it can be hard to tell without running the program which particular function will be dispatched at the moment. My biggest recommendation to Julia is to be better with namespaces, when I was last using it you could have a lot of spooky effects by importing new packages. In the end, it'll be interesting to see. I suspect Go will be better for large codebases in the long run, but who knows, and the magic of metaprogramming is alluring. I'm curious to hear the thoughts of /u/jerf .
gometalinter with following linters: golint, gotype, deadcode 
I think there are more ways to declare variables (function-scope), that are actually used in Go projects. 1. var s string var i = getValue(123) 2. var ( s string i = getValue(123) ) 3. s := "" i := getValue(123) 4. s, i := "", getValue(123) I personally like 4th way as it's more compact (where it makes sense obviously).
80x24 terminal, lol. Space is not such a big issue, that's true. I'm just trying to establish the best standard to use in my code and keep to it. Probably will go with ':=' instead of var, mostly.
It is not recommended to use the stdlib for multiplexing HTTP calls, as it is bloated. There are several frameworks that'll will suffice, but may I recommend my project https://github.com/gbrlsnchs/httpmux, so you can take a look at examples and, if you don't like it, you can still use other libs. It's built upon a radix tree and doesn't allocate memory when not using HTTP parameters. It's similar to `httprouter` but respects the stdlib pattern, so if you need to move your handlers to other frameworks, you're ready to go.
I have not used the particular profile tools he is talking about in Go, but have in other GC languages. The talk is very good though, highlighting some of the primary performance problems that come up in GC languages (and even non GC languages). Reduce allocations, understand the stack vs heap, understand CPU caches. Ram is slow, don't mess up the cache! Measure, measure, measure. He goes over some handy built in Go tools to profile things which look excellent. 
It seemed surprising to me too, but GOROOT is searched before GOPATH. If there was another order, it was before go1 (which is when I started with Go). The error message when a package not found shows the search order: $ go build foo/quxx can't load package: package foo/quxx: cannot find package "foo/quxx" in any of: /home/you/go/src/pkg/foo/quxx (from $GOROOT) /home/you/src/foo/quxx (from $GOPATH) This message was introduced in 1.1 (see https://golang.org/doc/go1.1#gocmd) I also tested the search order by creating a package fmt at $GOPATH/src/fmt that implemented `fmt.Println` (displaying a special message) and testing a little program that called `fmt.Println`. The special message was only displayed *after* moving my fmt package to a vendor directory.
Here's a useful benchmark that inspired me to write a mux myself https://github.com/julienschmidt/go-http-routing-benchmark
Honestly if you aren't using [this](https://github.com/bouk/go-faster) repo you aren't taking an idiomatic approach to writing concurrent go code.
Stripped Go binary of lets say 5-6M when zipped in apk is 1.5-2M. But you need to build also for arm64 arch, etc. Depends also what else is there, but 5-10M apk is not that bad.
My guess is that you could put rana/ora path in your project and include it without "github.com" prefix. That way you can include it in your git repository and have everyone get it from there as if a part of your project. I didn't check the license to see if you can do that though. 
See also: https://www.youtube.com/watch?v=ySy3sR1LFCQ https://blog.golang.org/profiling-go-programs
Also recommended: https://changelog.com/gotime/6 (ffwd to 7:30mns)
For future reference: why people are downvoting this? Is there a better subreddit where I should post this link?
Some purists might consider it cheating, but you never realize how much time it takes to manage imports until you don't have to worry about it anymore lol.
I agree that you could do this but the issue is when we run go get from our private repo, it will pull the code down and all the libraries BUT it won't pull libraries from outside our VPN. So we can't go get the ora and expect it to pull every library, so we have to manually install the packages. Which is very tedious and a waste of time for the entire team. So we have one person do it by hand and make a binary and hand the binary out. We just need a better way to hand out this binary or something of the sort when we have to use our DB library. 
Yes, I agree with you, I apologize for misusing the word "bloated". The difference is small, the really issue are when requests increase, but still bloated is not the correct word to use. Thanks for clarifying.
I'm not a big fan of grouping them up. I prefer to just repeat the keyword at the start. For the `type` keyword I find this also makes it easier to `grep` for things.
It could be to speed up their builds / testing on their CI, i.e. not need to fetch the deps as part of running the tests.
I run these in my editor, as they're reasonably fast: --enable=vet --enable=errcheck --enable=golint --enable=ineffassign --enable=goimports --enable=lll --line-length=120 I run these on CI for most projects. They're not fast enough to run in the editor, but still useful enough to catch the occasional issue: --enable=varcheck --enable=interfacer --enable=unconvert --enable=structcheck --enable=megacheck
standard library, database driver and one of the most used routers is all you need
OP clearly stated that requires very few handlers. I don't think an external router is needed despite how popular it might be.
 if someEnabledFlagHere == true { isEnabledString = "enabled" } `== true` is redundant.
I guess when you compare it to apps like facebook. I'm looking at total apk size of 3mb with quite strict requirements. Doubling that just to use a different language is not gonna happen. same goes for kotlin...
Yeah same here. I bet people who are asking for such operators have never had the wonderful opportunity to maintain code that abuses them.
The way you wrote your example is fine. It can be tempted to always get rid of boilerplate like error handling, but that's not always the best thing to do. I wrote a comprehensive post about this topic here, focused on Go specifically: https://medium.com/@shazow/code-boilerplate-is-it-always-bad-934827efcfc7
&gt; I wouldn't wanna develop a dynamic url matcher myself Why would you need to do that though?
Terrific! Bought a Mic-Drop Gopher shirt! 
0. write no code at all (cute) 1. use timeouts 2. use retries 3. fallback/degrade Now you've read the article too. How is this the top article on r/golang after 11 hours? This is kid stuff.
I am very happy with Gin (mostly just using it's router, I think I would switch to Chi if I could go back in time) and GORM as the ORM. Other libraries pull in as needed.
1. My mistake then! I was looking at https://github.com/vrde/ghstats/blob/master/utils/http.go#L9 and it sorta looks like it's parsing html 4. Yeah, that's generally the model. It allows each layer to handle the errors they can and bubble up the errors they can't to the layer that can :)
My perfbook is also coming along nicely: https://github.com/dgryski/go-perfbook
I don't think hiding complicity can make things easier to understand, unless that abstraction is well understood by readers, that code just makes the writer think it's simple but the reader still have to figure out how the abstraction works, which is usually harder than just understanding the code without the abstraction. Mathematics is full of abstractions and most of our experience doing math is to learn math, which is to learn those abstractions. The math we learn is often well thought out and widely applicable. When we are using mathematics, however, we just apply what we already know to the situation instead of inviting new ones. Metaprogramming does satisfy an intellectual curiosity, but it usually doesn't make your code easier to understand for new comers. 
Any other images from https://github.com/ashleymcnamara/gophers that should be on shirts (minus obvious copyright violations...) Comment here and upvote and we can let Ashley know to add the most popular ones.
Sounds like a cron job. This may work, or serve an an example. https://godoc.org/github.com/robfig/cron
I can recommend that one
After making a commit, before pushing it anywhere, I type `ci`. It's an alias that runs: go test -race ./... gofmt -d -s . megacheck ./... unconvert ./... unparam ./...
One of the things I need to do, though, is to change the style attribute of a path, polygon, or rect element in an SVG before (or after) adding it to another SVG.
I do know the exact times before hand 
Given the adverts for Goland I've been ignoring for the past few days, this entire post just screams at being an example of stealth advertising via content creation.
don't get me wrong, I enjoyed Android Development a lot. But business wise limiting yourself to only Android is not a good idea (been there for 3 years). The people also want iOS Apps and preferably a Website, so I need to look around and find a cross-plattform solution.. This doesn't count for employees ofcourse
I've been working mostly in C++ for a long time in video games and other high performance areas and have recently been using Go for a back end. Go doesn't try to be a godsend language that can do anything. It's highly opinionated and constrained. That's it greatest strength and weakness. It can't do everything, but it doesn't try to. We need more languages like it. Lua is a similar language in its minimalist nature. Go is clean, fast, great at multi-threading, portable, statically typed, and has an amazing tool chain that covers building, testing and code style. This all leads to great productivity in its targeted domains. There are drawbacks: funky syntax, limited power and options (e.g. generics), weird project location (GOPATH) requirements, limited OOP and weak dependency management. Some of these will improve with time. Some are also part and parcel of Go's strengths. I think it's a great addition to a C++ programmer's tool belt because languages like Scala, C#, or Rust are analogous, while Go is complementary in comparison.
Any language worth using can be abused. The nice thing about Go is that you can take a good C++ programmer and good PHP programmer and have them work on a project together using a language that is approachable to both and likely applicable to the reason why they are working together.
Slightly salty about Bonfire removing the Legend of Zelda design, guess I'll just have to order something different and then get it custom made on my own.
OP forgot /s ? I had a good chuckle at the readme though
Ashley was super upset about it :(
Super upset. I emailed DC asking for permission. What pisses me off the most is that if they know they have to approve every design then why not just hold it until it's approved instead of waiting until it's sold 64x?" 
Same, but i find myself using chi instead of gin. GORM's debug mode is by far the most useful feature of the package.
Yeah go is specifically by is creators meant for scaling only. This has been addressed countlessly for countless reasons, by multiple go team members. https://youtu.be/2k0SmqbBIpQ
A cursor google search for "golang cron" yielded [this](https://godoc.org/github.com/robfig/cron) which seems reasonable enough. Read some documentation on the crontab specification, it allows you to create pretty complex time based patterns for running jobs. Alternatively, you could roll your own solution. &gt; if i needed to execute tasks at times such as 1st minute , 3rd minute, 8th minute You may be interested to learn about [modular arithmetic](https://en.wikipedia.org/wiki/Modular_arithmetic). Golang has a builtin library for fetching the current clock time. Find the hour/minute/day/whatever, modulo it by the interval you want, if the result == 0, run the task. I'd strongly recommend leveraging an existing scheduling framework, though, to avoid introducing 'novice' level bugs or issues involving timezone/leap second/minute/hour/day/year handling.
**Modular arithmetic** In mathematics, modular arithmetic is a system of arithmetic for integers, where numbers "wrap around" upon reaching a certain value—the modulus (plural moduli). The modern approach to modular arithmetic was developed by Carl Friedrich Gauss in his book Disquisitiones Arithmeticae, published in 1801. A familiar use of modular arithmetic is in the 12-hour clock, in which the day is divided into two 12-hour periods. If the time is 7:00 now, then 8 hours later it will be 3:00. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Eh no, I disagree. Ternary operators can easily create dense, hard to read code. Switch statements are naturally more readable and are harder to be abused, not to mention that they are more powerful and useful in Go than other languages.
I agree with /u/The_Sly_Marbo that you need to fix your code sharing problem, those are no conditions to be working under. That being said I would recommend that you use a package manager like dep or glide, lock the latest stable version of your dependency to the vendor directory and then commit your vendor directory to your repository. 
Ugh, azure is not good. Their SDK seems to have really weird OO style as well.
I used to write a lot fortran For science it worked flawlessly Try it for graphics Write in C
Supports just Windows? No Mac or Linux?
* because of Babel? * because we are humans and can communicate by languages we can express ourself in? * freedom of choice?
He's a full time /r/programmingcirclejerk, just ignore.
This might not be the answer you were looking for, but maybe you have way too many tables? Furthermore, you might be doing OO wrong. As you don't need to map all types to specific structs in your language. ( Just like composition is more power-full than inheritance ). So you might want type to be a property instead of using reflection or type assertions. And you want to put different type of objects in one table, with a column indicating the type. Just my two cents. 
Why though
I don't really know another way of doing it. These tables are fully normalised and all have different properties. Cassandra doesn't work best with fully normalised tables but I'm going to cross that bridge when I come to it. 300 tables is just the definition of the objects within the game world, I haven't got to the live data yet.
Relevant discussion on SO: https://stackoverflow.com/questions/6390585/in-golang-is-it-possible-to-get-reflect-type-from-the-type-itself-from-name-as
&gt; I don't really know another way of doing it The other way would be what I said, make type a field/property. That way you can also query on it, and you can get all objects in one query, instead of having to query per type. And even then you can later map the 'object has a type' to 'object is a specific struct' later, if that makes the domain logic easier to implement. If you need to query 'what objects are in this [room/bag/whatever]' then you really want one table with objects of multiple types. If tables share a lot of fields (they are mostly the same), then you also want those objects to be in one table. It makes everything so much easier and faster. I mean, if you have a Cat database, would you threat the specific cat breed as a column or would you create a table for every breed? If you EVER have multiple tables with identical field definitions, you need to scratch your head and think about what you are doing. :) 
[Write in Go!](https://www.youtube.com/watch?v=LJvEIjRBSDA)
You seem like a really cool and dynamic person.
Video linked by /u/domnikl: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Write in Go (Fall 2014)](https://youtube.com/watch?v=LJvEIjRBSDA)|ScaleAbility|2014-10-24|0:03:43|1,645+ (98%)|85,836 &gt; Turn on the closed-captions to see the lyrics! --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/domnikl ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=dvu9t3w\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0
Ok cool, will think about it. The tables do have different columns and are fully normalised but I'm probably still thinking in the 2000s mySQL mindset!
&lt;3 thanks
I love Go, but try writing a driver in it. Gotta choose the right tool for the job.
That's fine, choose the right tool for the job. Sounds like a good use-case for an ORM which Go isn't the best at. Code gen might be something to look into if you decide to stick with it.
And if you don't need to query/index certain fields you can store data in Json for instance. That's a more document based design. No need to go with No-SQL entirely. The thing which needs to click in your brain is that you are automating the automation process itself. Any project with lots of meta data, lots of types requires you to do that or else you need to write a lot of boiler plat code. The hard part is finding balance between readable/maintainable code and a fast/small codebase. These things are at odds with each other. If readability is important (vs speed), normalising is still the way to go and reflection is a good way to deal with type info. 
Because up till recently (rust?) it's the only language that gives you full (almost) control of the hardware.
It's not a technology limit, you need to go back to basics and read a bit about software design. The fact that you are interfacing an API to tables means that something is wrong, software provides more than just raw data storage. If you only need to provide access to tables, there are plenty of tools that have solved that problem. On a superficial look (OOP perspective): - Models are much more then data struct, they can/(prob)should have behaviour - Cassandra, Factories, Reflection are just tools to make you software work, you should be able to design/solve your software with basic language constructs - If you consider tables as your problem, then you should represent Table struct and work from there 
The only solution that comes to my mind is code generation. I've never had to use it myself so I can't give you any tips about it but I know at least 1 company that does code gen in production so it's not totally untested. I appreciate you don't want to make your tables less pure like another commenter suggested, and I agree with you that you should keep to best database practices. Personally, I do use Python (Django specifically) for services that do large amounts of simple database work, as I think this is still a use case where Python is better than Go for this exact reason that dealing with lots of database objects is very tedious in Go. Generally my projects have a central Django-based core that handles all the data storage, and all processing tasks are microservices written in Go (or Rust/JavaScript/Elixir) which I communicate with using gRPC. So my conclusion is that you're not insane for feeling like you want to use Python here - Go isn't universally better and I think this is a situation where it definitely isn't the best choice.
It looks like you're putting what I call "static data" into a database - by static data I mean stuff that's frequently authored by game designers and doesn't typically change in a production run of a game server. This dodges the question of "how do I do this in Go?" a bit, but I'd recommend taking a step back and asking yourself if you really want to do it like that at all - how are you versioning data changes and promoting them, how can you sync back to an old version? Is a RESTful API efficient enough for data you're likely to to want to bulk load? Sometimes the desire to store data in a database comes from a place of just being the default assumption. I'd recommend just reading through https://medium.com/@offbyone/file-static-data-e2af8f8e8c0a as another point of view. Like I said though, this doesn't solve the question you asked though - it sounds a lot like you want an orm, so maybe https://github.com/scylladb/gocqlx might be something to look at?
Yup, sounds about right, it's a huge amount of static data. I want to do it this way because this entire thing I'm building is somewhat of a prototype. At some point I'm going to hand it off to a team that can build code that's going to stand up in a production environment. Things like versioning changes is somewhat out of the scope of what I'm doing but I'd definitely consider adding it in if I could. Creating this system is more of an aid to game design than something that's going to be in a live game, but the closer I can get the less work we have to do later. 
I haven't used GoBuffalo, but I'm gonna assume it wants to do the typical ORM approach of mapping structs to tables, because that's what most programmers want, a simple representation of their tables in native (&amp; simple) constructs within the working language (go in this case). But don't forget that that's all written on top of more basic stuff that just does SQL underneath. You can write your own abstraction layer, and completely ignore the ORM approach. If want you want is "generic" REST interfaces to your tables, rather than making structs for everything, take a metadata approach, where you have definitions of tables with columns, and information about what type of data is stored in the columns. You can then write a single REST service point which accepts an "object" (table) name and list of "attributes" (columns), and automatically translate that into a query, retrieve results, create a JSON response and return it, all based on your metadata, and not a matching struct anywhere. At that point, rather than having 300 various structs that mostly/hopefully align with your tables, and a zillion methods dealing with each kind of struct, you can have a single handler that will serve data from any table, as long as you provide a metadata definition. (So, you'll have a set of metadata somewhere that describes your 300 tables.) If you don't want a single REST point, you can use the metadata to automatically register your 300 different service points by writing functions that return functions (with closures to capture the metadata per service point). If you really wanna get crazy, you can use the metadata from the database itself. Every database has a way to query "what tables exist?", "what columns in this table? and their types?" You can take a half-way approach, where you hard code the list of tables to be handled and then get the metadata from the db. You can write a program that queries the database, generates your metadata, which you can then edit/tweak. Whatever. One of the things that I _really like_ about go is how easy it is to handle functions as first class objects. With this, you can create hooks in your metadata framework for "business logic". For _this_ set of objects/tables, do func A before serving a response, for _that_ set, do func B to canonicalize attribute X, or just about anything you can dream up. (I'm assuming you'd probably pass in data rows as `map[string]interface{}` or something.) Bottom line(s): 1. don't be constrained by a certain framework. If it's not working, use something else, or even cook up your own. 2. just because go doesn't have "generics" doesn't mean you cannot write amazingly smart/flexible software with it. Here are a couple functions that I used in a program I wrote that just takes whatever query/raw sql, and processes all values returned. This are very quick &amp; dirty, but demonstrate that you can do just about anything you want. If I passed in a list of types, I could scan to particular types, rather than to all strings (or all interface{}). func ScanToStrings(row *sql.Rows, numColumns int) []sql.NullString { strings := make([]sql.NullString, numColumns, numColumns) scanArgs := make([]interface{}, numColumns, numColumns) for i := 0; i &lt; numColumns; i++ { scanArgs[i] = &amp;strings[i] } err := row.Scan(scanArgs...) MustNot("scanning to strings", err) return strings } func ScanAllValues(rows *sql.Rows, nCols int) []interface{} { vals := make([]interface{}, nCols, nCols) args := make([]interface{}, nCols, nCols) for i := 0; i &lt; nCols; i++ { args[i] = &amp;vals[i] } err := rows.Scan(args...) MustNot("scanning all values", err) return vals } 
Thanks for the reply! I'd rather not go for the code generation route if I can help it, just seems a messy workaround for something that needs probably a few lines of Python (and definitely one line of PHP but let's not go there) As I've never used Python I'm thinking of starting with a barebones framework like Falcon and then learning it from there. I find it easier to learn in a small framework and then when I get frustrated that X doesn't exist, look for solutions that provide it. This project doesn't have to be perfect, it just needs to let me iterate the game design rapidly and have data that my Unity programmer can access. It's only the two of us right now but a few years out it'll be a large team.
So for a prototype, why bother? just do a pass-through file system to json files in source control. 
Sorry, a bit more context. I just want the API to reference tables directly as an aid to game design. Instead of making a GDD I prefer to map out the game as a data model, throw test data in there and the play with it on the Unity client. Systems just seem to make more sense to me that way. Initially it needs to be quite flexible and fluid, so I'd create definitions like CookingRecipe CookingRecipeItem etc., create the tables, insert a few rows and then send that data to Unity. As the game design solidifies then it the models would take more shape Cooking-&gt;addRecipe() for example, providing a layer between the API and the raw database tables. This is a small project with just two people but eventually we're going to hire up to 20-30 people. Doesn't have to be perfect for now, but production-ready stuff can come later. Thankfully we don't have much of a deadline so we can move slow and break stuff :)
I have a small line-of-business application written in Go with just over 100 tables. Key for any app + database: Metadata, Metadata, Metadata. Let's make this super simple for this post (you can do fancier things too. You can start with a map that maps API calls to requests such as: map[string]struct{SQL string, vars []string}{"monster": {"select * from monster where ID = {{.ID|int}};, []string{"ID"}} Then you just define a single endpoint http endpoint starting with"/api/admin", strip that prefix, and match from the map. When executing it the above syntax is from "text/template" with special functions designed to escape and validate data types. You could also do something more fancy to allow you to pass the values into the SQL as parameters (which is what I do). But really, you only need / want a single HTTP endpoint, then define metadata, either from the database schema itself (which can get a bit fancy) or do something dirt simple and define the SQL only. 
Yeah... fine, I don't think what I'm trying to do is possible. I'll make my own Go... with blackjack and hookers!
the models aren't a layer between the API and the database, the models ARE the software. The database is just a storage engine, chose any, even simple files would work for a prototype. The API is an interface for your game "behaviour", chose one or many, REST, RPC, ... if it is a proxy (REST API -&gt; DATA) to a database then just code generic without any references to your "models", they are just tables with items, so represent them like that 
So i guess the issue with that is you wouldn't get an instance of the struct that is a *Monster, you'd have a ModelInterface instead. Let me play around with that.
I asked you first. If you can't even give reasons as to why...
Ok, Python is my first true programming love so obviously I think you should use it. I've not tried falcon but it looks cool. My experience of building several products in flask is that even though you start off with good intentions of keeping it minimal, invariably the projects end up using an orm, user management, an admin interface, etc... At that point you've just cobbled together a less integrated and less well documented version of Django so I now just start all projects in Django. It's not even particularly harder to get a new project set up with, and comes with everything you need (properly tested, integrated, and documented too). The point of the above is that if you are considering learning a Python framework, I would absolutely recommend going full Django straight away. On the other hand, I don't think Django is particular easy for programmers new to Python so, the choice is yours.
I think you're missing a `"` in your code example. I think the problem the op is having is not the query generation, it's the functions that handle the objects from the queries - i.e. you have a `func getMonsterA(db *sql.DB, id int) *models.MonsterA, error { ... }` and similarly a `func getMonsterB` etc. as well as all the functions that deal in similar ways with each.
I can't share the exact code but I'll write up some notes on the approach when I get time. 
I think you'll find yourself stuck in the assumption of a database more quickly than you might think. It's a very common cycle to do a prototype on the assumption that it'll be replaced by something better, then people just keep adding to it because it's there and it's less work than doing something better, and before long that editing UI is a big project that relies on it and you're stuck (excepting a large effort to move away). I don't think you need to use Go for this, but you can also move away from using a database earlier rather than later and use something like Python or Node as a standalone interface to the data editing on disk. Separating your tools and your engine can be a very good architectural firewall, even though it can also cause some pain. I think that you would have hit issues with cassandra anyway, because it's designed to enable a very specific high performance way of accessing data and writing it by giving you some quite limited access patterns that frequently require you to duplicate data (hence things like materialized views) - it's probably a pretty terrible fit for an editor, imo. $0.02 Do yourself a long term favour and ensure that if you do have an API to your data, you ensure you're not just mirroring the constraints of the underlying data model.
Awesome thanks. Yeah I hit another roadblock. I want to use the struct *Zone but if it's a generic interface then I don't have access to all the hints and fields. I'm going to give it a few more tries though.
Feel free to implement it as you please, but saying you must have it in a database is not correct at all and a bad starting point for getting any kind of ok performance out of a larger application. If you notice, the code I posted is read on application start as it is not changing. (The "func init()" is special), and thus always live in memory. Compare this to reading items/other static stuff from database every time it is needed, you will quickly realize the overhead is enormous. My game is a "mmo" / "world builder" cross-over, this design works perfectly well. Either way, having this data in a text file is meaningful even if you insist on adding it in the database, since you easily version the text file along with your source code, and would then seed the database with the file content. (Personally I keep an "instance" of an item in a persistent database, but this is acctually item definitions. They are fully static). I'm just trying to suggest ways for you to allow for better scalability and maintainability as your project grows. Maybe you need to try it your way and run up against the wall before you understand you need other ways. (That's what I had to do to come to this conclusion, lol). Feel free to pm me if you want to discuss randomly or see more code snippets, I'm bored and glad to help! 
If you have these complex tables you will really benefit from using Django (and REST framework). Its ORM is unmatched! 
It still is: vendors are using C and C++ because they interface to the operating systems that are themselves written in C and C++. It's like asking why I do need JavaScript to run something on the browser, except that C and C++ have not been designed in one week, that is.
EDIT: updated my reply below
There's a trick to that, it has to do with putting your database objects in a library (package) and having a factory method for the library to return an object for whatever table you want. Each db object that implements the interface is in a file in that library. The file has an init() method that registers the object to the library and this adds the name of the object + it's field metadata to a lookup table in the library. Go calls each init() method at startup so all the objects are registered. type MyDbObject interface { GetTableName() string GetKeyField() string New() MyDbObject }
Hah mmo/world builder, mine too :) Ok will have a play around, thanks for the advice. It won't be going live for years so I'm not too bothered about scalability at this point.
I wish you all the luck! Please don't hesitate to ask about anything
I'd argue that the value of just getting a prototype done faster outweighs the benefit of having production ready code. Having a working prototype could uncover issues that lead you to completely reconsider your data model, etc. 
As opposed to javascript which was created in 10 days.
Not enough info to tell you _how_ since usb devices of various types will have different abstractions for working with them. But in general lower level serial devices are polled but in efficient interfaces that block until a timeout, signal, state change or new data is available. So they are more akin to a channel receive than the blind interval conditional polling I was speaking out against in the post above. Just google how to do your thing, find the best abstraction for it because that entire space is nuanced. For example maybe you can use an xutil like xevent if it’s a keyboard or mouse. Have fun.
**main** Not that this is a performance-critical program, but calling `fmt.Printf()` in the tight loop is bad. That's a syscall for every character! I suspect your fastest way is going to be allocating a `utf8.RuneCountInString(str)`-length `[]rune`, filling it, then converting it with `string()`. Or, if you can assume input is all-ASCII, and if you assume the output runes are of uniform width (consult UTF-8 to see if this is true), you can maybe beat that by doing UTF-8 directly and allocating a `[]byte` of the correct length up-front. Or maybe using `strings.Builder`. Measure it! **GetRune** Why use '\u' notation instead of just using ASCII? Why loop, instead of just using arithmetic? That's making an O(n) operation of something that should be O(1)
&gt; think World of Warcraft type complexity... well probably even more complex. Your game might be complex, but that doesn't mean your data model has to be :). In fact, I could make the argument that software engineering involves a lot of making a simple (maintainable, operable) backend act as a lever for very advanced features that *seem* to the customer like they'd need an advanced backend. You want to avoid complication here, not strive for it. Some of your posts speak to wanting this to be as close to production-ready as possible. It's worth thinking about what it will be like to operate your system, as well as develop it. You pay for every dependency (including the database) one way or another - do you really want to be in charge for tuning, optimizing, and responding to failures for 600+ database tables? Try approaching the problem from a different angle. Start with "What's the absolute cheapest way to get the end-user experience I want", and then critically evaluate if the cheapest solution is "good enough" or if you need something more. A lot of people have suggested storing this data statically (which I'd +1 as well); why won't this work for you? For example, one counterpoint is needing to do some sort of deployment whenever static data changes (this doesn't imply downtime, btw, but you will need to "move bits to the boxes" as it were); but is that actually a big enough problem you'd toss the solution in favor of a database? 
open a connection, send something, read something, don't close the connection. There isn't more to it.
&gt; this returns the correct *Monster struct but the compiler thinks it's an interface{} so I can't do anything with it. What would you do with it? Are you always just serializing it and returning it to the response as json? If you just make every object have a common interface like MarshalJSON, then it doesn't matter what type you have.
Please also post your question on https://groups.google.com/forum/#!forum/golang-nuts
Here's a benchmark comparing your GetRune vs an arithmetic-based version package main import ( "testing" ) const ( SwirlStart rune = '\U0001D4D0' DoubleBarStart rune = '\U0001D538' GothStart rune = '\U0001D504' SansSerifStart rune = '\U0001D5A0' MonospaceStart rune = '\U0001D670' ) var charsets = []rune{ SwirlStart, DoubleBarStart, GothStart, SansSerifStart, MonospaceStart, } var Result rune func BenchmarkGetRune(b *testing.B) { b.Run("Loop", func(b *testing.B) { benchmarkGetRune(b, GetRuneLoop) }) b.Run("Arith", func(b *testing.B) { benchmarkGetRune(b, GetRuneArith) }) } func benchmarkGetRune(b *testing.B, getRune func(c, s rune) rune) { var r rune for i := 0; i &lt; b.N; i++ { charset := charsets[i % len(charsets)] for c := ' '; c &lt;= '~'; c++ { r = getRune(c, charset) } } Result = r } func GetRuneLoop(c, start rune) rune { var offset rune // ascii A-Z for i := '\u0041'; i &lt;= '\u005A'; i++ { if c == i { return start + offset } offset++ } // ascii a-z for i := '\u0061'; i &lt;= '\u007A'; i++ { if c == i { return start + offset } offset++ } return c } func GetRuneArith(c, start rune) rune { switch { case 'A' &lt;= c &amp;&amp; c &lt;= 'Z': return c - 'A' + start case 'a' &lt;= c &amp;&amp; c &lt;= 'z': return c - 'a' + start + 26 default: return c } } Here's what my laptop gave: $ go test -bench=. -benchtime 20s convert_test.go goos: linux goarch: 386 BenchmarkGetRune/Loop-2 3000000 8376 ns/op BenchmarkGetRune/Arith-2 30000000 916 ns/op PASS ok command-line-arguments 126.872s Almost a 10x improvement! And clearer code too!
And my intuition on the main part was right too: package main import ( "os" "fmt" "strings" "testing" "unicode/utf8" ) const ( SwirlStart rune = '\U0001D4D0' DoubleBarStart rune = '\U0001D538' GothStart rune = '\U0001D504' SansSerifStart rune = '\U0001D5A0' MonospaceStart rune = '\U0001D670' ) var charsets = []rune{ SwirlStart, DoubleBarStart, GothStart, SansSerifStart, MonospaceStart, } var file = os.NewFile(3, "file") func BenchmarkConvert(b *testing.B) { b.Run("Printf", func(b *testing.B) { benchmarkConvert(b, ConvertPrintf) }) b.Run("Runes", func(b *testing.B) { benchmarkConvert(b, ConvertRunes) }) b.Run("Builder", func(b *testing.B) { benchmarkConvert(b, ConvertBuilder) }) } func benchmarkConvert(b *testing.B, convert func(string, rune)) { str := "The quick brown fox jumped over the lazy dog" for i := 0; i &lt; b.N; i++ { convert(str, charsets[i%len(charsets)]) } } func ConvertPrintf(asciiString string, charset rune) { for _, c := range asciiString { fmt.Fprintf(file, "%c", GetRune(c, charset)) } fmt.Fprintln(file) } func ConvertRunes(asciiString string, charset rune) { out := make([]rune, utf8.RuneCountInString(asciiString)) i := 0 for _, c := range asciiString { out[i] = GetRune(c, charset) i++ } fmt.Fprintln(file, string(out)) } func ConvertBuilder(asciiString string, charset rune) { var b strings.Builder for _, c := range asciiString { b.WriteRune(GetRune(c, charset)) } fmt.Fprintln(file, b.String()) } func GetRune(c, start rune) rune { switch { case 'A' &lt;= c &amp;&amp; c &lt;= 'Z': return c - 'A' + start case 'a' &lt;= c &amp;&amp; c &lt;= 'z': return c - 'a' + start + 26 default: return c } } which gave me: $ go test -bench=. convert_test.go 3&gt;/dev/null goos: linux goarch: 386 BenchmarkConvert/Printf-2 20000 67233 ns/op BenchmarkConvert/Runes-2 300000 4831 ns/op BenchmarkConvert/Builder-2 300000 5550 ns/op PASS ok command-line-arguments 5.262s and the improvement is even more dramatic if we use something that doesn't just discard the result: $ go test -bench=. convert_test.go 3&gt;/tmp/out.txt goos: linux goarch: 386 BenchmarkConvert/Printf-2 10000 105420 ns/op BenchmarkConvert/Runes-2 200000 6149 ns/op BenchmarkConvert/Builder-2 200000 6899 ns/op PASS ok command-line-arguments 3.836s 
Use interfaces to create a 'generic' type. You can use the interface to fetch a specific type and fill in relevant data from your db. You'll need to identify the type of resource when the record is saved to the db, so that you can switch on the resource type later. See https://play.golang.org/p/bv652AOhouT for an example. P.S. I played a lot of neopets growing up, its one of the reasons I got into web development :)
My experiences using gRPC have been promising. If you write your “structs” in .proto files, you can end up using different languages for different parts of the game. It’s supposed to be faster than http and more rigid than arbitrary json. It’s more work up front, but for large scale projects (I’m hoping) it will pay off in performance, maintenance, and scalability. 
I think you've had some good recommendations for ORMs etc, so I won't touch on that, but I do want to touch on your database choice. I'd strongly recommend rethinking your usage of Cassandra if you are dealing with relational data, which it sounds like you are since you've mentioned you're normalizing all your data. You will wind up hating your life going down that road. You'll be saving yourself a lot of headaches in the future if you take a step back and really analyze what Cassandra is good at and think about if your use case really fits the bill. In my job we were using Cassandra to deal with a mass number of streaming, non-relational, geo-spatial temporal data. Cassandra was the right tool for this use case. It's write throughput was good for the streaming nature of the data and while we were duplicating data we were able to setup good indexes to support the queries we needed to do. However, this lead some developers to say "well we're using Cassandra as our database, so let's put all our data there" and we wound up using it as our main data store, even for our relational data. I urge you, *do not* do this. It was painful for us and we wound up migrating all of our relational data to PostgreSQL. If you do stick with Cassandra, at least format your tables in a Cassandra way. Example if you have the `Monster` type that can have many `Items` on it's body, instead of having a mapping table that maps `MonsterID`s to `ItemID`s as you would in a normalized database, make a [user-defined type](https://docs.datastax.com/en/cql/3.1/cql/cql_using/cqlUseUDT.html) for your `Item` and have the `Monster` column family have an array of `Item`s. Also look into [static columns](https://blogs.infosupport.com/static-columns-in-cassandra-and-their-benefits/). They help in denormalizing one-to-many relationships. Again, I urge you not to normalize your data if you use Cassandra. Eventually you will hit a point where you need/want to do something with your relational data that you cannot because you are fighting your tools. Materialized views help, but won't cure all your problems.
Anyone tried CosmosDB the multi-model db? They have [Golang quickstart docs for a Mongo API](https://docs.microsoft.com/en-us/azure/cosmos-db/create-mongodb-golang) (accessing CosmosDB through a Mongo API) -- so I've been wondering if Go might get some love for the other DB models as well -- SQL, Cassandra, graph...
Can you help me get my old login?? My brother hanged the pwd, but I had ~500 baby Neopets paintbrushes. xD In order to actually contribute to the conversation, I've had great experiences with Gorm for this type of problem. Go doesn't play nicely with ORMs like I was used to with Ruby or Python, but they're still better than writing your own solution.
&gt; No need to go with No-SQL entirely One of No-SQL's strengths is rapid prototyping, and sounds right up the direction that /u/borovan is trying to go :-)
If you are talking about caching html, css, js files served from a linux file system you should strongly ponder doing nothing and allowing the kernel bufcache to do this for you. If you are talking about caching those API calculations, web responses, database response, there are many options from a simple map to redis and everything in between. I'm leaning towards groupcache. https://github.com/golang/groupcache I'll let you know how it goes.
I only want to cache static files. Yes, the final project will be running on Linux. What do you mean by "allowing the kernel bufcache to do this for you"? Please explain it.
And why do you think Rust is incapable of these things?
Right! I've [changed the code](https://github.com/vrde/ghstats/commit/61a7aa432f380fb7c7379ecb8ffb48f0d9100f36). Thanks.
Oh man, I loved neopets...
:P
I stopped doing that loooonnng ago sorry! Baby PBs though, nice! Assume you got them fair and square? :)
[removed]
I'm not striving for complexity I just want to have no ceiling on how complicated the game can become. Storing the data statically vs. a database is really the same to me, just the latter is way more flexible. Plus since it's not SQL and you don't have foreign keys I'm going to run loads of scripts and tests on the data just to make sure the game design still makes sense. You can always just have a caching layer in front of the database to give it the same performance characteristics as static data anyway.
The good parts of Erlang don’t seem to make up for the bad parts, which (through the eyes of a Go programmer) are an obscure and obtuse syntax, relatively poor performance, and, most importantly, a standard library that doesn’t meet the needs of a modern server.
He means, if you're saying "I want to cache these files on disk into memory so I can respond faster" then the kernel pretty much does that for you. Don't worry about it. Nginx can sit on top of your entire app and give you a little more functionality here, more guarantees on how the caching will happen, more control. But in either case; you're micro-optimizing something that isn't that slow. The real level where "caches" operate at in modern web apps is outside of your app. For example: If all you're doing is serving static assets, that stuff should live on S3 and then be CDN'd. If you'd respond to that by saying "my app isn't big enough to need that", then you might be right, but you also don't need any other caching solution. 
That's understandable but judging from the comments of the thread the problem is tough. Posting in golang-nuts does not guarantee you will get a good answer but a lot of distinguished people read the mailing list so there's a chance you'll get some insights that you won't find here.
Ok cool. Yeah things have changed so much since I posted this so not exactly relevant any more, but will definitely post a follow up. Thinking Go is a bit of pain but I'd love to make it work!
Exactly this, wish it could be sent to the top. The signal-noise ratio for this topic shows how many reach for ORM's and libs to solve, what should be a simple problem, if you didn't look to ORM type solutions first. Either A: Construct the sql from the params and return the result of the query without abstracting to a model first or B: Use a common interface to your model, like the one above, that satisfies the needs of the code in the single handler. 
&gt; Files with this header will be ignored by GitHub (in PRs and diffs) and Go Lint. Why would I want that? My understanding is that go generate is something a package author should be running, not a package consumer. If the generated code isn't checked in, the consumer has to run generate?
Etcd
Is there a video of the talk? I like what I have read on the slides, but I would love to see the talk. :)
Its not clear to me what you consider to be a database or not in this case. Are you against any type of broker service storing the data for your cluster? Are you just against a formal database like postgres? You could use something like Kafka as an event source that keeps your cluster in sync. Or something like redis if you need to treat the data like a queue. Nats.io can provide queue semantics if you have 8 servers that need to work on FIFO data. 
&gt; but will definitely post a follow up. Please do. I'd love to read the follow up or how you made it work.
I agree with almost all people here, but just want to add that you should look at some better ways of implementing REST APIs using HTTP. Don’t add ‘/list’ or ‘/show’ to your URLs. This is just a nitpick. But I overall agree that you should look at some more software design and take a step back.
I meant that GitHub will collapse the files when viewing diffs. They're still committed to the repo. I'll clarify the article when in back at my laptop. 
As a quick hack, you can store the static data as a single binary blob in the database, and later think about providing this information separately from the database.
I'm a huge advocate of the Kappa architecture: http://milinda.pathirage.org/kappa-architecture.com/. Tl;dr: Just use Kafka as a WAL for all your state.
Thanks for clarifying! 
Thanks, that's great! &gt; Why use '\u' notation instead of just using ASCII? Because I wasn't fully grasping that runes are just int32! I actually started out using hex (e.g. c == 0x41 ) but was getting an error about mismatched types (rune vs int), so went back to '\u0000' notation. &gt; Why loop, instead of just using arithmetic? Given the above misunderstanding, this seemed necessary at the time. 
There is also [reftree](https://github.com/stanch/reftree) ([docs](http://stanch.github.io/reftree/)) for scala.
Keep state in the client. Send an offset or something with every request. If that's not an option: Go isn't really designed to be like Erlang/Elixir, where you can do IPC between instances of your program to communicate that state. For better or worse. There might be ways to set up some sort of consensus algorithm between your apps, but its not worth it. Just use a database. Etcd is probably the easiest one to set up and its blazing fast. Consul or Redis would also work.
What you are optimizing here are syscalls and memcpy's. Any sane OS caches files in memory, so repeated reads will be entirely from memory (as long as there is enough memory for it). The OS caches are also smarter than any user-space cache, as it can consume all memory not used by processes. You're going down a wrong track here. The caching functionality in nginx and other HTTP servers is meant to cache dynamic content which is costly to generate, or to act as a reverse caching proxy in front of remote or slow servers. It is absolutely not meant to cache local files. Using it in such a way is mostly a waste of resources, and replicating such a setup in Go is silly. Just for reference, if you are actually looking at pushing the limits of the machine you are hosting files from (I have zero reason to believe that this is the situation you're in, and in such case, Go is a suboptimal choice), then a cache will save syscalls and copying, which is a nice win. If your resources can all fit in memory, you could just make a map[path]resource, where path is a string and resource holds headers and a byte[], all filled out on server start. I did that once, and had a seperate webserver bound to 127.0.0.1 where you could ask it to reload resources. However, this is *micro* optimization. Poor locking would annihilate any benefits from this. If you want to write pretty Go with channels and defers, then you are barking up the wrong tree.
Keep us posted. :)
Something like https://github.com/astaxie/beego/tree/master/cache?
Awesome stuff! 
Yeah chewxy (the channel creator) really wants generics which is only natural considering [the problem domain he is working on](https://github.com/gorgonia/gorgonia).
&gt; Yeah chewxy (the channel creator) really wants generics not entirely true. I am OK with having no generics. In fact I'd rather have no generics than Java-style erasure generics. I'm working on a few ideas atm on different possible generics path for Go
Without the actual code, I can't really give you more than 'use the profiler'. Specifically, [this package](https://github.com/pkg/profile) should drop into your `main()`. Since you probably want to ctrl-c your program rather than wait once the slowdown happens, [catch the signal](https://stackoverflow.com/a/11269077) and call `profile.Stop()` using a closure to capture the result from `profile.Start()`. Some potential issues could be heap allocation or constant regex compilation. Profiling should reveal this.
The right answer depends on a lot of parameters you don't give here, like how important it is for it to never give out identical lines, how distributed you need this to be, how catastrophic it is if you lose one node, etc. If it doesn't matter to you much what is going on, and you don't mind manual intervention on node failure, a simple socket on a centralized server that hands out numbers on demand will work just fine. But those are big "ifs". If you need clusterability and automatic failover and so on and so on, you end up still coming out ahead to just use a database or something, because that will still be easier than writing something _correct_ with all those properties. Edit: There are servers that have as a feature this "counter" ability... Keep an eye out for those, and _read the fine print_ on exactly what they provide.
Here are some questions, answers, and links to great explanations. https://stackoverflow.com/questions/6345020/what-is-the-difference-between-buffer-vs-cache-memory-in-linux
&gt; I've searched all over but I can't seem to find an explanation for this. Because the explanation is on your server, not on the internet. And we aren't going to be able to explain it to you because we can't see what's on your server either. This is all you. Your next steps might go something like: find the option(s) and/or tool(s) provided with your DB to start logging slow queries. Find out what are the slowest, then use EXPLAIN to see what's going on... it might tell you that you're missing an index or something. You might also look at lock contention, to see if your query is hung up waiting for some row(s) to become unlocked. You could also take a packet capture of the traffic between the DB and your program. Could be some clues there. &gt; at what appears to be the rows.Next() point. You might also profile your program, to make sure this is what's happening. You could spend all day looking at your DB but if your program's locking itself, all that DB work is for naught.
Look at how Ada implements generics. No type erasure nor templates.
Why varnish haven't yet been quoted in this thread ? It's nginx with purge, in memory caching, load balancing.
Yep. I learned Ada for this purpose (along the way [this happened](https://twitter.com/chewxy/status/895194648729104384) )
There are other tools you can use for this outside of go. You can definitely do it in go, but that doesn’t mean it’s a good idea. Something like Varnish would work well. 
It's python, not Go, but you might appreciate: https://github.com/reinderien/mimic
&gt; It won't be going live for years so I'm not too bothered about scalability at this point. Scalability isn't something that you can fix at the end of a project. It's something you have to design for at the outset. Especially when using a database... a bad schema can reduce even the most efficient application to a crawl (lock contention). You said in another post that you want to write something prod-ready... I don't see it happening here.
I generated this tool for tracking test coverage on some of my own projects, and thought it might be useful for others in the community too! Inspired by the badges generated by https://coveralls.io/.
That is interesting. It's not really an "apples to apples" comparison to some of those languages because they implement Perl style regular expressions instead of just regular expressions. It looks like Go's implementation could use some more optimization. Rust's regular expression engine is way faster even though they use the same general design.
Yeah, I thought that whole site was pretty interesting. Generally speaking, Go performed admirably, but regex definitely stood out.
I just use the standard. Been collecting resources doing so. I advice you to do the same. I'm still struggling with Jquery auto compete but it's coming along. It's just doing relational db stuff in practice that gets confusing. The coding part is always doable. I guess that's where gorm as a prototype comes in specifically. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk&amp;ouid=116246055924160986923 
Because I'm a crazy nut, and I'll take any excuse to write a bunch of go code, I created a fuller example here: https://github.com/pdk/genquery This has example implementation of `GetString(colName string)`, `GetNumeric(colName string)`, etc. and a metadata driven scanner that figures out the right type variables to scan based on metadata types (`ScanRow` in datacontainer.go). (What I was doing with the code from my previous example didn't require dealing with handling different types. Just getting everything as strings was sufficient.) The point being that you can create whatever framework you want, at the level of abstraction that most closely matches what you want to accomplish. If you really want to provide a base with a bunch of structs so that other programmers can easily build on top of specific types, you can use an ORM approach. If you just want to build a way to (almost generically) get/retrieve data in a database via REST calls, then a bunch of structs is just noise. Getting back to the "thinking of switching to python" issue: What I'm trying to show is that you can build stuff that is just as flexible as stuff that people might think python is better at, but the biggest difference is that go is a lot more forceful about encouraging the programmer to check for errors and handle types correctly. In python it's easy to write code that _mostly works_. What I've done is a very quick and dirty example, and I've glossed over a lot of error handling, but some might still complain about it being too verbose: nullIsGood, err := data.GetBool("is_good") FatalIfErr("retrieve is_good", err) isGood, err := nullIsGood.Value() FatalIfErr("retrieve is_good value", err) log.Printf("column is_good has value %t", isGood) In python there will be the same failure conditions: is the column actually in the result? is it null? is it the data type I think it is? A difference is that in python the tendency is to just code as if everything will be just fine, and that your assumptions are valid. And then, of course, on a completely different trajectory, there's the generators for everything path. :) There are tools floating around that will look at your data base and generate go structs. That can provide a basis for just generating structs for all your 300 tables, and all the associated code you want for every type.
The entire static fileset could be copied to the `tmpfs` that resides in memory and has nothing to do with the disk IO. Cheap, dirty, fast.
Thanks for the ideas! From your explanation I notice I might have a misconception of how the query process works in Go then. I assumed that, once DB.Query returns its result as a Rows object, the querying was over, and that all rows were now sitting in memory waiting to be iterated over with Next and Scan. Does this mean that, as I'm iterating over the rows, those rows are still being fetched? This is why I assumed that it was all on Go's side.
Just wondering why they would steal some other companies logo (favicon): https://www.duetdisplay.com/
So what's the list of embedded system that Rust successfully targets? 
One approach with these kinds of problems helps is working your way in reverse... Imagine that you have all the things you need then what would be the minimal code that would be sufficient to write the code that you need. As an example: mux.Register("/admin/monster/{monster.ID}", admin.Manager(&amp;Monsters{})) Then you write all those different bits and pieces of domain-logic that you need and work on the next level of abstraction, adjusting the first level as necessary. When you can implement some level there with an existing piece (such as database), great, you managed avoid some work. Eventually, you will have the full-stack implemented. By taking your starting point of making different folders such as `admin/model` you are forcing your design into a solution that may not make sense for you, which leads to accidental complexity and things that don't fit together. Of course, there's a downside to this approach... it requires more thinking up-front than the "framework style" throwing things together.
Yup, don't worry I love this approach!
You can get the same (but with better integration and CI) on [Gitlab](https://b.agilob.net/test-coverage-in-gitlab-ci-in-a-golang-project).
Most 32 bit chips Just Work. AVR support is almost here. Basically, anything LLVM can target. The only one people ask about often that straight up doesn’t exist is Xtensa. It’s a backend issue, not a language issue, though. So in theory, basically anything. Theory and practice are different obviously. Oh and this is not a real answer, but use mrustc to compile to C and then use a C compiler, boom! Works on basically anything.
&gt; Theory and practice are different obviously. Good thing theory ships products then...oh wait it doesn't and there is still a glaring lack of production-ready embedded Rust projects &gt; but use mrustc to compile to C and then use a C compiler, boom! Works on basically anything. "Don't write C but use C anyway!" 
It is such a turn off to see Chinese characters on golang documentation as well as in here, why don't you have those under a separate page.
Are you just "rehosting" the golanguk video? https://www.youtube.com/watch?v=75NjCfLLftw 
pair programming is just the worst (most of the time)
Lol the banana!
Why do you think so? 
Obligatory: it is not "GO," it is "Go."
Go has access to the file system, so if you can mount a normal solution you can access it via go.
Thanks, got it working
Yes, but specifically I’d really like to find something that lends itself to programmatic access rather than a hacky bash os.exec call. 
Because it's not necessary here. You don't use Varnish to cache static files on the same machine as the files are served from. That's just a waste of memory and cycles.
What exactly are you trying to do? The cross platform requirement is strange in this context (to me at least)
That looks like a good alternative! Personally, I am using Github, and I am very happy with it. This project is meant to work as a simple drop-in for any Go project, regardless of Git Hosting + CI setup. 
As of this writing, the page states: "japan" &lt; "Japan" true But I think this is actually false, as confirmed on playground using a snippet like: fmt.Println("japan" &lt; "Japan") Perhaps you would be interested to look into this?
&gt; Exit a switch &gt;A break statement terminates execution of the &gt;innermost for, switch, or select statement. My favorite feature of switch statements! It was odd when I saw `fallthrough` for the first time, but it makes complete sense now. 
Unless you're shouting! 😁
This looks awesome! I'm not really familiar with Gitter - what's the benefit of using that over slack? I've done a lot of pair programming with slack and they already have built-in screensharing and (optional) screen control that makes the whole process pretty simple. 
[removed]
Hey good job, I found the code pretty easy to read. Make sure to call resp.Body.Close() after your http request or you will leak memory. I'd also get rid of worker and make it a single function call passing in the request and response channel.
Ransomware?
Thanks, yes I need to close out the response. Also I wanted worker to see, how to pass channels across structs etc. 
For me, coming from a C background, the first time I encountered this in Go, it didn't behave like I expected, since `fallthrough` is the default in C/C++. This makes sense if you understand how it works and the difference in philosophies behind the languages, where C/C++ is more of an explicit nature than the more pragmatic approach Go takes. The default behaviour in Go is what you want 99% of the time when using a `switch` statement. In the end, al it does is generate a bunch of conditional jumps into a linear set of instructions depending on the value. In Go (and other languages) - these pieces of code where you jump to are treated as individual blocks where at the end of each there's just a jump to the end of all those blocks. The `fallthrough` statement at the end just prevents this jump from being automagically generated by the compiler. In C/C++ it's the other way around - it's treated as a single continuous block, where you have to tell it to `break` in order to jump to the end of the complete block of code inside the `switch` statement.
The query is ongoing, you've effectively established a pipe that you're consuming from. Under the hood, you're receiving data in chunks of multiple rows at a time. While that's an obvious explanation for your performance hitches, the GC would also fit the symptoms. Though probably not on a recent version of the language, after all their work to keep individual collections small.
This is important. I've been burned by having a switch statement within a loop and a `break` within one of the switch cases, expecting the loop to be exited if that case is hit. But it just exits the switch case itself, not the loop. 
There are several buffers between you and the database: there's a row buffer on the DB itself, there are buffers in your network stack, and there are buffers in your DB client library. I'd start by looking at your client library to see how that's being used... are the default values in that library suitable for your use case?
You're welcome. :)
I visit the subreddit almost every day and I never saw this post until today. Given this is a new account, it's likely that your post wasn't approved yet by the moderators or something like that. After you make a post, you could try visiting the subreddit logged out to make sure your post it's visible. Now on topic, I consider testing to be a standard engineering practice. Go's tooling and culture make it abundantly clear that tests are part of the code. The `testing` package and `go test` make it trivial to write tests. In terms of test quantity for me it goes: unit tests &gt; integration tests &gt; e2e tests The testing tools we got are already pretty good and can help you go pretty far without even reaching for an external library which is the default in most other languages. I also think that Go is the only language that makes it easy to have runnable examples as part of the code which serve both as tests and documentation. Some useful resources: * https://golang.org/doc/code.html#Testing * https://golang.org/pkg/testing/ * [The cover story](https://blog.golang.org/cover) * [Andrew Gerrand - Testing Techniques](https://talks.golang.org/2014/testing.slide#1) * [Table Driven Tests](https://github.com/golang/go/wiki/TableDrivenTests) * [Mitchell Hashimoto - Advanced Testing with Go](https://www.youtube.com/watch?v=8hQG7QlcLBk)
I've added an example to show how to break out of both a switch statement and a loop. Thanks for the feedback!
Do something like this: // Message wraps all messages type Message struct { Kind string Data json.RawMessage } // FooData is the payload for a "foo" message type FooData struct { ... foo fields } // BarData is the payload for a "bar" message type BarData struct { ... bar fields } In your read loop, call ReadJSON: for { var m Message if err := c.ReadJSON(&amp;m); err != nil { // handle error (exit loop and close connection) } switch m.Kind { case "foo": var d FooData if err := json.Unmarshal([]byte(m.Data), &amp;d); err != nil { // handle error } // do something with d case "bar": ... } } } 
Whaoh! Thanks ill try this for sure!!:) 
&gt;"Don't write C but use C anyway!" We don't write in assembly but use assembly... What's the issue?
Fair points. So, the real requirement is for a user to be able to remotely lock and unlock the disk in the easiest manner possible. However, I haven't seen anything that lets LUKS play well (easily at least) on Windows, and it's the only one that would allow automounting with /etc/fstab. Veracrypt requires some command line parameters at each mount and unmount, and makes it really not reliable for something like udev rules. Currently users access a disk that's mounted with udev rules to a known path. This makes the implementation nice and easy and there's no mounting work to be done by Golang. Essentially I'd like the same thing, but with the added layer of encryption. Granted, users will need to provide the password &amp;/or key at mount time. The additional requirement I probably should have spelled out would be that the disk is done via the key provided by the user over the web ui or REST API. I point to full disk encryption because it would eliminate the need to dynamically allocate encrypted storage space, which can take some lengthy preparation time based on the size requirement. With a full disk solution, we can prep this disk in advance.
The drive is removable, and users access it after they're finished writing data to it remotely, they then plug it into a windows machine. I agree it's a very unique situation.
You're control flow is really confusing. Idiomatic Go returns early.
I guess you are talking about CheckSignature() function. In my company we are using 5-6 languages in our product (same team), and we apply some common coding standards on all of them. So we try to minimize return statements. But anyway good point of view thanks, i changed and try to make more attention on this next time ;)
We write a lot of tests at my work place so it kind of comes to me quite naturally. That being said, I have yet to try out writing tests in Go since I am very new with the language. 
Here's a blog post about it: https://medium.com/@matryer/line-of-sight-in-code-186dd7cdea88
Tried it, you saved me alot of head ache! The map contaning the functions has made my api alot easier and probably more effeciant! Ive gotten rid of two channels one multicast and one broadcast and the api is much more scalable now! Im really greatful for this, that was a neat trick! Summary: 1) you made my api scalable, instead of changing the code for each new wanted function I now simply modify my func setupHandlers() where the map is initiated with all wanted handlers. 2) efficenty, no longer do I need two global channels (yes, bad i know) that is continously scanned 3) Simplicity, since alot of logic handling is now gone, its much easier ti read and understand 4) the function callback, storing functions inside map, neat trick that I will try to implement more often, meaning alot of code will be more generic. 5) You sir, helped me alot! Many thanks for your time! I wish I had any reddit gold, if I did, id give you! ( Dont even know how to give them tho!:))
Assuming your JSON file is large because it contains long list of objects, you do something like this: https://golang.org/pkg/encoding/json/#example_Decoder_Decode_stream Basically you you find the beginning of the array using the streaming API and then use json.Decoder to decode the array elements one by one. 
There are a number of third-party JSON decoders, with various trade-offs: https://github.com/pquerna/ffjson , https://github.com/mailru/easyjson , but I would benchmark first to determine that json.Decoder isn't performing well enough before switching to one of them.
&gt; But of course the encrypted data will be accessible from different people (admins, developers, etc...) Rather than using a derivation of the password as the encryption key, you could generate a random data encryption key and store that key encrypted multiple times, once for each role (user, admin, dev, etc). Pass these passwords through PBDKF2 w/ 10000+ iterations and then use the derived key to AES encrypt the data key. data - AES CBC encrypted data data_key - randomly generated key data_key_user - AES encrypted Data_key with pbkdf2 10k user password data_key_admin - AES encrypted Data_key with pbkdf2 10k admin password data_key_dev - AES encrypted Data_key with pbkdf2 10k developer password You could go up to 100k on pbkdf2 if you like, but 10k is near NIST recommended minimum. Of course if it was me, I'd pbkdf the user password client side and remove backdoor data access if possible. Then again, I don't know your app requirements.
I made a dockerfile that runs a local webserver including all the pakcages in your gopath `docker pull deltaskelta/go-docs` https://github.com/deltaskelta/dockerfiles/tree/master/go-docs
Without seeing your code I have no idea what's taking 6% of your CPU. You are probably calling poll on a file descriptor, maybe your timeout is too low. Maybe you are generating garbage with a new error on each failed poll instead of using sentinels. Not sure. Regardless you probably try to use whatever library exists for it, a quick google shows: https://github.com/monome/libmonome/search?utf8=%E2%9C%93&amp;q=poll&amp;type= they support linux and have drivers available. You could call that with CGO if you needed to. Good luck.
Just curious, what are you doing that requires more specific GC guarantees?
This is good to hear as I just bought it today :D
Database table has to be indexed. Indexing help to resolve such poblems.
How about using glassdoor instead? 
[removed]
You never need to do this because the kernel already does it for you.
Interesting. What languages / runtimes are you thinking of that offer these guarantees?
First, run EXPLAIN ANALYZE the problematic query and see if it's the query itself working slow. My second guess is that lib pq has some issues with buffer management as with Java and Ruby drivers I was able to fetch hundreds of thousands of rows quickly and without any issues. So, do yourself a favour and try to do run the query via CLI and if it works flawlessly, then try to use other languages to fetch the same dataset. If nothing yields the same results then please submit a bug for the pg developers to fix. 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/neocirclejerk] [NEOPETS CONFIRMED FOR PHP3 SPAGHETTI - MMMMM](https://www.reddit.com/r/neocirclejerk/comments/85fy8d/neopets_confirmed_for_php3_spaghetti_mmmmm/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
nice, but also more work for the computer
Don't show this to /r/programming...they'll complain about not having generics, polymorphic parametrization (lol), and google 
Why do they have against Google? There's a wealth of knowledge there, especially in high performance code and parallel computing. I'm not saying I'd ever work for Google, but I can't deny they have some serious brain power.
You stored a pointer into the interface, then copied the value of that pointer. So what? That isn't the point of the original question. The OP isn't asking for a work around, he's asking a question about the design of Go.
In case you didn't notice, the OP marked my answer as the correct one and commented: *Thanks for explaining instead of stating "you should ask another question", like the others do.* 
**My longest yeah boy ever **
I'd really rather be writing Go than python, at least there's some serious arguments *[Redacted rant to avoid a holy war]*
http://dave.cheney.net/resources-for-new-go-programmers
Yup, that might be one way to do it. I'm new to golang and may be I'm wrong here but I just wanted to learn channels and implemented this way. Will try out your approach as well. Thanks. 
You can set vars at build time like so: package main var buildTimeVar string . go build -ldflags "-X main.buildTimeVar='value'"
I may have worded it poorly, but I mean I already have my “main” executable compiled but when I want to create the stub with custom settings from within my main executable, how would I go about adding those settings to the stub? An example would be Quasar RAT’s “build” button. 
How I did this back in the day in C, is the server would have a global static char* variable that would have data like: "---===--===START===--===--- port:12345 key1:value1 key2:value2 \0\0\0\0\0\0 ---===--===END===--===--- " Then in your server editor, it would open the binary, find that section, parse the values, and be able to save it to the same location. I had padding at the end to make sure it could hold larger values if the user put them in there. This was a basic way to do it and it's not very stealth.
&gt; which is bad practice Why should this be bad practice? I think uniformity of code is a good thing. Call this a "pattern" and have a good day. Nothing to worry here.
Your test cases are almost always of a specific type that relates to the code that you're testing though, so there's not really any way to abstract it sensibly. There's also the adage: *A little copying is better than a little dependency.*
It's always easier to find faults than it is to point out good things. It's just the way we're wired, I guess.
It's very possible that I'm misreading your question, but what it sounds like you're describing is kind of in the realm of the concept of [table testing](https://github.com/golang/go/wiki/TableDrivenTests). That way you can illustrate test cases as data. I've found that it helps to iron out more edge cases as I write them. A good, albeit a little complicated example I've been studying lately [here](https://github.com/Shopify/sarama/blob/master/client_tls_test.go).
Thanks a lot for the link about the zip files, I may be in over my head for now but I think that approach would be the most simple for me to learn! 
[removed]
The [Stack Overflow Developer Survey 2018](https://insights.stackoverflow.com/survey/2018/#work-salary-and-experience-by-language) might be a good start.
Maybe you are looking for something like this: [dearplain/goloader: a golang dynamic loader](https://github.com/dearplain/goloader)
Well I did write out a lengthy rant about python before deleting it, so I guess you're right.
If I want to change something small with the t.Errorf función, I have a lot of refactoring to do
Yes, that's exactly what I'm describing! Thank you! I think I could easily turn this into a small library to make error messages more uniform. Thanks
Go is exceptionally good at a fairly small number of things. It is extremely awkward at a large number of things. Probably most of the people you are talking to are more focused on frontend web dev, or mobile apps, or games, or basically anything other than server apps.
We still love your spaghetti! 203 month account &amp; still going strong! :D
None really, in GC'd languages, you'll always be chasing after GC implementation if you do something that disagrees with the major paradigm of the language. The flip side is no GC which makes memory management a pain in the ass (seealso : C with random segfaults, or Rust with borrow checker which now is much better). 
No, you can't, because you don't have generics in Go and because that library would have to accept an input and an output set of values, and all it would do would be to use a for loop and run the tests against the input value. Don't try to abstract the wheel when there's nothing to abstract.
Now I'm confused. I have no idea how your original question is related to this reply. Probably you should show code.
I prefer enclosing a for, select within a function and returning, labels in my experience have the possibility of becoming messy and hard to follow if overused.
The question sounds the way suggesting the poster for some bizzare reason assumes the whole population of this subreddit is in the US.
For development many services, each can used common packages, example: logger, DB driver, data model and etc. Each service using own repository and vendoring (dep, glide or go.mod) gosvm provide tool for version management for several repositoreis
Thanks! Glad you enjoyed it :)
Because `OnPaint` is being called from a tight loop that triggers itself: onPaint(glctx, sz) a.Publish() // Drive the animation by preparing to paint the next frame // after this one is shown. a.Send(paint.Event{}) And then `OnPaint` resets the color: glctx.ClearColor(0, 0, 1, 1) Change `OnPaint` to only do this and it should work: func onPaint(glctx gl.Context, sz size.Event) { glctx.Clear(gl.COLOR_BUFFER_BIT) }
I've been bugging antirez to learn Go for the past 2 years or so, glad to see he liked it :) 
[removed]
How many devices do you need to support? What type of data do they collect (timeseries metrics? or something else?). If you want good advice you need to give a lot more details and some scope on what you are tring to do.
It's frustrating, but it's one of those things that you understand after having worked with Go for a while. Compromises had to be made, not having generics is a compromise to ensure that other goals that Go set out to achieve were met. A lot of people don't seem to think through why some decisions were made early on, and (like myself at first) don't really like the language as a result. Also, people just like to circle jerk I guess.
Coming from C#, I find myself missing polymorphism in very specific circumstances, but those don't come up often. I was very surprised to discover I haven't missed generics at all, though. But once I got used to it, I realized generics are a design pattern that can always be avoided. I understand where they're convenient, but I've never actually needed them.
It would have been more helpful to link the actual repository. I see "No packages found."
That's weird: I now get "No packages found", too. Here's [the repo](https://godoc.org/blitiri.com.ar/go/chasquid/cmd/mda-lmtp).
Don't use ffjson if memory is a concern. Its decoder reads the whole json from the reader first before decoding it [1]. [1] https://github.com/pquerna/ffjson/blob/master/ffjson/decoder.go#L61
following this one, interested into IOT projects for some time as well 
Think security early-on and make sure you aren't building a future DDOS bot net. How will devices authenticate with your backend, is there a way (through your app or otherwise) to send security patches back to the devices, can they be remotely disabled if needed, etc. I don't know if this is always true, but in my limited experience IOT apps are much heavier on the write side than on the read side. Meaning that you may be constantly writing data from large numbers of devices, but only a small pool of admin users read it back. If that feels true for your case, optimize the database schema, your queries, and your caching strategies for quick writes.
Thanks so much, that worked perfectly. I was trying to use PowerShell but it kept opening a new terminal window to run the benchmarks, then closing it automatically after the benchmark had finished so I couldn't see the result.
I agree, I recently started with this team and the whole go environment is new to the company. The issue is, we believe our VPN is blocking any git cloning from github. Basically when we call git clone github.com/rana/ora (Any github repo) we get "Can not resolve hostname github.com"
Yeah, especially in cases like, you know, collections. 
Yeah, interfaces, like `ICollection&lt;&gt;` and `IEnumerable&lt;&gt;`?
&gt; But once I got used to it, I realized generics are a design pattern that can always be avoided. Generics are not a design pattern, they are a language fature. And yes, they can always be avoided, but so can be most other language features. You can always strip away language features as long as turing completeness is maintained and it will still 'work' (you will end up with what is colloquially known as a 'turing tarpit' - google it for amusement and education). For example, you could remove member functions and live with it, after all, C doesn't have them. However, with every language feature taken away, you lose something. In case of generics, the ability to DRY and maintain type safety is reduced quite a lot. 
I've done a reasonably-large IoT platform project and Squeakerpants nails all the big comments I have as well. Clearly they have done this before!
Stay away from fire and forget transport protocols like mqtt. If your having devices reacting to devices you really need to know that device got your message and responded like you expect
What are the differences from open faas?
Thanks @delta_skelta! Will definitely check it out.
Thanks @beknowly! Previous discussions from 2015 seemed to discourage rebuilding a local version of gddo directly, but I am sure the code can be a good indicator/basis for alternative approaches to pursue.
https://godoc.org/sync#Map. Just look at it. And that's in the _standard library_.
I'm genuinely interested to hear your experience. I have had great success using Go for web services, forward and reverse proxies, server daemons for various tasks, internal grpc microservices, matchmaking servers, and serverless compute functions, but in my mind those are all pretty similar things. I've found Go to be largely unusable for serious projects in the categories I mentioned above. Trying to use it for anything not running on a server has generally been quite unsatisfactory for me. With no disrespect to the people working on cool projects like golang/mobile or Azul3D or lxn/walk, those projects just aren't anywhere near the polish level of native iOS dev or Unity or Unreal or WPF, (and they don't claim to be) so they don't seem like good choices right now for for serious work projects in those areas.
Applied, cheers
About that, I have just pushed a followup of this post about socket activation: https://vincent.bernat.im/en/blog/2018-systemd-golang-socket-activation
You might want to use [`github.com/stretchr/testify`](https://github.com/stretchr/testify/) then—basically it allows you to spill `assert.Whatever` instead of hand-crafted calls to `t.Errorf` as it has sensible idea about how to write what happened.
Yeah it's a knee jerk reaction...."I can't do x because go doesn't have y so thrilled whole language is shit" 
basically licensing, and who contributes to it.
I've really enjoyed working with Influx Data's open source stack for time series data. 
Just a short feedback, you could use a more inclusive language. See: &gt; DM him with your communication info. &gt; Wait for him to send you his communication info with a DM.
In my opinion this is just the beginning. More and more company are going to turn to Go for API &amp; Back End.Go "out of the box performance" &amp; architecture really makes it a perfect fit for low latency application and large traffic applications , especially compared to NodeJS or Java. Wouldn't be surprised if the language went to 12% or so in the coming 2 years .
Thanks I'll have to read some more about this
How would this work when a JSON document has nested arrays? I made the following use the example but the loop stops after the first array. https://play.golang.org/p/2oIzcX4OPQS
If you are working with micro controllers (Arduino/esp8266/esp32/etc) over TCP, be careful as they can sometimes act unpredictably, ex: if you don't utilize read/write timeouts and some sort of layer 4 ping a device can just go offline and your app will still think the TCP is connected until you next try to write on the pipe
how about here https://golang.org/pkg/reflect/#SliceHeader ?
From spending a lot of time writing Go and trying to find a job writing Go, I feel like it's really an untapped resource. It's a really solid language for cloud computing, it's easy to learn (even at a higher, production-ready level) and it has *really* solid standard lib, documentation and community.
A runtime safe `sync.map`?
If it fits your usecase, we've had good luck with [jsonParser](https://github.com/buger/jsonparser). It's a lot faster than a lot of the others. See the benchmarks in the README - the numbers are old, but it really is fast.
&gt; Tests are a huge part of your codebase and your workflow includes writing lots of tests I absolutely agree. I generally write at least 4x as much testing code as I do actual code, and it makes testing a breeze. It's often a lot of copying and pasting, but futuristic editors like Atom make it much easier. Thanks for the article!
Go is probably the best language for writing GTK apps right now even though the prominent GTK bindings are far from complete. Vala is built explicitly for GObject/GTK and it's *still* worse than Go (building is extremely complicated, the compiler is buggy, memory is reference counted (cyclical references), weird/arbitrary inheritance/interface rules, etc). Go is fine for games (needs a bit more mature libraries, but there's nothing incompatible in the language) But yeah, for things like web dev, android apps, and iOS apps, everything but JS, JVM langs, and Swift/Objective-C (respectively) are going to be "extremely awkward".
A lot of differentiation in the Fn team itself. We have a lot of experience building these systems as we were the creators of IronFunctions and the IronWorker platform which was one of the earliest serverless services. I tried to sum up much of why we originally built Fn here: https://medium.com/fnproject/8-reasons-why-we-built-the-fn-project-bcfe45c5ae63 We're moving quickly and expect to get to GA shortly (~months) along with a more solidified roadmap around then as well. Feedback welcome. The team is in slack.fnproject.io.
Help a newbie out. I'm a sysadmin, picking up Go to keep my mind sharp. Mostly I've been using bash for little tasks around the server room. With bash I'd write a function in the code and I'm good to go. I might get fancy and include a library to functions commonly used by the team. Functions as a Service .. I don't get the point. Stuffing a function in the code is no longer a thing, in Go?
I think outside the west coast and known Go-using companies, there are a lot of places that use Go but don't mention it in job postings. I've worked with two teams where they had Go code but only posted to hire .Net devs. Sometimes you have to get lucky, and then as you gain seniority, you will also gain the ability to make some of your own decisions in this regard.
we have a company that make developing smarthome technology. and we almost used to for 4 years at go. we are like everytime because it is very fast language
In my experience it is only good in network services, simple data processing and CLI utils. That's all.
I appreciate that!
With FaaS, you're taking some self-contained code referred to as a function, uploading it to a platform (the FaaS), and "calling" the function using a trigger mechanism which is usually over HTTP such as a webhook. With Fn specifically, this function can be any container, and act on anything to STDIN and emit its results to STDOUT/STDERR. The simplest way to try it out is follow the hello world. It'll walk you through 3 simple commands, fn init, fn run, fn deploy, and fn call. Expand from there. 
I agree with you on the facts (that Go is bad at games, windows UI, mobile etc.). I just don't think that backend programming is "fairly small number of things". I mean it is as small as enumeration. It's only one thing. But when you look at jobs, today those are major categories: * web front-end * backend of all kinds (for web and services to support web front-end or mobile front-end) * mobile * a very distant 4th: games * a very distant 5th: desktop apps There's is no language that is really good at more than one thing. Swift and Objective-C are pretty much only for iOS and a distant second for Mac apps. Non-existant as web front-end or backend languages. JavaScript is all front-end and some backend. PHP, Python, Ruby, node.js are just like Go: only good at backend (and sys-admin scripting). C++ is pretty much only great at games and high-end desktop apps like Chrome or Photoshop. So I would be down with "Go is good at small number of things" if we also acknowledge that the same is true about Python, Swift, Ruby etc. 
Go replacing Java would be fantastic. I'd even settle for just Kotlin replacing Java!
One of my grievances with open faas is that the model is "build a function and we'll turn it into a binary and run it once per request" instead of "build a function and we'll turn it into an HTTP server that runs for the life of the container". How does fn compare?
Java isn't going anywhere. It's bearable with Lombok annotations, though. But yeah - I hope to use Kotlin some day, it's difficult to argue for when no one knows it and everyone would prefer Java because it's comfortable..
I've written a couple of small 2d games with it using a game engine and it was an enjoyable experience. They were fast and smooth. I've also written a large desktop application using a Qt binding and it worked pretty well with the usual caveats around that kind of binding. Honestly I think the "Go is only good for server side applications" story is pretty much propaganda.
&gt; but only posted to hire .Net devs. See, I always just completely ignore those postings. I don't use windows, haven't used it in years and don't plain to in the future. Ever. Double goes for .Net
Sure, and I don't entirely know why management and or HR chooses to have inaccurate postings, but my assumption is that they don't believe they will find a go developer and simply want a developer that will fit in with the rest of the stack. It is annoying since it makes it nearly impossible to find a lot of those go jobs since go will not be listed in those cases. I just don't know a way to find those jobs other than getting lucky when you're hired for a Java, Python, C#, or Ruby job and suddenly you are a go developer instead. 😋 That said, one of the teams I'm mentioning did not deploy to Windows. It was 100% .Net core on Ubuntu Linux with Docker and Postgres, so C# does not necessarily mean a Windows stack. I strongly prefer Linux to Windows but also think C# is a pretty good language, especially if you use .Net Core and VS Code. 
Yeah, I don't mean to imply that I think everyone in this community is American, and I don't know what it's like in other markets. 
Can say that here in Denmark, nobody uses Kotlin. But we're a Microsoft country.. so C# is mostly all the rage
Good work. I quite enjoy it
lol video post
Man, there is such an overwhelming number of FaaS options these days, both written in Go and other languages: OpenFaaS, Nuclio, Funktion, Fission, the Gestalt Platform, Fn. Some of them focus on providing direct handler function access for "hot functions" and some just try to generically wrap everything into per-request stdin calls. This Fn project looks really cool, but I have to say, its really hard to try and keep all these competing options in a table and compare them. 
[removed]
Fn has a feature called hot functions which will keep the container alive while it's serving traffic. The language FDK's (function dev kits) provide a handler that makes hot functions transparent and easy to use, the system will take care of the rest including routing requests to hot containers with capacity until it's reached then routing to the next node, etc. That said there's no guarantee that a function will be hot (there will be some cold starts) and thus no guarantee that you'll be on the same machine, access the same local ephemeral storage, etc. See more here: https://github.com/fnproject/fn/blob/master/docs/developers/hot-functions.md
Really cool! I'm the CTO at DrugBank, is it okay if I post a link to this from our blog / twitter?
Collections. How do you represent a list of types with type safety without resorting to generics? And if "interfaces" is your answer, please elaborate.
Not an exploit. This a PoC. 
Are there any non GPL'd Qt bindings? All the bindings I used were nice and then I get smacked in the face with GPL.
I used https://github.com/therecipe/qt which is LGPLv3.
I can't tell if what you're describing matches what I'm describing or not. It sounds like you're talking about keeping containers alive, but running the executable once per request. I'm proposing keeping the container alive with long-running server processes. By way of example: Let's say our application is implemented in Go and the function signature is `func(Request) Response`. One option is to compile that into a single process that reads a serialized Request from stdin and writes a serialized response to stdout before terminating. This is what OpenFaaS does. Now we can do "hot functions" and keep the container around, but we're still forking this same process with each request. _I propose_ we compile the function into a *webserver* that continuously handles requests, thereby foregoing the overhead of process forking.
We are replacing all of the video streaming components that we had written in Go - because of the cost savings which are demonstrable with the cloud servers we run our stack on.
[removed]
Switch the `COPY` and `RUN` lines for better caching. 
It doesn't need remote code execution to be an expoit.
Let me prefix this by saying that I use Go and C# on a daily basis. Go is great. My main problem with the platform is that .NET exists. Specifically .NET Core. Go and .NET Core are extremely similar, except C# is far more mature and has far batter tools simply because it's been around for so long. Feature wise, Go almost feels like a pure subset of .NET Core which makes it very hard to justify its use for new projects. Performance is comparable. To make matters worse, .NET Core is actually easier to get started with. We generally use it on projects on which the lead developer simply refuses to touch anything associated with Microsoft. Or because people have outdated knowledge on .NET and think it runs slowly or only on Windows. I'm hoping Go branches out and does something unique that makes it easier to recommend. The more .NET Core spreads into Linux environments the more Go will end up living in its shadow.
I posted about this above, but our main issues is .NET Core. It's very difficult to recommend Go above .NET Core since .NET Core matches it in performance and portability but has far more features and far more mature tools. Go code is a bit less verbose than many C# projects, but you could just throw your entire codebase inside a single C# class and get a similar result. Go needs its killer feature. Something C# can't do. I'd like to use it more. 
I read that sentence over five times and still don't get it. Please unbreak my brain with one of the following choices: - You're replacing the stuff you had written with Go and can demonstrate the cost savings in your cloud environment. - You're replacing the code you wrote in Go with the cloud. The first one makes more sense. The second one may make sense with a serverless type approach but without more specifics it sounds like "Just put it in the cloud!" ha.
They are rewriting the video streaming components, which are not currently in Go, in Go
You sure because that's not what it says: &gt; we **had written** in Go Pretty sure you're right, it's the thing that makes the most sense....but I asked anyway since you never know.
I switched to go from python last year. I switched from C++ to python a few years ago to enter web development. I'm loving Go so far: - It's faster than python out of the box. - it compiles faster than C/C++ (although runtime isn't as fast apparently) - It's a bit slower to write programs for than python, but that may just be because I'm still learning it. - it's faster to write larger programs for Go than C/C++ - its syntax is as simple as much as possible, one of the things I loved about python. - its commands are few and far between, so again it's as simple as possible, and more python like in there only really being one way to do things. - concurrency...I just love it, coming from python. I wrote a load balanced zonemaster processor (just some TLD related thing), which ran this program in parallel...it was beautiful to watch running, and it was it relatively easy to make. Zonemaster was typically a serial process, and Go allowed me to run it in parallel, with a 10-20x speedup. This one project alone was enough to sell me on Go as my next big thing.
third option is: - they're replacing all of their video streaming components from another language, to go, because go is cloud friendly
Yes, this.
This actually makes more sense. Can't beleive I forgot about assert from jUnit
Miss-keyed quite badly there. Let me re-word it with a little more clarity. We are re-writing the components that we had written in *NodeJS* using Go instead. It is demonstrable to any non-technical business stakeholder that the cost savings are significant, and will save far more money, when we start to scale up, than sticking with the original implementation. We are also able to show that lower processor overheads will cascade as less infrastucture is needed, and so less cooling will be required.
We're not going specifically serverless, but we are using Docker swarm as Go works really nicely in containers.
Thanks! The latest version has a powerful new feature allowing it to obtain all the subdomain names being hosted within ASNs/CIDRs/IPs, etc. Enjoy!
People have an aversion to MS for a reason, but at the root it is typically burned trust. When it catches you out, you'll know get it. If it has caught you out and you're still on that train, you're a very trusting person indeed :) The problem with .NET on anything other than Linux is that every so often it proves to be a second class citizen on anything other than Windows. I tried trusting MS again with .NET core, and not long in evaluation... Boom! Hello Linux the 2nd class citizen. I can't remember the exact issue, but it was along the lines of exbrace/extend, bait/switch or Windows first/only. Once trust is burned it takes quite some time to earn it back. You don't have to look far to find a bunch of examples in recent history. Others can list them if they like.
I don't think net Core will ever eat Go because they're a bit different, net core needs a VM, Go doesn't, you can compile Go into a single binary where net core is like Java with a "bloated" runtime. 
I really love Core and after having had similar time working with both, I agree that both are great, but I vary from you a little on the conclusion. I don't necessarily think Core has better tooling and setup. I tend to favor Go for those features. As far as library support goes, I go either way. I wrote an Active Directory integration once and actually chose Go because once I realized I would need to use some raw LDAP either way for my particular needs, C# didn't add anything extra. Sometimes I need something .Net gives me, but usually it ties into something where I wind up needing Framework, so I don't get any of the nice things from Core anyway. I do prefer C# (or Typescript) for desktop, but for a cli I love Go. Web can be fine either way. Both are a pleasure. In the end, the reason I prefer Go when things are even is that you don't get clever things from a previous developer nobody can figure out in Go. In C# you'll eventually get an application that imports assemblies at runtime, does reflection on them, and puts them together in a way that will take you months to decide. In Go you might find someone spending an extra hundred lines of code somewhere to stick to the standard library, whereas in .Net you're more likely to find that each product has it's own unique homebrew ORM. 😋
.NET Core can build self contained binaries. Future versions of .NET Core will have method level trimming of runtime features from the build output. Kestrel is production ready. It's designed to be used by a reverse proxy. Go should also be used by a reverse proxy. Neither should be public facing.
I would be curious to see what the issue was since the .NET Core team is composed of Linux enthusiasts who operate largely independent of Microsoft. I keep seeing people make vague references to this happening with .NET and .NET Core, but rarely do people provide any concrete details.
How does that compare to afterburn on openFaaS?
I think we are largely of the same opinion, just with different wording. &gt; There's is no language that is really good at more than one thing. I don't want to start a language comparison argument, but for completeness sake C# actually does very well in at least 3 of your categories, maybe 4 if you count Xamarin, and has it's eye on the 5th via WebAssembly. It's an exciting time to be a .NET developer.
Thanks for the perspective. I don't write GTK apps, so I wasn't aware of that. &gt; Go is fine for games (needs a bit more mature libraries... I think we're largely of the same opinion here. Go is _potentially_ fine for games at some point in the _future_, but it is not ready yet.
&gt; Does that count? Pixel looks like it could be a lot of fun with to get your hands dirty and build a hobby project. Based on what I see on their github page, I don't think I could recommend it to a team that's planning on building a commercial game for the purpose of profit.
Didn't but it doesn't really matter. Go has much better support for Linux, and I grew up on Linux and I make a living on Linux. Really no reason to use anything else. Especially something ported from windows.
Isn't LGPL basically the same as GPL for Go since we only have static linking? How can you provide a way for end users to re-link the proprietary portions of your Go app with modified QT libraries? http://www.gnu.org/licenses/gpl-faq.html#LGPLStaticVsDynamic
Can you provide the comment where I made any assertions about performance of either language?
Having a hard time understanding sealed interfaces. Anyone have a better example?
Go to meetups and network there. Also, look into Docker and Kubernetes to make your sysadmin experience relevant. Where do you live?
VS Code on Linux is great. I use it for C# and Go. C# with Visual Studio is definitely the best experience. The amount of tools at your disposal is insane. I've unfortunately become addicted to historical debugging. :P
Yep. It's logical to use a language ported from another OS over one with native support.
I can. Syscall interface and whole interaction with Linux is horrible. Working with libvirt, for example, is impossible under Linux unless you are using mono (and no, it's not even remotely bugs free - I see it everyday just by seeing random freezes in my KeePass). The language itself feels overcomplicated. And that's coming from C++ dev, mind you. The actual performance is subpar - check the techempower benchmarks, especially database related tests. I don't mind Microsoft projects - in fact I use Windows as my home system. And I don't mind Net since they have one of the most powerful GUI toolkits. But if we talk about Linux networking - I would really like to have the first class citizen support. Honestly, you have better chances to convince someone to use Java/Kotlin on Unix environment in this sub. At least they were designed to be cross platform from the start - and JVM ecosystem is second to none (npm module that doesn't do anything useful doesn't count as an ecosystem). P.S. C# crypto is slow everywhere but Windows. This is just sad. 
Wow, I haven't seen that before. Feels pretty cool. As in, I wish the official plugin package worked as well as that.
Go works perfectly without any sort of reverse proxy. In low latency scenarios it's actually preferable, since nginx introduces additional overhead, and there are times when you really don't want to pay for this. Since most of the crypto stuff is implemented using platform dependent assembly, it's also pretty fast. Last time I checked cloudflare infrastructure worked like that. There is also fact that I can just launch Go web app with some sort of the embedded database inside my ODROID box, and it will do ok. I know it's not a big deal, but the fact that I don't have to deploy the usual proxy/app/database/cache stack is very uplifting. I don't want my little home application to be "webscale". I just want it to work. 
It's being fixed: https://research.swtch.com/vgo
I mainly use .NET Core on Linux for cloud services, so I've never dealt with syscalls. I use C++ quite often. Personally, I think C# is an extremely clean and simple language. It's behavior is well defined and predictable. C++ macro hell and template hell makes it one of the most unweildy and complex languages in existence. But I will admit that C# has a bit too much syntax sugar. If I recall correctly, .NET Core 2.0 crypto uses the underlying platform implementation on Linux.
Going to recommend this to my colleague ! He comes from a java background and was doing the exact same thing. You just made my job easy :)
If we talk about web or cloud applications: basically CRUD with semi to very complex business logic - there is no bad choice. Since most of your app logic isn't tied to underlying OS mechanics you can use anything from Node and Elexir to Java EE. It's just a matter of personal taste and project required functionality. I don't think that Go really shines in that area tbh, since most of the business logic is quite repetitive and you want to remove as much boilerplate as you can using language features. This is where having syntax sugar and a rich collections is a good thing. But not every app is a CRUD that do not care about the underlying OS 😉
That's my point, when choosing between Go and .NET Core for cloud services there's no real reason to choose Go since it's missing a lot of features, even though Go is great. Although cloud services can be a lot more than just CRUD and business logic.
Go actually works better (much faster) without a reverse proxy. https://blog.gopheracademy.com/advent-2016/tls-termination-bench/ In fact there are some rather good reverse proxy implementations that are built in go https://github.com/containous/traefik 
Of course it does, but I still wouldn't expose it directly to the public internet.
&gt; Can you confirm whether or not my proposal is "hot functions"? That is what it looks like, [here](https://github.com/fnproject/fdk-go/blob/master/examples/hello/func.go#L13:17). The language-specific fdk provides a handler function signature, and then your function is served as a long-lived http server.
Say you have this package: package numbers type Positive interface { Do() error isPositive() } type Float64 float64 // implement Positive for Float64 type Int int // implement Positive for Int func Add(a, b Positive) error { switch a.(type) { case Float64: return nil case Int: return nil default: return errors.New("FAIL") } } Now you cannot declare and create a `Positive` anywhere outside package `numbers`. Therefore in all the functions in `numbers` you can confidently and exhaustively pattern match on the types.
Specifically, having to specify one at all, which you don't need to do in .NET Core. And needing to keep projects in a specific directory structure is counter productive. I wish they would fix this. Regarding C# features that Go lacks, I could compile a long list. The most glaring is the lack of generics. It makes Go feel like .NET 1.0, including the exact same work arounds and arguments. 
Just curious since you've mentioned needing a "killer feature" a couple of times: do you not find go-routines or the interface system to be unique and compelling? I've found that the trivial concurrency of go-routines have really shaped the way I write software (in fact I feel a little claustrophobic without them) and the ability to design interfaces and implementations of those interfaces has made me a much better producer of modular software.
Well, if you're down to spend a fortune on hardware for IIS and licenses... 
After two years of go I still for my life can't _understand_ the complaints about the GOPATH. It's the greatest relief of all time. Just put your stuff in ~/go and you are done and voilà you have a fantastic way of keeping things organized. I even put all non-go projects in the Path, since it's just such a great idea to have it symmetrically organized with the source repo urls. 
Regarding project structure. It has never been a problem. My source usually lives in a specific folder anyways. Would it be nice if I could choose, sure. But it is not a glaring problem. Once I coded go for a while, I didn't miss generics anymore. And the verbosity of the language makes it easy to read and understands. There is no "clever" code anywhere. I like C#, don't get me wrong. I am just saying, after been coding Go for a while, I don't miss it. Every project I wanted to do, I have done, and a lot faster than I would have done it in C#. 
Swarm was chosen because we need the option to deploy on customer's servers, as many have their own data centres, and others just plain don't trust the cloud. Our DevOps uses both Kubernetes and Docker and suggested that the installation overheads in our case would be rather high using Kube.
I prefer to have my project directory being a valid GOPATH. In the project root I have a directory `src/$project`. Then I can set the GOPATH to my project root and be done with it. Dependencies get vendored in via dep.
I'd also suggest lurking on [the mailing list](https://groups.google.com/forum/#!forum/golang-nuts), on the relevant [SO tag](stackoverflow.com/questions/tagged/go) and may be on [the forum](https://forum.golangbridge.org/). Watch the discussions taking place there, learn from those giving answers. Consider updating your profile on LinkedIn and SO (and whatever) as you progress in your mastery of Go. If your country has dedicated head-hunting sites (here in Russia, we do have them), make sure to prepare a CV with the relevant keywords attached. I mean, HR people actually do active searching for relevant people so you might catch an offer for an interview even by such "passive" means. As to the active stance, Go-related jobs postings happen here as well as on the mailing list.
So your `GOPATH` contains only one entry? Your own projects and dependencies are both in the same directory tree? One reason I dislike that setup is that you can't back up only your own projects easily (which is a major point for `~/projects`).
I agree with you, but the problem is that C# is boring as a language and .NET is boring as a runtime. F# makes this a little bit more fun, but that bit is indeed not very large. So while you're factually correct, there's that thing that *coding should be fun,* and I find coding in Go to be way more fun than coding in C# (which I did plenty).
Just started a Go project, and I agree C# .net core is very attractive. It was the main other language we were considering. But .net core is still new, so yes people will be worried about it (from what I read, msbuild support was just added in august). When I looked at the setup for C# .net core, it looked more complicated with more dependencies. Go is easy (ok so set a gopath variable not a big deal). Installing on linux or windows is easy. Depending on the developers on the team, it is much easier to write very magical and complicated C# than it is to do the same in Go, and Go is easier to pick up for new developers. These are really important business attributes for long term projects that don't need the extra power of C#.
Is there a way to configure custom triggers with Fn, or does it only support http calls as a trigger? Is it possible for instance to run an Fn function upon receiving an AMQP message over a RabbitMQ queue?
Exactly, C# can be used to generate very complicated code using multiple inheritance, extensions, linq and other ways to express functions, loops and conditions, lambda syntax, and tags. These can build in a huge technical mental burden into the code for anyone new to the system. Go is like C#-Lite and that's a good thing (*sometimes).
Go in time will take over node. Even the guy that made node says go is better!
This is a different use-case; the author does explain the usefulness of interfaces for mocking later on too. You're getting the wrong end of the stick though. The author is saying that you don't need to define the interface when you define a concretion all of the time. They go on to say that there are times when it is appropriate, but not always. You may still be thinking something along the lines of "but if I'm writing a library, I still want to have tests for my library code in the library". And of course, that would be right, but you don't always need mocks to accomplish that. For example, say you were making an API client, you could use a mock HTTP server and client in your type and swap that out during testing - no need to mock there. Things that might be trickier to do that with may be things like databases I suppose, but even then, there are ways around having to use mocks even then. Worst comes to worst, define an interface where you use the type still in your own code and then make a mock, that's also fine if you have to, and the author is not advocating against that; only that you don't always need to define interfaces next to their concretions. If you're using a library in a project too, sometimes libraries will provide interfaces and testing utilities. Sometimes that's useful too, but you can also just do that yourself in many cases by doing with the author is explaining and defining interfaces for things where you use them, and then making your own mocks. TL;DR: You don't always need mocks. You can define interfaces and mocks where they're used, not where the single, real concretion is defined in many cases. Many types don't even need interfaces to be used at all.
&gt; but the problem is that C# is boring as a language and .NET is boring as a runtime That's an opinion. You are welcome to it and I won't try to change your mind, but I do not agree. Personally, Go and C# are two of my favorite languages, and I find the two of them "fun" in roughly equal measure.
&gt; Your backup solution should easily (read automatically) back up your projects. If it don't, you should switch backup solution. This is fully unrelated to golang and directory structures. Eh? If you back up your complete `GOPATH`, you back up tons of third party shit instead of backing up just source code you have written yourself.
Change GOPATH to `~/project/go` - a bit anoying that your project is nested deeply inside this path but it follows gos convention and keeps all your projects inside `~/projects`. One extra this I did was use path aliases (in zsh, not sure if bash has an equlivent) to my project space hash -d gop="$GOPATH/src/github.com/mdaffin" then I can cd ~gop to get to get to my go projects path. &gt; One reason I dislike that setup is that you can't back up only your own projects easily (which is a major point for `~/projects`). Your projects are in version control right? This reduces the need to backup your local projects and just worry about backing up the server the upstream version is held (or clone them directly from github to your backup system).
Don't do that? Maybe you can set `GOPATH` to `${HOME}/projects/go` instead. That way everything is under your projects directory.
5) my reaction to a lot of the things on this subreddit. ...
Currently I'm thinking of setting: export GOPATH=~/go:~/projects/go From `go help gopath`: &gt; Go searches each directory listed in GOPATH to find source code, &gt; but new packages are always downloaded into the first directory &gt; in the list. This would allow separating third party dependencies from your own projects, allowing easy backups etc.
&gt; Change GOPATH to `~/project/go` - a bit anoying that your project is nested deeply inside this path but it follows gos convention and keeps all your projects inside `~/projects`. A workaround, albeit a bit ugly, would be to add symlinks like this: ln -s . github.com ln -s . username &gt; One extra this I did was use path aliases (in zsh, not sure if bash has an equlivent) to my project space &gt; &gt; hash -d gop="$GOPATH/src/github.com/mdaffin" &gt; &gt; then I can &gt; &gt; cd ~gop &gt; &gt; to get to get to my go projects path. Bash equivalent would be: gop="$GOPATH/src/github.com/mdaffin" cd gop &gt; &gt; One reason I dislike that setup is that you can't back up only your own projects easily (which is a major point for `~/projects`). &gt; &gt; Your projects are in version control right? This reduces the need to backup your local projects and just worry about backing up the server the upstream version is held (or clone them directly from github to your backup system). Backing up from upstream separately would work, but then you miss stuff like workarea changes that have not yet been committed. I got [an idea](https://www.reddit.com/r/golang/comments/85r63b/how_to_keep_your_own_code_outside_gosrc/dvzk0xm/) that could let me both eat the cake and have it too!
Maybe this is what you want - https://golang.org/pkg/time/#Duration.Nanoseconds ? 
You mean like Docker?
Like [this](https://github.com/filebrowser/filebrowser) and [this](https://github.com/go-gitea/gitea)
Because one wants to manage dependencies and pin down versions per project and in the project repository. Not in some machine/environment specific directory. Every mature language has this (although it also kinda sucks in Python).
What happens if we miss one? Why do you need a list with all of them? Arguably, from an operations point of view, the single binary that contains both application and assets is one of greatest features of Go, in my mind.
Lol, I meant list all you could remember* &gt; is one of greatest features of Go &lt;3
In principle, I agree. In practice, I've found that workareas occasionally contain stuff that is useful to back up.
Roughly where are you from? If you're okay with answering.
Let me thank you for your level-headed replies to this thread. Such are truly rare here on Reddit, and hence pleasure to deal with.
my entire GOPATH after ~6 year of go is 7.9G. this is not insanely much of data. You can also of course blacklist specific folders if you insist, such as $GOPATH/bin (92M), and $GOPATH/pkg (97M)
That's what I am currently doing, but it sometimes displays 0ns elapsed time, which is obviously imposible.
There are a bunch of options: https://github.com/avelino/awesome-go#resource-embedding I've used `go.rice` and `vfsgen`, but take a look and find the one with the API/workflow you prefer.
Yes, it is. But I don't see why a GOPATH is necessary for that. In fact, I want to isolate my projects.
Here's the example from the `exec` package: https://golang.org/pkg/os/exec/#example_Cmd_Start After the command is started, you can access the `Process` field of the `Cmd` and `Kill()` it if you want to terminate it manually.
Also, not very related but can be useful. I was using Sublime before, and by starting to learn Go, I decided to give VSCode a try. With the Go extension (it will prompt you to add it if you open a Go file with VSCode), everything is easier. It will gofmt/goimports and auto imports as soon as you save your file. If you don't use VSCode already, give it a try :) (I'm not familiar with GoLang form JetBrains, but I heard only good things about it)
Also, not very related but can be useful. I was using Sublime before, and by starting to learn Go, I decided to give VSCode a try. With the Go extension (it will prompt you to add it if you open a Go file with VSCode), everything is easier. It will gofmt/goimports and auto imports as soon as you save your file. If you don't use VSCode already, give it a try :) (I'm not familiar with GoLang form JetBrains, but I heard only good things about it)
For now, I wouldn't bother creating something too exotic, just stick with `$GOPATH`. `vgo` solves this problem, allowing you to put your Go projects anywhere you want in your system. Of course, there is the chance that `vgo` won't actually happen, but it's looking likely that it will for the time being.
Yeah, this seems to work for a process that exits after a certian period of time, how about a one which runs indefinitely?
This article is garbage. &gt;&gt;&gt; Golang provides automatic memory management or “garbage collection” which increases application speed. This makes it better suited for developing server-side web applications that need to scale.
I second that!
Damn the ecosystem is pretty neat. I'll probably go with fileb0x. Thank you!
This helped, thanks!
You don’t work around it, it’s how you write code in Go. I know foreign ways to do things tend to make us want to bend them to what we are familiar with, but if you try to do that here your Go experience will be awful. You will find lots of conventions and constraints just like this one in Go, in fact that is ALL you will find. Go is designed to be full of constraints, to limit our freedom to write code how we want. But it’s through these constraints a new type of programmer freedom emerges. The freedom from dozens of different theepie’s writing code how they “prefer” in my organization. Every theepie produces the same mundane Go code, begrudgingly it may be. We use the same linters. We use the same build tools. We are all writing software the same way. The point here is that I really want you to see the value in the fact that while you may have to learn to write software the Go way, you don’t have to learn to write software everyone else’s way. It’s the reason I like Go and hopefully you will to. If you try to write Go your own way, you won’t just be fighting the tool chain but every other Go programmer out their. You’ll be missing out on the best part of Go. As someone else said, don’t do that.
 export CDPATH="$GOPATH/src/github.com/mdaffin" cd someproject
Instead of calling straight to `cmd.Wait()`, do your processing/interaction, then close the process. If you don't want to use kill, you can send whatever signal will shutdown your process gracefully using, eg `cmd.Process.Signal(syscall.SIGTERM)` (only `SIGKILL` and `SIGINT` are supported on all platforms though), then call `cmd.Wait()` to wait for the shutdown.
&gt; it's mostly a comparison of library availability and not fundamental language utility It is, but that's what pays the bills. I can use Go for fun whenever I want, but when I go to work there is not enough budget in any of my projects to recreate the libraries we're talking about, so I'm going to keep using the languages where they already exist. I eagerly await seeing how/where the community fills those holes.
Lol I love this.
https://github.com/grafana/grafana https://github.com/prometheus/prometheus https://github.com/gopherpit/gopherpit https://github.com/geeksteam/BoltGUI
You could symlink in the other direction, which leaves your source in your $GOPATH, but still let's you have a vanity shortcut under /projects/ This approach still uses symlinks, but it doesn't break tooling.
Unfortunately that makes backing up `~/projects` kinda useless (unless you can dereference all symlinks).
[Relevant xkcd](https://xkcd.com/1957/) (the second last one).
The string conversion example was just to get a `duration` type. A `time.Since()` or `t.Sub()` directly gives you the `duration` value. If you are getting 0. Then there is a bug somewhere in your code. If you can isolate your code to an independant reproducible example, please upload it to play.golang.org so that all of us can take a look.
Each project under GOPATH usually has its own repository. That's an individual backup. I'm not sure my approach works still if you also want to do some other kind of backup on projects/ . The only advice I could offer now is to consider what you want to do with this other backup.
Honestly I would just use docker to package the go binary and the other files together in an easily moved and run container. 
[removed]
&gt; https://blog.chewxy.com/page/about/ 404 If I was your colleague I'd say fuck some random opinion on the internet.
Interesting, I've definitely run into the various corner cases here and I'm still looking for the perfect daemon implementation. I didn't realize you could reassign MAINPID to trick systemd into restarting the service but I'm not a fan of turning KillMode off. The Python decoy process doesn't seem to be doing anything you couldn't do with Go. Sure you can't just fork, but you could invoke the main executable with a flag (or a special os.Args[0]) that puts it in the "sleep a bit then die" mode. It would still be awkward but at least it's not dependent on anything external. What about a model where you re-execute the (potentially new) main executable as a child process, set MAINPID to that, and then the parent dies when it finishes processing its requests? It's a common model that systemd doesn't like so much because of the parent process disappearing but if you can explicitly change MAINPID it might work.
reflection always looks like code smell to me 
Pretty cool! What about adding LVM partition map support? (I recently had to recover a HDD that had partitions behind an LVM map)
That's a type assertion not reflection.
Yes, Windows 10 64Bit. That might be the problem. Thanks, I'll search more info about this.
The reason for not having a file like `package.json` is that unix paths are not deterministic and `pwd` &amp; co can "lie". It is a valid concern and strictly speaking, a deal-breaker for multi-platform support. However, in 99% of cases, paths are either deterministic or it doesn't matter if path A or path B is chosen. A tool like godep/dep can make this assumption and get away with it, the Go toolchain less so.
Put a big fat asterisk on that statement. Many essential features are either not available or broken.
The linked tweet was tweeted by [@0xb1ns](https://twitter.com/0xb1ns) on Mar 20, 2018 15:22:07 UTC ------------------------------------------------- Happy to announce the first stab at "saloon", a [@gobuffalo\_io](https://twitter.com/gobuffalo\_io) based \#golang forum (heavily inspired from \#discourse and \#nodeBB): [https://github.com/go-saloon/saloon](https://github.com/go-saloon/saloon) let me know what you think! (and send PRs) ------------------------------------------------- ^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •
Certainly a point. It depends on the details though. packer is pretty small and a go-program itself so embedding it in my go-source might have some merit. I am still evaluating though.
If the goal was separate your own Go project folders from third-party Go packages' folders, without messing your "default" GOPATH, I think you found your answer.
 sudo apt-get install dotnet-sdk-2.1.101 dotnet new console -o myApp cd myApp dotnet run No paths to manage. No special directory structures. Just "dotnet new" anywhere you want. Setting the GOPATH isn't a big deal, until you need multiple GOPATHs or Go projects within other larger projects (which is very common in a large mixed language environment). Go doesn't play well with others. My office is a Go/C# split and managing dev environments is probably the most frequent complaint about Go.
Why would you use a snow flake dependency control that no one ever heard about? Use dep, vgo or none.
True, still defeats the purpose of polimorfism
Avoid `COPY . .` for the same reason. Or at least put `.git` in `.dockerignore` (a good idea anyway). 
Anyone have any recommendations for defining interfaces where a method returns a struct that you want to be an interface? Eg, type Generator interface { Load() Connection } type Connection interface { // ... } In this case, all I can do is define a local `Generator` interface. Not a `Connection` interface - which is the most important. Thoughts on how to avoid java-style interfaces in this example?
because it's good enough for such small example apps :) 
&gt; This reads pretty phobic to me. I feel like any day now people on r/golang might as well start calling other people "brainwashed in generics". This reads pretty phobic to me. I feel like any day now people on r/programmingcirclejerk might as well start calling other people on r/golang "brainwashed in not needing generics". As you can see, we're circling too close to calling names and pointing fingers, so I propose we stop now :-)
Fair enough. It does not make for a nice development experience, but we'll get there ;). 
Actually, I usually have exactly one directory within the src directory. The other dependencies get directly added with the `dep ensure -add` command and are therefore added to `src/$project/vendor/...`. If you want to add the vendor directory to version control depends on your preferences ... I personally prefer to do so to have really reproducible builds (even 10 years down the line).
Tool fragmentation for no good reason is bad. "Good enough" is not a good reason. At the current state of affairs you should use dep unless you have an actual good reason not to. 
github.com/kevinburke/go-html-boilerplate
Too bad go is missing covariant type matching for interfaces. This prevents you from always returning a concrete type and forces you to forward declare interfaces from time to time. Like [this](https://play.golang.org/p/Kvet0JvpWag) 
[removed]
Yes! This is what I just posted about here. It's killing me. I'd love to avoid defining interfaces in root packages, but I often have this exact issue. Anything that returns an advanced data type frankly has an issue where you *need* centralized structures and interfaces. It sucks.
@campy was eagerly waiting for this. Thanks :)
Don't you mean "fork two times"?
thanks for advice, makes sense 
I had some issues uploading overnight, but it's finally out! Enjoy :)
&gt; What happens often is the need for very specialized collections How is a concurrent map a very specialized collection? Even the standard acknowledges that it's a generic data structure, but since the language doesn't support it, it takes interface{}, making you lose all type safety.
https://github.com/sosedoff/pgweb
https://github.com/shurcooL/home https://dmitri.shuralyov.com/website/...
An architect buddy joked that C# is what Java should have been, Kotlin is what C# should have been, Go is what all of them should have been if you cut out the bureaucracy..... haha
I use https://github.com/cznic/assets. The result is compatible with https://github.com/cznic/httpfs.
On top of the ones I've seen posted here, I remember this one: https://github.com/peachdocs/peach
What is [going on in http/server anyway](https://golang.org/src/net/http/server.go#L1981)? r2 := new(Request) *r2 = *r I thought this would create a new variable (`r2`) that points at the same address as `r`. I must be mistaken, because having two names for the address of `r` doesn't seem to achieve anything.
I really wish more middlewares would focus on 1) input validation and 2) templates in addition to speed and context. Gongular is onto something, but missing templates or any kind of middleware chain context.
No, this copies content of r into r2. The pointers are dereferenced as you can see. 
404’d!!!!!!
Explicitly talked about here if you're interested: https://medium.com/@cep21/preemptive-interface-anti-pattern-in-go-54c18ac0668a
Right now I live in San Antonio, TX. 
Isn't "persistent file storage" what makes a filesystem in the first place?
You're probably at the limit of time resolution. Are you sure you really need to measure that part anyway, if it's clearly so fast?
Ah, I forgot about the array literals... don't think I've ever used them that way.
Exactly - use dep or vgo. Both "from the mothership" 
That part is going in an industrial process, it's supposed to execute a thousand times per second (absolute max is 1ms, if it goes slower it will lose data). We are currently at 0.993-1.013 ms, so.....not fast enough. I'm trying to measure it to try to optimize it more. If I didn't need performance I'd probably go Python, just import any random library and it does everything for you, it'll probably take 100ms, but who cares? Well, not the case this time, I need it to be fast haha.
Depends on what you mean by polymorphism. In its most elementary, polymorphism simply means something (a function, an object, a type) can take multiple different things. There isn't any constraint in what those things can do with its input(s). Dispatch based on type is actually a valid usecase for type switching. 
I have implemented your first suggestion here: https://vincent.bernat.im/en/blog/2018-systemd-golang-socket-activation#addendum-decoy-process-using-go
You seem to be applying the term "cloud services" rather selectively. I have a set of cloud services. Most of them are low latency/real-time - they have to deal with microsecond deadlines. Last time tried anything .NET related, there was jitter in tens of milliseconds. I wouldn't allow .NET within 10 miles of that cloud. 
lol no generics 
Aah, across the pond from me then, nevermind!
Feedback hugely welcome as per! This one was a real struggle to write! 
I've seen some other FaaS solutions advertise "event source" triggering. Recently I was reading about [Gloo](https://gloo.solo.io/) as a way to possibly not have to choose a FaaS solution based on having all of these extra features, and defer to Gloo as the API gateway. The docs for Gloo says its supports "Event Source" matching such as nats.io or amqp. But I am not clear if that means it can publish a message when the http endpoint is triggered, or that it can watch a mesage queue for events and trigger your function.
Nothing off hand. This was around 2 years ago I'm guessing. These vague references to issues are there because people encounter them. I generally don't keep Github a collection of issues in my "I hate .NET Core" bookmarks folder to pull out as absolute proof of issues I encountered in some random Reddit chat in the future. The .NET Core team may be Linux enthusiasts but their employer of course has a very deep interest in another OS.
Thanks, but the link works for me. What browser you are using?
It's so annoying that I'm intimately familiar with this particular topic, means I have to wait for the next episode for learning new stuff. Of course, great work as always, keep it up!
Quick questions! Can you do graphical applications with .NET Core on Linux/MacOS/Windows? What languages can use .NET Core? (C#, but can it be used with VB?) I'm looking for a platform to build cross-platform (desktop) visual applications for my job, with preferably high performance because we're going to drop Qt/C++
I'm open to relocation, though I know that would be a big investment for any company considering that. :)
This looks like a phenomenal resource, thanks a ton. 
The latest version can obtain all the subdomain names of everything being hosted within ASNs/CIDRs/IPs. Enjoy!
I thought you'd stopped making these, thanks for doing more, instant classics
If I'm working on a large project and I import `my/pkg/v1/foo` all over, won't importing `my/pkg/v2/foo` in one place (as part of incremental upgrade) spell disaster with types? Expected *Bar not *Bar kind of errors.
Well… This is it! You found a solution to all my problems!
I prefer having a private git repo on my local network than taking directory backups of my code. Bit you are right, my own projects are hosted on a corporate git host.
This seems like a very useful package. Could one be able to call Linux command line tools similarly to Python with that?
!redditsilver
I also often forget, but Reddit has a save function :o
This is an example of a pattern that arises semi-frequently. Let's say I have a filesystem object which can access file objects and file info. Obviously files and file info objects should be interfaces. Right now the only way to do that in go is to pre-declare that set of interfaces. This means that of you had multiple instances of this, say the os's filesystem, a zip file, a webfs and a in memory mock. The only way for them to be interchangeable is for them all to implement the same forward declared interface. That means all of these independant objects are all depending on a common package.
I haven't read this latest iteration of the proposal, but from his blogs about it a few weeks ago it sounded like the idea was to have packages that import different versions of other packages be isolated in different modules, which would be compiled and linked separately.
Exactly what go generate is for
Thanks for the interest. Ya, we agree. Hype cycle for sure with resulting expansion and contraction. We'll see a consolidation. We're betting pretty heavily on Fn and have corporate backing and partnerships in the works so that we can run the marathon to become a successful project.
Thanks for sharing that. Initially I thought I shouldn't rely too much on 3rd party libraries when using Go. I played with go-sqlmock the other day for a bit and found out it doesn't really cover all the use cases that I had. However, sqlx looks very promising and it looks like something that I can get a lot of benefits from.
The newer package could type alias the previous package's types where possible
Agreed; in the cases where you need a thread-safe container, this is what you are stuck with. The reasoning of the core Go devs is that this is a rare case and not worth a major language/runtime change. Note that even in the sync.Map docs they tell you that what you want is a normal map and a lock/mutex most of the time, except when you have one of the special cases for which sync.Map has been specifically optimized. I'm not sure if that's the "right" answer (I am fond of .NET style generics, personally), but it is at least reasonable and well-thought out.
Isn't `my/pkg/` the repo and `v1` the tag? Would major version upgrade from a package maintainer point of view go something like: 1. Replacing all definitions(at least exported ones) with type aliases 2. Make breaking changes. 3. Release new version. That doesn't sound very convenient. (Major version changes must not be, but probably not this difficult either)
So the flow goes: 1. user plugs USB into computer 2. user uses rest api to authenticate 3. on successful authentication decrypt drive + mount it to /static/path 4. be able to do this with system independence I have a few questions about this. 1. Why do you need full disk encryption? 1.5 If your entire drive is encrypted, where is the REST API going to be run locally? -will it need to be installed first? a separate partition? are you wanting to run (what i consider risky) commands over a network connection? 2. what do you mean by "programmatic" if you don't want to use command line parameters? my current thoughts ( may change depending on your reply) 1. have a USB with binaries for all supported OS types + encrypted directory 2. use said binary to authenticate to main server 3.main server returns decryption key &amp; said binary handles unlocking IMHO remotely encrypting and decrypting is more trouble than its worth if you can avoid it + opens you up to a whole new set of security issues. Can you trust the network admin? can you trust the network? your files become as secure as your network connection. Is there a reason for wanting auto-mounting of devices apart from having a fixed path? what happens if that path is not available? I have seen decades decades of work wiped out because a new backup drive got auto-mounted before a full drive.
One reason to avoid docker in this case is that, if you are using the binary to update an existing host, that might need access to local resources. The container could keep all the tools, but running the container would need access to many different file paths, inherit the uid/gid and may have to connect to local processes using network protocols. Obviously this is all possible, but it is pretty painful from an API standpoint when the goal is to be able to `mydevoptool update iptables` or something else that becomes trivial when access is directly available. That said, it is good to consider the option because if you don't require access to system resources that would need to be mapped when calling the container, the container path might be much easier. 
&gt; The general implementation is to go about storing the data in memory along with the fs (as a field in one of the structs) when mounted, and lose the metadata and the data on unmounting. No it's not. The general implementation is to write a filesystem diver, except in userspace. That's why it's called "filesystem in userspace". A memory-backed FUSE fs isn't someting you would do except as a toy, because it doesn't serve any real purpose.
The real flow is closer to: 1. USB disk is attached to the server, but not powered (literal power to the disk is controlled). 2. User sets server in a location that is accessible over the network, all closed net, trusted link etc. 3. User does some random things with the remainder of the server (the server being the hardware and the service provided by the REST API and Web GUI. This results in disk one being populated with some files. 4. Files need to come off of disk one and be copied to disk two so that disk one is free to go back to work. 5. Disk two (external media) needs to be encrypted to handle data at rest cases and loss prevention. Disk one is already hardware encrypted. Which would be the ideal solution for disk two's encryption, but currently not feasible. 6. User retrieves server, powers down etc. 7. User plugs disk two into a windows box of some kind to decrypt the files. Yes, the user would be prompted for a password to authenticate and unlock disk two. I would accept this over the Web UI or the REST API in some form of course and pass it on to an OS call for the encryption program. So the number one problem I see with veracrypt is that the command line options seem like a second-class citizen on the Linux version. Not very well documented. Very unusual. The command line version hangs a lot, and the most all tutorials you read on veracrypt for Linux make reference only to the GUI, unfortunately. Auto-mounting is a nice to have, but definitely, something I can just handle with a bit of Golang, and yes static paths are preferred as I understand the same problem you're speaking of. When I speak of automounting I would be relying on udev rules to create and remove the directory as needed, but udev would still be pointed at a fixed path. Udev creates the path when the kernel sees disk two and then deletes it when the kernel sees disk two removed etc. Originally I was hoping for an approach that would allow me to let udev handle the work of passing in the decryption options as well by picking up some short-lived environment variables or something, but the approach I worked through with veracrypt and udev didn't flush out so well. Veracrypt wants to handle all of the disk unmounting effectively making udev useless for this scenario. I may have caused more questions on your end. :-) 
I see. Thank you for explaining it to me. I’ll keep it in mind next time I work with FUSE :)
Gophercises.com is deployed as a single binary. Happy to elaborate a bit if it helps (email me - jon@calhoun.io) but it's sleep time now. Hugo also comes to mind. Super cool project.
Yes. That's probably what you want, though. The major version shouldn't change unless something is incompatible. And if there are incompatibilities, then you want compiler errors if you accidentally use the wrong one. Yeah it's annoying, but breaking changes in a statically typed language are annoying. IMO this proposal deals with it in the best possible way (at least, the best that has been discovered so far).
This is great. I like that they mentioned the other tools they looked at and what they learned from them. I hope the work on kubernetes goes well.
the database driver is exactly my point ;) how would one handle thta? and please don't expect the drivers to register themselves with different names per release... that would be annoying