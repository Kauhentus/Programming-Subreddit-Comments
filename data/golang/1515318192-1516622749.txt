There's a fine line between writing html+js in django/rails/php, and just writing it without the server-side component. It takes a mental shift to go from that to go+vue, but at least in my case it's well worth it. In the end, it doesn't really matter if you're doing server side or client side rendering, because that's a technological choice that your users won't care about, or even know the difference. It's a brave new world, if you open your mind to it ;)
&gt; Cloudflare: one of our engineers refuses to learn new things FTFY
I think blog posts are a bit different from quick hacks doing on the side. When presenting your work, one could take extra minute to have the code snippets be a correct code. Especially when some novice programmer stumbles upon such code and decides to either use it without second thought or adopt the clumsy style. func GetChannels() []*image.Gray { data, _ := os.Open(fileName) img, _ := png.Decode(data) rgba := img.(*image.RGBA) And in the end you need to maintain this shit.
Neat I just used postman today and didn’t really like it in terms of UI/UX this one seems like more my taste. 
The Go hate in the programming subreddit [is real](https://www.reddit.com/r/programming/comments/7ok5ty/cloudflare_golang_sucks/).
Yeah!
c-shared on windows looks nice
You should also try Insomnia. Great looking, though it lacks some features. 
Heh, I'm not moving on from Go, but I think it's good to be educated vs. ignorant about some of these examples. It's not like -- insert language here -- doesn't have hacks or workarounds or weird behaviour that would be unexpected :)
File reading in Go is synchronous, so the proper word here is parallelism. Nearly optimal for actual usage algorithm is something like: 1. We have 8 core CPU, has 8 goroutines and thus will try to read in 8 threads in parallel. 1. We have a file and can find its length. 2. We can split a file (logically) into 8 equal pieces (±1 byte) 3. But the split should not split words, so actual piece should start after separator which should be found before. https://imgur.com/a/4QIxn 1. First thread (goroutine) just starts over its chunk. 2. Other threads (goroutines) look for the first separator, save its position somewhere for the "previous" thread (goroutine) and start scanning over. 3. The last thread (goroutine) just exits when reached the end of its chunk 4. Other goroutines checks where the next goroutine started its chunk and read until it. This will require a custom complex reader with shared context to store bounds. The other approach may be introduction of two steps: 1. Find chunk bounds 2. Run threads (goroutines) on these chunks In this case you will be OK with [LimitedReader](https://golang.org/pkg/io/#LimitedReader) and [Seek](https://golang.org/pkg/os/#File.Seek) PS I have yet to see a real need for such an approach. The parallelization is usually done at the process level, where independent processes reads their own files.
What a terrible community.
Glancing at your code you made an interesting design choice of storing keys by insertion order (correct me if I am wrong). Since you do not store sorted keys you can't provide an API to fetch keys within ranges. This rules out a lot of common use cases like pagination, grouping keys by prefix and so on. You also don't call fsync each insertion by default like most real production databases (bolt for example). What use cases was it written in mind for? Session stores (with a per-insertion fsycn policy) / caching seems like a couple potential areas. That said it doesn't seem entirely fair to benchmark fetching each individual key from your hash-table store to a set of 3 sorted key-value stores. It's like comparing sort.Search to v := map[key], no contest here. You should also include iterating over ALL keys and performing an aggregate operation like a sum of values, it would provide relative cost of full database scans on a bit more (but not entirely) equal footing.
Thanks for your feedback, the keys are stored in an unspecified order. Pogred is basically an on-disk hash table - it was designed for systems with infrequent bulk inserts and frequent random lookups. Let's say you have a huge numbers of keys like "user_id:keyword", you want to access them as fast as possible, but at the same time you don't want to keep them in memory - pogreb would be a good fit for this use case. &gt; That said it doesn't seem entirely fair to benchmark fetching each individual key from your hash-table store to a set of 3 sorted key-value stores I couldn't find any on-disk hash tables for Go (that was one of the reasons I decided to create pogreb), but I should probably mention in README that pogreb was specifically designed for fast random lookups.
in Croatian language "pogreb" means "funeral"... just saying...
Funny, in Russian it means "cellar".
Very interesting! I'd love to see a write benchmark
Did you look at https://github.com/coreos/bbolt for an on disk key value store? That or the parent of this fork, https://github.com/boltdb/bolt is what I usually see used for this sort of thing. I like some extra query and ease of use on top, so I use a wrapper: https://github.com/asdine/storm
Gob is really only useful as a streaming codec. And, in that context, you would create an encoder/decoder for each stream. So in your example, the 3 programs would each maintain a socket connection and a encoder/decoder pair per connection. Using it as an encoding for HTTP style stuff, and reusing the encoder/decoder is super-dangerous when it comes to stuff like live upgrades where it's possible that 2 different apps have different definitions of the same type. for example: v1 of your code has struct { A int } v2 has struct { A int, B string } if you used the same decoder for talking to those two programs, you wouldn't know how to parse that struct. but, if you apps connect via a persistent socket, you can easily just create a codec per connection, then there's zero chance that the type changes mid-stream since the corresponding process would have to be restarted, causing the socket to drop and you to re-establish the connect (thereby re-creating the codec) 
The write performance is not bad: Keys,pogreb,goleveldb,bolt,badgerdb 10K,63594,90536,18039,28598 100K,58913,78027,16721,24461 1M,52121,36040,11897,24746 10M,47749,23237,10325,23585 but keep in mind that I disabled automatic fsync for every store I benchmarked.
I looked at the original bolt package and pogred is about 5x faster for random lookups https://akrylysov.github.io/pogreb/read-bench.png.
Thank you for posting this. I was considering doing something like this myself, I'm glad you did it first! Would it be difficult to integrate support for org-mode syntax? 
The benchmark is nice, but you need more than just one (everyone can usually win if you tweak the variables enough). Specifically I'd be interested in: 1. Concurrent reads: How many goroutines are doing reads in each case ... and/or how many processes. 2. Concurrent writes: As you benchmark reads how many writes are happening (in G/P) ... it's fine if you are really bad here, it tells people when they can't just use your code. 3. Data sizes: Are you reading with len(key) &lt; 10 (&lt; 20). Are you reading values that are len(data) &gt; 100 (&gt; 1k, or even &gt; 1M).
No. Assuming what in b() is: c() // takes 1s do something directly // takes 3s d() // takes 2s then cum of b() would be 6s, and flat of b() would be 3s (assuming that the "do something directly" part does not have function calls).
Thank you for correcting my fault! I get it now!
Looks good. What use case is this for?
I'm going to take a look at this too, but just thought I'd drive-by comment and ask if you've seen ikiwiki yet. 
The post title is verbatim from the slides title. Apologies if it sounds overly provocative, but I didn't want to editorialize. This originally appeared in r/programming. I'm curious to hear what is r/golang's opinion of it. Original presentation [here](https://www.youtube.com/watch?v=_Id9bFkjaDc), but it is in Polish, so I don't know what the presenter was originally saying.
This isn't concurrency-safe: go func(word chan string, done chan bool) { for scanner.Scan() { word &lt;- scanner.Text() } done &lt;- true }(word, done)
Can we please stop with this already? We know, that person can't be bothered to read the language specs or understand that Go is a different language, not just yet another language with a different syntax that copies every other existing language. It really gets tiresome after a while. Go learn / use another language instead, or even better, write one that's mildly useful and see how that works out. Meanwhile gophers are busy building things that work.
I think it has less to do with the content and more to do with this being posted less than a day ago. https://www.reddit.com/r/golang/comments/7ol5r8
Hey! Nice work. I made a similar library a while ago but I seem to forgot to announce it anywhere :-) I'm thinking if you want, I can add some PR to merge the few fetaures differing from my code into yours, and deprecate my repo. I don't feel any point in having two competing libraries for such narrow functionality. Stuff I can add in PR: - windows 10 proper notifications using toast. - Alert() function, like a notify but uses system alert sound too. You can find the lib at https://github.com/martinlindhe/notify, a demo application using it at https://github.com/martinlindhe/timer I also opened an issue about this over at https://github.com/gen2brain/beeep/issues/2
it pretty much is a way to take notes
I actually had to do something somewhat similar for Java, essentially: * parse an SQL-like language into an expression tree * build and compose predicate objects from the expression tree recursively (or alternatively, generate code that evaluates the predicates) * map column names to values of row objects, apply predicates to the mapped row data If you [Google for sql parsers](https://www.google.com/search?q=golang+sql+parser&amp;oq=golang+sql+parser&amp;aqs=chrome.0.0l4j69i64.1647j0j7&amp;sourceid=chrome&amp;ie=UTF-8) in Go there looks like the first parse might already be done for you. That all being said, it's still probably quite challenging for someone new to Go, and more importantly, what leads you to believe that Go performing the filtering would be faster than Oracle doing so? Databases are usually impressively fast at filtering data (especially when indexed correctly). I would think that if it takes hours to process, the solution isn't just to rewrite it in Go, it would be to investigate where the bottlenecks are and solve those, that's hopefully what the DBA would be doing. Switching languages can sometimes lead to performance boosts, but good systems design is more important when talking about scalability.
Probably because it had a mixed reaction then as well since context was lacking.
Can you share a small example repo?
This is possible, but if you haven't written a compiler before it might be difficult. Also it's dubious whether it will be faster. In general, IO bound tasks like this almost always run faster inside the database rather than streaming out of the DB, processing somewhere else, and streaming back in. Also, introducing more columns to mark the partitions is going to make your tables even bigger. I also find SQL very productive and find that performing significant logic outside of the database to not be any easier. 1. You have to know SQL anyway to query the DB. 2. It's a pain to have performant and reusable code. E.g. if you represent a row with a struct, your functions might assume you selected every field from the DB, so you tend to have to `SELECT *` instead of just using the columns you need. Similarly, if you need to join tables, it can be difficult to make sure your query and go functions agree on what joins are made. 3. It's the same logic, but now in 2 languages instead of 1 with all the verbosity needed to glue them together. 4. The optimizers of each language don't know about the other language. I would take a look at optimizing your SQL. It sounds like `INSERT ALL` (i.e. multi table inserts) would be very useful for this if you aren't already doing it by letting you scan your main table only 1 time. Are you doing joins? How many GB is your database? Is your database otherwise very loaded or using underpowered hardware? Unless you are doing something really strange or your DB is TBs, i don't see why it would take so long. If you don't know why it's this slow, then you don't know if rewriting it in go can make it faster, and it's almost definitely going to make it slower. Now if you are really set on doing this this is an outline of how i would do it. 1. Parse SQL into AST. (I think there are go libraries for this) 2. Analyze types of columns and expressions. You will need the table schema. 3. Translate SQL AST to go AST. 1. Most AST nodes have simple translations like the one you have shown. Once you know the types, you can probably do this in 1 pass as a depth first traversal. 2. Remember gotchas of SQL logic like comparisons to NULL. 3. It's easiest if you make the whole WHERE clause a single function that takes all the columns it needs as arguments (this list is different than the SELECT clause and you will have to fetch the union of the columns to cover both). 4. Generate go code from go AST.
I just added a link to a gist of the code. It's not all of it, but has the important parts. I have tried setting the environment variables from init, and TestMain as well, neither did the trick.
So let me get this straight: 1. The user logs in, Firebase returns a JWT 2. This JWT is stored in localStorage(or the equivalent, now that it's a mobile app) 3. Upon calling the microservice endpoint, the user passes on the JWT from localStorage when doing the call 4. This is where I'm in doubt. What does the microservice do in this case? It receives the JWT, how does it know whether or not to return a http 200 + data, or a http 403 forbidden? Not sure how to handle this case? Sorry if i'm repeating myself. It's an interesting subject :) 
Looks good! Good idea to use Git for versioning instead of making your own database focused versioning system. I do think that using page names for REST request isn't a smart idea though, such as POST api/wiki/:page-name - I would have used IDs instead. Just makes it feel safer. You can still use the human readable pagenames in the URL and elsewhere, and you should, but page names being the identifier makes me feel a bit cautious.
For #4, your microservice needs to validate the signature that was used to sign the JWT (you can't just trust it since it came from the front end, by validating the signature, you can feel comfortable that it was in fact generated by your login api) . You will have to use some sort of secrets management to pass the key to your service on the backend.
It's just a single guy in a team that can't be bothered. And if you did based your decision not by evaluating the language and pros/cons yourself but relying on others's success then you deserve it. Cloudflare uses Lua, will you switch to that now? 
I was thinking something along those lines.. So I need the Firebase JWT to create some sort of secret key that I then validate on the microservice? How would that be done in practice? 
&gt; The author deleted this Medium story
&gt; We know, that person can't be bothered to read the language specs Judging by those slides, I think he has a pretty good grasp of the specs. He isn't saying *"I don't understand why it behaves that way"*, he is saying *"It behaves this way and I think it's wrong/questionable/weird"* which is a very fair opinion. &gt; It really gets tiresome after a while. Personally, I find it very tiresome that whenever there is an article that paints Go as anything less than perfect we get dozens of people from the peanut gallery taking it as a personal insult who somehow feel obligated to defend Go's honor. It feels trite and childish. Go isn't perfect. Gophers aren't perfect. The author of that talk isn't perfect. All he did is share some stuff about that he personally found not-great as a Cloudflare engineer. The fact that it gets downvoted so heavily speaks volumes about the maturity of this sub and only reinforces this place's reputation among the wider Go community.
Yeah not really ready for team use ATM. Just built it for my personal note taking like FluffyRabbit said. Open to PRs/may add auth/team support in near future. 
My thought was that the page name is going to be globally unique since you can't have two of the same file in the file system. I.e. my-folder/file.txt is different than other-folder/file.txt. But I do see your point! Just simplified the rendering process a bit 
1. do undefined shit in lang A 2. repeat in lang B, obtain different results 3. conclude that lang B is horrible ok
Sure, don't see why not. Just have to adjust the remote/branch to what you want to track in the config file.
&gt; Just makes it feel safer. Curious about this, could you provide any more info? If I were to design this I'd be following the RESTful philosophy as the author did too.
The JWT is signed with a key. Your microservice needs that same key in order to verify the payload has not been changed. https://godoc.org/github.com/dgrijalva/jwt-go#Parser.Parse
It's alright as long as the content is in latin1 as far as page names go. But what if the user is Russian and uses cyrillic characters? Or Chinese? They probably will have their locale set to something that accepts these characters, but maybe not. What if they check the repo out to a computer that doesn't match the charset? Things will probably work fine most of the time, maybe even every time, but I just foresee this possibly being a problem in the future. Numeric IDs will always work. If you do end up using strings as identifiers, you need to make sure that they are valid and strip all the characters that might be problematic. If the group is a directory and title is the filename (as OP's reply to my original comment suggests) then at the bare minimum you need to escape trying to access places outside the intended place. I mean, what if the title is "../../../etc/passwd" ? (Yeah, that is extremely unlikely to work, but it is to hilight the idea) Also, I realise this is intended as a personal blog and not some kind of multiuse CMS thing. So some people would probably say that I am being way over the top with this issue. But I can't help it, I see strings as identifiers and immediately my experience tells me that this might not be the best way to do it. There just could be a few cases that I can't even fathom right now where things might get broken.
You call it inconsistent even though some of the features presented here are *undefined behaviour* in C, and thus inconsistent behaviour...
WHERE statements rely on indices to reduce the number of rows that need to be considered. Unfamilar with Oracle, but getting direct access to index data out to use in Golang is no go in most other RDBMS.
interesting projects: * https://github.com/microo8/plgo * https://github.com/prest/bgworker 
if your're using plain text names - it would be recommended to slugify the names which would resolve all of them. I like your last example though.
OTOH, there's a pedagogical opportunity, here.
Yes, you could put in the Authorization header prefixed with Bearer (eg `Authorization: Bearer TOKEN`), a custom header, or as a URL query parameter.
I'm really surprised that more people don't have your attitude towards this sort of thing. I thought this set of slides was pretty great, but I don't know, I get the feeling a lot of people haven't actually even looked at them properly.
Excellent, thank you so much. Gonna start cracking away at this :)
Great! I will check them out at work today! Thank you so much for your assistance
This one seems simpler and more popular: https://godoc.org/golang.org/x/sync/errgroup Also since it is "x" package under golang.org hopefully it will make into stdlib some day.
Well, the problem with the slides is that the author, if he is a developer at all, is totally incompetent. For example, since when is the “net” package blocking? It never was. Also there’s no such thing as “casting to interface”, a struct conforms to an interface or not, no casting involved. The slides are laced with nonsense. I really like to read critical comments from competent developers but this one’s awful.
I think people who read a clearly tongue in cheek title and rush to defend a language's honor should get a sense of humour, but I guess your solution might work as well.
oh so that was what i was missing
&gt; but how come compiler doesnt complain that the HandlerFunc is not a http.Handler because it doesnt have a ServeHttp method so it doesn't inherit the http.Handler interface Type [`http.HandlerFunc`](https://golang.org/pkg/net/http/#HandlerFunc) has a [`ServeHTTP`](https://golang.org/pkg/net/http/#HandlerFunc.ServeHTTP) method. Also don't forget that interfaces in Go are satisfied implicitly. There's no "inheritance" involved.
yes i figured that right now 
&gt; the author, if he is a developer at all, is totally incompetent Yeah [I'm sure he is](https://blog.cloudflare.com/author/marek-majkowski/), definitely-competent random anonymous redditor. &gt; For example, since when is the “net” package blocking? It never was. If you, unlike the author, think there is a way to emulate non-blocking [connect](http://man7.org/linux/man-pages/man2/connect.2.html) do share the code so we can all learn from your wisdom. &gt; Also there’s no such thing as “casting to interface”, a struct conforms to an interface or not, no casting involved. This talk was intended to cover an audience not necessarily familiar with Go. Casting is a term most programmers are familiar with and you and I both know what that sentence meant. So you are just objecting for the sake of it. 
Hot damn, where were you on Friday when I was cobbling together a crappy version of this? ;)
Or https://godoc.org/github.com/oklog/run
This is fantastic news!! :) I hope someone can do this with NPM now, haha.
tl;dr Random "ab" run to Prom**e**theus says ~5% perf. impact.
I think it's just a form of tunnel vision because of the clickbait title. Some people react with too much emotion and then don't read anything else because they expect it to clash with their experience/sensibilities and then lash out. tl;dr did you mean: young junior programmers?
Impressive. I could think of using this in build tools or custom deployment software. In which other ways could this be used?
Library I wrote that mimics Python's advanced string formatting in Golang. I found that the most interesting part of this was actually testing how closely it matches Python's formatter. To do that, it goes through a cgo wrapper and cffi, then uses the Python Hypothesis[1] library to generate random examples. [1]: https://hypothesis.readthedocs.io/en/latest/
If I had infinite time, I would make a git history viewer that doesn't suck.
Hey, what I have done is created a constraint in the .toml file and set the repo source with a github token. For example `https://&lt;token&gt;@github.com/owner/repo.git` That way dep will be able to download the repo. I haven't experimented with using a ssh key though.
Weird. The blog post I think was talking about https://github.com/murphy214/vt_index IIRC.
I've had so many ideas for this library which I haven't been able to make time for, but one of the things I want to do is use it in an automatic update tool.
That makes sense, but that's essentially the optimization INSERT ALL does.
As a user, I think I'd rather have no prediction than one not based on fact. In fact, I prefer progress bars that show amount done vs total amount instead of time, but with a time estimate below it that I'm free to ignore (e.g. if I choose to download something else, which limits bandwidth available to the first program). However I can see utility in load balancing scenarios where nodes can predict when they'll be ready for more data.
Git-based CMS is another obvious usecase. 
in your .gitconfig use the "insteadof" directive and always use ssh # Enforce SSH [url "ssh://git@github.com/"] insteadOf = https://github.com/ [url "ssh://git@gitlab.com/"] insteadOf = https://gitlab.com/ [url "ssh://git@bitbucket.org/"] insteadOf = https://bitbucket.org/ ref: https://stackoverflow.com/questions/11200237/how-do-i-get-git-to-default-to-ssh-and-not-https-for-new-repositories
What would be the reason against just setting a specific unmarshaller for this?
I would recommend to use alphanumeric IDs buuut allowing an option slug, just like how reddit does it. Take this OP for example: &gt; /r/golang/comments/7oryxt/modern_git_based_personal_wiki_written_in_goreact/ Only working against simple IDs make it simple and kinda safer to code, while end users can navigate their browsing history using the slugs. Easy peasy for everyone.
(1) Yes (2) Yes (3) Yes. The standard says that it is passed in a header like `Authorization: Bearer ${token}`. (4) Your service should get the token then do a few things: - Ensure that it is signed with the signing signature you expect (HMAC-SHA-256 aka HS256 is the usual option) - Ensure that the signature it is signed with is valid (this is the step that makes it "secure") - Other verification based on optional fields in the payload (ex: look at `exp` to determine if its expired, look at `iss` to determine the token was issued by you, look at `nbf` to determine if the token is allowed to be used yet, etc) - Use the data in `sub` (subject) to determine who holds the token, and write business logic to ensure that they have access to whatever API they are trying to access. Most libraries will do the first 3 points for you.
Right, so I'm at the point where I've passed the token in the request header properly. And I have a .json with the validation key from Google. Just not sure how to properly validate them. The documentation on firebase consists of incomplete examples..
You can post Hacker news job posting.
gogs/gitea with custom ssh port: [url "ssh://git@git.domain.com:10022/"] insteadOf = https://git.domain.com/
Lots of really useful factoids and quirks about the Go runtime/syntax/stdlib. Would have enjoyed some constructive suggestions for how to improve the language along the way—maybe talk about some actual proposals submitted? I actually enjoyed it, but I agree that the title is too troll-y. Too bad.
Conceptually, floats are bad keys. Conflicting standards, instability or unpredictability in rounding/truncating AND in precision, and more could lead to issues where keys aren't consistent before/after unmarshalling even on the same computer. Sending them over the wire to another server with potentially unknown float behavior introduces more uncertainty. I'm also arguing that a map is not the ideal top level data structure for the overall data over the wire and especially not in JSON, regardless of the keys used. This is a timeseries. A series, or a sequence. A list. A list of entities ordered by the time of their appearance. The goroutines can extract all desired entities and dump all of them into an intermediate storage location. Off the top of my head, I'm imagining that a map would "work", but a more complex datastore might be ideal for representing, say, a *specific* entity that appears at multiple timestamps. Maybe the goroutines don't identify "a brown dog named rex" and only see "a dog" in which case you could just build something like this: https://gist.github.com/nickdumas/84c25df8aed27dcd8e0456f64eaf456e From there, you should be able to massage the VideoElements type into an array/slice type and dump that into JSON and send it over the wire.
'golang prefers use of global namespace which is wrong'
This what I have but for some reason the git CLI is stuck during git ls-remote / git-upload-pack ... :/
A Croatian and a Russian met for a funeral in a cellar...
Curious: so there is no equivalent of rust's `#[inline(always)]`?
The title is the least problem. What experienced programmers who know Go well don't like about the article is that it's full of nonsense. I bet most Go developers like constructive critique as it triggers interesting discussion but there's no point discussing misunderstandings (at best) or outright lies (at worst). The author gave a very bad presentation and while he's not a troll, now the trolls here started parroting the nonsense ("-1/2=0 ... but I work with floats ... Go sucks ... beeeh"). All told, Go has some rough edges and misses some stuff most modern languages have, but Pike and his team always give very good reasons for their decisions and, after all, they've created Go for themselves.
Well, -1 / 2 = -(1 / 2), is that a problem for you?
[removed]
http.ReponseWritter is an interface so you can implement your own. Here is something I use regularly. type statusWriter struct { http.ResponseWriter status int length int } func (w *statusWriter) WriteHeader(status int) { w.status = status w.ResponseWriter.WriteHeader(status) } func (w *statusWriter) Write(b []byte) (int, error) { if w.status == 0 { w.status = 200 } w.length = len(b) return w.ResponseWriter.Write(b) } func LogHTTP(handler http.Handler) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { start := time.Now() sw := statusWriter{ResponseWriter: w} handler.ServeHTTP(&amp;sw, r) duration := time.Now().Sub(start) Log(LogEntry{ Host: r.Host, RemoteAddr: r.RemoteAddr, Method: r.Method, RequestURI: r.RequestURI, Proto: r.Proto, Status: sw.status, ContentLen: sw.length, UserAgent: r.Header.Get("User-Agent"), Duration: duration, }) } } 
i see so theres really no way of doing this without creating my own response writer and passing it down each time for each endpoint 
Use Dep to manage external dependencies. Dep will place them in /vendor for you. Your internal packages can go in /pkg. Stuff like /pkg/handlers, /pkg/router, pkg/models, etc. 
I know it's from Clojure conference but it's such a gem (in my personal opinion) i think it should be famous. And I believe it can be of use for Go programmers. I myself don't write in Clojure though i tried and am a bit familiar with it. I think we shouldn't sit in our community sandboxes and should share good ideas across technology stack boundaries. The irony is that it was Rich Hickey (creator of Clojure) amazing talks that inspired me to start my first project in Go and i like to discuss Rob Pike talks and ideas with my Python using mates.
&gt; because that's a technological choice that your users won't care about, or even know the difference. But search bots would.
Take a look through the standard lib and x packages. They are everywhere and super useful for certain things. https://github.com/golang/net/search?utf8=✓&amp;q=goto&amp;type=
Great video! I am still a novice at Go, so could you please explain the last part of the video (where you actually use the nil channel)? Why does this: v, ok := &lt;-a not cause a panic? Aren't you trying to pull off a nil channel after setting a = nil ? Sorry if it's obvious, and thanks again!
It is always legal to read from channel (after you close your channel, it will simply first return queued variable and then every addition read will instantly return default value) 'comma ok idiom' is used to determine if the return data is actual valid (like 0 for int, ok == true) or channel has been already drained ('0' and ok == false in case of int)
the channel has not been drained, it has been set to nil and that's the whole point of this video :) receiving from: - an open channel blocks until a new value is available - a closed channel never blocks and returns 0, false - a nil channel blocks forever
Yeah that a fair point that I should first watch the latest episode beforehand :). 
You need to wrap your handler anyway. 
I find this all the time in code reviews. I suggest looking at his talk https://www.youtube.com/watch?v=ynoY2xz-F8s from gophercon 2016.
You realize ... that ... I gave that talk? 🤣
Lol, yes. I guess you were not my audience for the post. I thoroughly enjoy how you approach your videos. Keep them coming. 
&gt; it's from Clojure conference but it's such a gem &gt; I think we shouldn't sit in our community sandboxes and should share good ideas across technology stack boundaries. Yes I totally agree. This is a great talk. We need to share more like these.
According to recent sources, no. Google will index pages produced with JS. Not sure about bing/yahoo, but hey, you're serving *people* first, not bots.
Previously posted [here](https://www.reddit.com/r/golang/comments/7jrwau/dotgo_2017_sameer_ajmani_simulating_a_realworld/) (includes the ~~annoying~~ dotGo intro). Slides previously posted [here](https://www.reddit.com/r/golang/comments/7b8g52/simulating_a_realworld_system_in_go_speaker_deck/).
Re-implementing your own `ResponseWriter` is the way to do this, but keep in mind, that you are [hiding optional methods in the process](https://blog.merovius.de/2017/07/30/the-trouble-with-optional-interfaces.html).
Markdown lists are created like this: \* item \* item \* item Comes out like * item * item * item
Got that working.. in case you can help with verifying the token via google's own function, do not hesitate.. :) https://stackoverflow.com/questions/48164890/google-app-engine-golang-how-do-i-pass-the-app-around-function
Looks cool, i'll give it whirl. Kinda wish the API was nanoid.New()
you cant reason with /u/dlsniper
I'm happy enough with Vue and how it works in SEO, and more over, love the separation of back-end APIs away from the actual front end code. The SEO stuff in my experience isn't impacted, and it's not worth it in my case to deal with a server-side stack for the bots of yesteryear. Happy 2018 :)
Note that JWT may create security holes if you do not know what you are doing and, in the case of JWT, if you do not have an infosec-background you likely don't. There's better and simpler (read: less error prone) alternatives, though. [Fernet](https://cryptography.io/en/latest/fernet/) is great and there's a [go library](github.com/fernet/fernet-go) as well.
I have used JWT in Java before without issues. So not that concerned:)
Ahem, there are some issues, like: ./gonanoid.go:5: imported and not used: "fmt" Unused (and invalid) `Generate` function too. Why invalid? Missing a return statement at the end. It's weird that go doesn't complain about the latter when running tests, it's literally missing a return statement at the end? Maybe Go knows that this is an infinite loop and doesn't complain about end of function return? Also, not handling `rand.Read` semantics on possible non-error less than len(bytes) reads in Nanoid() as well as Generate() and elsewhere. [Read io.Reader()](https://golang.org/pkg/io/#Reader). Use [io.ReadFull](https://golang.org/pkg/io/#ReadFull).
Gin is a great framework and we used it a lot in the beginning. However we have since switched to https://github.com/labstack/echo and are very satisfied with the functionality it provides without trying to do too much.
The biggest downside of JWT is that it is not easy to invalidate the tokens. In case you need this feature, I am curious to see how you have solved this problem.
I really don't know how else to solve this tbh, google's documentation is confusing af
I prefer https://github.com/go-chi/chi but really it doesn't matter too much. Ignore Github stars. The question is "is this software sufficiently maintained for me to rely on it?" That can be true even with 0 stars and false even with 1 million stars (see OpenSSL for a non-Go example of widely used unreliable software).
You can do markdown lists with `-` too. I think campoy just wrote `from:\n- an open` instead of `from\n\n- an open`.
I've had a lot of fascination with Otto and Goja as embedded scripting engines and it has led me to poke around at implementation requirements for adding a lot of the file system API for node. That in turn has made me start thinking about building a simple npm type project in Go. Most of the time I'm using Go for web services and small sites, and currently I use multi stage Docker containers for building. Whether I could make something or someone else could make something to replace npm in production build servers is an unknown which I don't expect to investigate in the near-term but it would fascinate me to see an attempt. Certainly an embedded scripting language should not aim to compete with V8 or run complex applications, but even for simple embedded scripts, I would like to see a way to pull in JavaScript dependencies without the need to require the massive dependency of node and npm.
[removed]
Maybe you should look at https://github.com/gobuffalo/buffalo
Nice, thanks. Out of curiosity, I'm trying to figure what you're doing in [errz.Log()](https://github.com/Benchkram/errz/blob/master/error.go#L67)?
But, since this service only responds to valid requests with an authentication header + JWT, wouldn't it be "prettier" for it to return 403 for everything except successful requests? Or maybe I'm just dreaming :) 
if you need to do this for a lot of handlers you can wrap it in something like: type precheck func(w http.ResponseWriter, r *http.Request) func (p precheck) ServeHTTP(w http.ResponseWriter, r *http.Request) { // verification here p(w, r) } and use it like this: http.Handle('/some/path/', precheck(someHandler))
You can take an interface{} as parameter and play with https://golang.org/pkg/reflect/ to manipulate your map
&gt; a panic due to looking at a slice index that doesn't exist isn't pretty... Indeed, hence why I am learning :)! &gt; Alternatively, use empty values: Thought of this, but seemed a bit javascripty to me. But yeah looks a bit better in the flow, I can see that. 
I'm not sure how is it better than just using panic/recover which is actively discouraged by Go?
Short answer: If you'd mask all bad requests to 403, you'll have a hard time tracking down the actual error. The 503 is a valid response, which you resolve by writing better code in this case. In another case it might indicate a database failure, or something else. Either way, it's something that should be investigated and corrected, and not hidden under the carpet ;)
&gt; but hey, you're serving people first, not bots. This depends on the model of your app. Is it a a SaaS where it requires users logging in and using a service? Then separating the frontend and backend makes perfect sense. But when your app is something reddit where the generated content is fed to bots, and then bots find people who search for what your content might have, then SEO will be crucial for your app to stay alive.
I assume I cannot go ahead and then just "cast" the parameter to the map I'm using? There's probably no casting in Go, right?
There are some various ways that you can slick this up here and there, but generally speaking, yes, Go tends to end up with some copy and paste here. It is slightly true that programming in a scripting language does encourage you to think of the world as a set of dictionaries, and Go prefers to think of the world in terms of structs, but still, for code like that you're going to have some annoyance compared to a scripting language. That dictionary merge code is going to end up looking like that pretty much no matter what you do in Go. Depending on your need for randomness, you can abuse Go a bit with: var randomkey string for randomkey := range myDict { break } though I don't know about how random that is. This doesn't seem like a crypto use case, but it's possible it'll still be more biased than you'd like. (Note if you test this on the playground, it either caches the result of the run, or has the randomness removed for the playground specifically; run this locally and you should see it choosing things with at least some randomness. From what I've seen, maps end up with constant orders within themselves for the same keys, but range will start at a random offset. I do not guarantee that is how this works, it's just what I've seen.) As MaxWayt suggested, it is true that reflect can do this, but I would recommend against opening that door at this point, unless you choose to do it for educational purposes. (Ultimately, the function would not be that long, but figuring out what ~10 lines you need and why they do what they do would probably be a distraction right now.)
I work on a project where we have to interface with git over exec. This works mostly ok, but it's ugly and error prone. I'd love to replace this with pure Go.
There is cast, but you need to know the exact type to cast with. Which does not resolve your issue here.
What I've been tooling around with is we have a package that performs aggregation on a channel with varying levels of heterogeneity I.e. Not much to aggregate, but millions of entries to go over, so many that once it hits a threshold we flush to disk and continue, I've been having it take in a gobencoder &amp; gobdecoder so that whatever comes in the channel can flush itself to disk. 
Yes. I just saw yesterday that there's an existing (stdlib) library that takes care of goroutine management, but I haven't yet seen a _multithreaded_ map/filter [1] library. [1]. Yes, if you don't need the speed, write it clearer. But speed is a bottleneck, on my machine the iterator approach goes almost four times faster than the naive approach, though only about 3/4 the speed of multithreaded rust.
There's actually some interesting interaction with Go, in that Go objects _do_ reasonably compose. Perhaps not quite as flexibly as functions in some ways, but then, in Go, functions don't compose terribly well either so object composition is much more reasonable. I have basically written the sample code that guy used in Go, _and_ it's sufficiently generic that I was able to write a generic engine for playing games over a network, and it looks pretty similar to what the clojure example was. I do find it interesting that Go is a language I'm OK with, given my other tastes, and I think the support for object composition is a big part of it. It's an OO language that tends to favor the compositional approach due to the fact that inheritance is effectively impossible in Go. This may also explain why coming in to Go from a conventional OO language can end up being a shock, even though on paper, Go and Java look like they ought to be virtually identical.
99.9% of the time you don't need a makefile for go. 
the vim plugins youcompleteme and ycm-generator require it
As an emacs user, I'm not even going to comment. ;-)
[MFW an emacs user shows up](https://78.media.tumblr.com/dc942338a5c819cbf57c450d6daa6dd7/tumblr_o91ea0KOJP1rjmvbeo1_1280.jpg)
Kind of on topic: why not look at gRPC? Are you really doing restful design, ie HATEOAS? If not, why not a binary, documented protocol that's supported by the majority of programming languages including Go and JavaScript?
Why not look into VSCode + Go plugin?
ew.
I'm actually not creating restful server but a server that returns html pages.
This looks like it will make the code look more complex, but at least I can have it in one function again.
I try to structure my Makefile’s as minimally as possible, basically just a place to store oft used tasks like running gox, linters, and other extras. I think all Go projects should “just compile” and install with the standard go command line utility. If you like, here is how I currently structure Makefile’s for my Go projects: https://github.com/mcandre/toys/tree/master/go/hello Ultimately, make falls short of being a complete command line solution for organizing builds, simply because of its dependency on low level shell details. It’s actually quite painful to write a Makefile that can delete artifacts for both UNIX and Windows developer machines. I started on a project to do that, called “meme”, but I think it’s best to use a build system that comes with crossplatform features, basic things like deleting files, getting the path to the user’s home directory and so on, so that the build tool users don’t have to rediscover and test this logic themselves. Gradle does a half decent job of this for JVM projects, and Gulp/Grunt can get by for JavaScript projects. I think in Go land, the thing to do is mage, which unfortunately requires a compilation step, but does at least hooks in fairly naturally to the Go standard library, which contains a crossplatform API for file system, shell, and path query operations.
I like `go-kit/log`. The `Logger`-interface is just alternating key values: `log.Log(keyvals ... interface{})`. With the `log.With(logger, keyvals ... interface{})` function you can pass in your logger and prepend it with a relevant kv such as level, timestamp, component etc
Makefile for building any go project: all: go build 
No they don't, that's just for the clang completer. You need to install gocode though. 
For those unfamiliar with make, `all` is not a special keyword, Make just uses the first target as the default, so running `make` would run `make all` in this instance. It could be called `foobar:` and would work the same way.
I don't see much need to build up the list in a single method, just so you can select a random one from it. func pickRandom(dict map[string]map[string]int) string { which := rand.Intn(len(dict)) c := 0 for k, _ := range dict { if c == which { return k } c++ } return "" } On the other hand, if you're looking for a way to make your code more expressive, I think it's important to remember that go will let you define methods on any type you define, so: type MapOne map[string]map[string]int type MapTwo map[string]int func (m MapOne) keys() []string { keys := make([]string, len(m)) i := 0 for k := range m { keys[i] = k i++ } return keys } func (m MapTwo) keys() []string { keys := make([]string, len(m)) i := 0 for k := range m { keys[i] = k i++ } return keys } func pickRandom(keys []string) string { return keys[rand.Intn(len(keys))] } Yeah, there's copy and paste there, but it's isolated to the particular issue of getting the keys. With this, you can just do `k := pickRandom(myMap.keys())` where `myMap` is either type of map. 
Like just serving? If so, why not learn nginx? You'll get to learn about services, and configurations, but get a really quick, custom built problem solver. The reason I pry is to see if you're using the best thing for a problem. Don't get me wrong, Go for the sake of Go is nice too. I just want to do my part to avoid a not-made-here mentality.
Oh sweet. I would've just removed the whole map and put interface, that would also get rid of the switch that was suggested on another comment.
Interesting. I thought I read the other day, that there's no method overloading. How does this work then?
Here is an example https://play.golang.org/p/d1oyvUmW3lg
The best resource is the one-page [make manual](https://www.gnu.org/software/make/manual/make.html) here. Just control + F for any identifier you're unclear about. If it's not found than it is probably an environment variable or defined in the Makefile. I personally think Makefile's are really useful and use them in all my projects to build my docker containers and binaries. Although many people use it to just execute commands, the purpose of make is to map targets to a dependency graph and set of commands to *make* the target. Knowing this there is only 3 things to be confused about, what are the targets? what does a target depend on? what commands are needed to make a target? Some useful flags to answer these questions: - Flag -r to remove all the implicit rules which makes the next flags less noisy - Flag -d to add debug information, this will show how make is determining if targets need rebuilt. - Flag -n to just print the commands but don't execute them, a dry run - Flag -p provides a nice dump of makes internal state, this is useful for example to figure out the origin of a variable. Things that come from the environment will have a comment the line above them of "environment" where as macros will have "makefile". If you show some examples of ones that you don't understand than people could help explain what they are doing. Knowing the above though- when you want to discover those meanings on your own you may simply: # What the heck is this? $(ACME_VAR) # control + f "ACME_VAR" on makefile docs, not found so lets check make -np $ make -np | grep -B1 '^ACME_VAR' &gt; # environment &gt; ACME_VAR = acmeval # ^ It's an environment variable # What about $(targets), it's not in docs! $ make -np | grep -B1 '^targets' &gt; # makefile (from 'Makefile', line 1) &gt; targets := acme_file1 acme_file2 # ^ It's a regular variable containing a list of space separated files # What about $(call ACME_BUILD), docs say call means execute a # function, but ACME_BUILD is not in docs or in my environment? $ make -np | grep -B1 '^ACME_BUILD' &gt; # makefile (from 'Makefile', line 24) &gt; ACME_BUILD = test -f .$(1).image || { ... shell cmds ... } # Interesting, what other functions are defined? $ make -np | grep -A1 '^# makefile' &gt; # makefile (from 'Makefile', line 1) &gt; targets := .acme.image .acme2.image &gt; -- &gt; # makefile (from 'Makefile', line 12) &gt; ACME_LOG = test -f .$(1).image || { ... cmds ... } &gt; -- &gt; # makefile (from 'Makefile', line 24) &gt; ACME_BUILD = test -f .$(1).image || { ... shell cmds ... } &gt; ... # Why is this building the entire project .. EVERY TIME! $ make -dr &gt; &lt;will print dependency resolution decisions&gt; &gt; Prerequisite ACME_FILE is older than ACME_PART. &gt; Must remake target ACME_FILE # Your makefile needs improved, make sure you can type # make ACME_FILE without rebuilds before running a # top-level target as more distance in your dependency # graph makes troubleshooting harder. You can write horrible make files just like you can write horrible shell scripts, but well put together makefiles are pretty easy to follow after a while if you take the time to learn.
If you're serving static HTML, you should really just use `http.FileServer`. Or nginx. Or, host the files on S3 and enable Static Website Hosting (this option is huge, more people need to use this). 
No, they are dynamic (I think this is the correct term). I use the template package to generate the html files with data from the database.
Guess this doesn't work: markov/markov.go:71:20: cannot use dict (type map[string]map[string]int) as type map[string]interface {} in argument to pickRandom markov/markov.go:85:27: cannot use dict[word] (type map[string]int) as type map[string]interface {} in argument to pickRandom
Oh I see, you're defining a function for the type that you created.
Yeah, the polymorphism in go is limited (on purpose), but you can definitely define the same method (with exactly the same param list) on multiple receiver types. That's the root of `interface` definition in go. Building on my previous example: type keyPicker interface { keys() []string } func (kp keyPicker) pickRandom() { keys := kp.keys() return keys[rand.Intn(len(keys))] } and then you can just say `k := myMap.pickRandom()` for either type of map. Yes, there are some, er, limitations in go, but after you get the hang of it, it can be much more flexible, in ways, than some other languages. 
[MFW when I get that reaction](https://media.giphy.com/media/QKEFDjlKEuXLy/giphy.gif)
Good to know, thanks for the explanation.
Thanks for the example. Will play around with that one as well.
I'm slightly confused about people comparing Chi with Gin. Gin is a framework, which uses [httprouter](https://github.com/julienschmidt/httprouter) as a router. Chi is "just" a router with some middleware. You can't compare those 2 as they don't serve the same purpose and you surely can't recommend one over another. For OP: what's wrong with the http package? Why do you want to try something new? When I first started doing stuff in Go I was looking for a framework as well, coming from PHP/Symfony2 I was used to that approach. I've been through nearly every framework Go has to offer... at some point I was always hitting a wall deciding that I'm not gonna use that particular framework. The standard-library+a proper router (like Chi) serve me well these days and so far I've not caught myself looking for a framework again. On the opposite, I'm in the middle of writing my own little framework that helps me develop faster. Also helps me learn Go a bit more.
I even turned it around a little and now I'm able to use these types throughout my code: // SubDictionary of follow up words and the corresponding factor. type SubDictionary map[string]int // Dictionary of start words with follow ups and the corresponding factor. type Dictionary map[string]SubDictionary
While you don't need make for Go, it is however useful for those small edge casts for advance Go development. For example: What if you are publishing your binary cross-compiled for 5 systems? Who wants to remember all of those params and typos when you can have it all in a single make target that will loop though all 5 targets and build for each system. What about controlling C.I. servers like Jenkins? Who wants to become a Jenkins expert, having to grant everyone on the team direct access to modify the Jenkins runners for the slight build change - when instead you just have it run a make target. Then you can control what Jenkins runs, tests, builds and deploys all from Makefiles and batch files. Another is often devs don't read the README to know they need to first run go generate before go build to update any Go files before you build. You can put this in a make target. Another I often use is for testing: instead of teach dozens of people across different teams on how to run unit tests separately for your project than you integration tests, you could instead just have Make targets for each (tests that include Intergation or not, tests with -s short flag, etc). In summary, while you mostly don't need them, Makefiles can be used for slightly more complex projects requiring a few addition build steps, where you don't have to teach every single person what those build steps are, how they changed, what they adapt to as it progresses and so on. Instead, you just tell everyone and support `make build test deploy` and be done with it. The basic rules I follow is: if it is anything other than `go build`, create a Makefiles and direct everyone to run that instead. If anyone has a question as to what steps to follow, they can just open the Makefiles and see the additional steps.
How arbitrary? gRPC seems to do well. And if that isn’t supported there’s good old fashioned JSON. 
cool.
+1 for GRPC
Given that you're writing a markov bot and most of your time will be selecting random entries from maps, the proposed solutions below are all very expensive in terms of both time spent and memory used. Here's a solution that defines `smap` a string to anything map that tracks the keys that have been inserted and provides O(1) random key retrieval. Then it defines `wordmap` and `dictmap` with type-safe wrappers around smap. https://play.golang.org/p/-0ZyYwJH_ax 
While this looks interesting it would still need some tweaking as my implementation will rely on the factor of the word, hence map[string]map[string]int is my original definition. I will have a thorough look at your example later today. Thank you.
Not easily, as it belongs to the company I work for. It's a system for running programming contests based on writing game clients. But I wrote about [some non-trivial elements of the techniques I used here](http://www.jerf.org/iri/post/2945).
Haha, I probably should have googled "goroutine pool" before making this post... It looks like this is exactly what I'm trying to do: https://gobyexample.com/worker-pools I think I'll try it this way initially, but that repo also looks really interesting so thank you for that!
&gt; Always copy and modify! If you can't understand make well enough to write a Makefile, how would you know if your copypasta's any better?
From what you're describing, the consumer/producer (AKA worker) approach would work to your advantage quite well. Bear in mind that channels will block if they are full, so you don't necessarily need to have a channel that communicates from the worker to the main process in order to get more work. Just have the main continuously trying to send more work through the channels. When an item is removed from the channel, main will be permitted to send another item. Would you like an example? Also, from what I can tell, you probably aren't looking for a library/package/framework to do this. It's should be easy enough to do with the types/packages Go ships with. It really depends on your requirements.
You're right, I would definitely rather implement things on my own as part of my goal here is to learn. An example would be great if you have one!
As someone who writes Go, I've never seen a Go Makefile, but since you're looking for a VIM experience, I recommend using VS Code with VIM keymappings. A friend of mine uses that setup, and I don't believe he uses Make for anything. Make isn't bad, but it just isn't common in Go projects. That said, the suggestion for the one linego build make file works.
VSCode + Go plugin + **Vim plugin** then!
Experiment with someone else's code. And don't try to re-invent the wheel. ;) But I agree that you need some sort of understanding of how things works to be able to use the code proficiently. 
For me I'd rather use gin that http because I'll be just writing code that someone else has already written, and written better than I could write it.
Another upvote for chi. I don't prefer routing framework that doesn't use `HTTPHandler()` interface or if they invent their own `Context`.
&gt; avoid the verbose but idiomatic error handling pattern &gt; if err != nil { &gt; log.Println(err) &gt; return err &gt; } This is not the idiomatic way. In the above snippet you are making two decisions. You are both logging the error to a file and returning it. This is problematic because the error can appear at more than one places. You are essentially handling the error twice. Do either but not both. The idiomatic way to handle errors in Go is to add context and produce meaningful error messages. [Errors are values](https://blog.golang.org/errors-are-values). You have [the entire language](https://blog.golang.org/error-handling-and-go) at your disposal [to handle your errors gracefully](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=17m25s). Use it.
There's also my implementation at https://github.com/dgryski/go-highway ; I haven't updated the assembly core (only amd64 for the moment) for the new frozen hash definitions. "Soon" though..
I watched the episode and was puzzled in the beginning, because Intuition lied to me and I expected select to deadlock for a moment. Maybe this was because you presented the nil channels deadlocking with the example snippet. Then I remembered that having all inputs blocked is normal for select - it processes the first channel that does not block anymore, so everything works just as demonstrated and does not deadlock. Edit: fix typo
Yup, you got it right!
Yes @dgryski would love to get your feedback as well. 
Faktory is written in Go, with a significant chuck of C++ in RocksDB requiring CGO. I hope people find it useful to have a polyglot background job system.
&gt; We always listen to the OSS community, and many voices were asking for a new license. As of today we’re moving go-git to Apache License, Version 2. Out of curiosity, I would like to know what was the previous License, what problems you had with it and why did you choose this particular license as your new one.
https://play.golang.org/p/w0z-JnoHTVj
It was a joke, get over yourself. 
I strongly dislike visual studio. 
what is the difference between cherami released by Uber and faktory
I wrote a package a while back you might want to check out, github.com/dvln/out is the name. It has leveled logging, can manage a couple of writers (screen and log file for instance with independent output level controls, thread safe, and one can flip on log levels based on file name or even routine within a file... although I tend to use those via env control when I want to do that). Regardless, you can modify further as needed...
People typically discourage new Go developers from using web "frameworks" because it's valuable to understand Go's http standard library before jumping into someone else's abstraction. Often times, for small projects at least, the standard library has everything you'll need. That being said, you're going to find common tools/patterns/features useful as you write more web applications. Once you're operating in that context, you can either: A) Be a "no framework purist", which would require you to copy+paste tools/patterns/features from project to project. B) Use someone else's package that has the tools/patterns/features you find useful, e.g. gin. C) Create your own package that has the tools/patterns/features you find useful. awesome-go is a great resource for checking out go projects, and has a section of web frameworks and middleware: https://github.com/avelino/awesome-go#web-frameworks 
If go is spawning the other language then json on stdin/stdout is pretty straightforward and makes for a very language agnostic interface.
Think he meant `str += msg`
Thanks for posting this! 1) What logger are you using? I don't recognize `Log(LogEntry{...` 2) How does the handler get used? Thanks!
I thought this was a really interesting talk on utilizing a lot of google's app products (firebase, app ending) in order to create a realtime crossword player. Disclaimer: I created Talkery.io - [Click here for the original Youtube Link](https://www.youtube.com/watch?v=8mLmyK-n5JQ)
Oh okay good one.
Hey. Any progress on this marvelous idea?
Visual Studio Code is not Visual Studio (Microsoft sucks at naming things) EDIT: Or you can use nvim + vim-go + nvim-completion-manager and avoid all the YCM bs
Feel free to send improvements/suggestions - thanks for letting us know. 
Starting goroutines and just letting them end is generally simpler and faster than trying to do pooling yourself. Unlike GC for memory objects, where the end-of-life is only determined during a mark-and-sweep phase, the end-of-life for goroutines is obvious once the function returns. In that situation, the runtime actually puts the goroutine stack in an internal pool. New goroutines are actually sourced from that pool. Writing your own pool is likely to be slower and have edge cases that causes it to perform terribly.
makefile is optional in using Go, I only use simple one to stroke less keys: all: run build: @go build run: @go run main.go test: ...
I see. But what if you need a job queue sort of setup where you want a fixed set of goroutines and you want your code to wait until a goroutine is free to take up the task ? Possibly to indicate processing backpressure to downstream clients. Isn't a goroutine pool a good solution in that case ?
I'm sorry my package wasn't more friendly to adding the arm64 code :( . Now we have two packages for highway hash instead of one.
You definitely can - the system/db package lets you query the DB for your raw data without making an HTTP call. 
That was my first thought as well, but then I saw the break statement in the next line ;) 
What you're describing sounds more like semaphore, which can be implemented using a buffered channel containing empty structs. sema := make(chan struct{}, n) // where n is fixed # of goroutines 
Wait.... what...? Haha
Great write up! Thank you very much
Yay - someone with knowledge being helpful! 
You are right actually. I was over thinking stuff.
In what way do you mean a bit much? gRPC is actually really easy to use, but if you want to get simpler (though more difficult) then you could always just use a raw TCP connection and pass bytes around yourself - but why go through all of that hassle if you don't need to? gRPC will also be more lightweight than making some JSON web service too since Protobuf is a faster (to encode and decode) and more lightweight data format.
You just feed them little chunks of work through a channel, and have each goroutine range over that channel. Here's the basic pattern: workCh := make(chan T) var wg sync.WaitGroup wg.Add(poolSize) for i := 0; i &lt; poolSize; i++ { go func(in &lt;-chan T) { defer wg.Done() for work := range in { // do stuff } }(in) } for _, b := range batches { workCh &lt;- b } close(workCh) wg.Wait() ... 
There's a new update in the LE forums: https://community.letsencrypt.org/t/2018-01-09-issue-with-tls-sni-01-and-shared-hosting-infrastructure/49996
Yes, solved. It has been posted here a couple of days before. Also ft works unencrypted ... or you pipe it through a tunnel.
We'll, you have this if you're on Android: https://play.google.com/store/apps/details?id=com.termux Go is in the repo, as well as clang/gcc, and I even have rust (for ripgrep) installed on my little phone. Which does have sshd. So if you can live with emacs or (neo)vim + vim-go, and have a dumb terminal somewhere - that works. Price is also right (free)! You can even just use the phone. Would strongly suggest using an editor config that remaps ESC, though - or use a non-stock keyboard on Android. Downside is I have some hiccups on my Oreo device - the Termux API module is currently broken - but you don't need that for coding.
Interesting. Thanks.
Can't find my info on actually using Cherami beyond setting it up, is anyone using it bar Uber (are Uber even using it)?
The lack of generics makes it very difficult to write any of the tools you're used to in functional programming, or the dynamically-typed languages that can do it. It is impossible to write in Go the function `func map([]&lt;A&gt;, func(&lt;A&gt;) &lt;B&gt;) []&lt;B&gt;`. I can't even express it in the syntax without making stuff up. Even if you use reflect, you'll still be forced to return an interface{} out of your function which will have to be casted. They don't completely fail to compose, either, because we do have closures and can pass them around, and get some mileage out of that. But generally Go prefers object composition techniques, such as the way it makes the decoration pattern so easy it's hardly even a pattern because it's just in the language. Compare Go to even Erlang, which I don't consider a very good _functional_ programming language (very tedious to map and fold and reduce things due to its syntax), and Go can't even keep up with that. Trying to write in a functional style in Go is not a great idea.
Previous discussion [here](https://www.reddit.com/r/golang/comments/7p3jwx/justforfunc_26_why_are_there_nil_channels_in_go/).
sorry :( my bad
http://rurounijones.github.io/blog/2009/03/17/how-to-ask-for-help-on-irc/ If you're going to ask a question like this and give us no context, we're not going to be able to give you a good answer.
[removed]
&gt; PPPS `r, _ := utf8.DecodeRune(word)` this can be too slow because of GC. Highly doubt that. `DecodeRune` has no reason to either allocate or let `word` escape.
I suggest posting [here](https://www.reddit.com/r/RosiePatternLanguage/comments/7mijxx/integrating_librosie_a_c_library_with_go/), as the author requested. They are unlikely to read comments in this subreddit.
There are a whole lot of good tools for this sort of tasks out there already, pick one which works for you and move on. Just let this autocrap-era abomination die already. 
Two relevant issues on github: [x/crypto/acme/autocert: Manager should support DNS-01 verification #23198](https://github.com/golang/go/issues/23198) [x/crypto/acme/autocert: Support http-01 challenge #21890](https://github.com/golang/go/issues/21890) 
I installed Go and VSCode on a cheap (99€) Windows 10 tablet PC with Atom processor. Although everything is pretty slow, it works. Downside: Windows takes most of the RAM for itself. I plan to try installing Linux when I have some time left.
Hello again, We filled the previous position, but we're hiring again for Kubernetes work. This one would be for senior engineers. Here's the new job post: https://www.reddit.com/r/kubernetes/comments/7phrg7/microsoft_is_looking_again_for_folks_to_work_on/. If you want and think you'd be a good fit, can you DM my colleague on Twitter? https://twitter.com/khnidk
I'd like to understand this better. What I thought could be happening was that a small stack was erroneously allocated (in the pthread sense of asking the OS for space when the thread is started). Does a CGO call run in a new thread with a larger (typical for C) stack? Does that mean that there is the overhead of thread creation for every CGO call? This would be unfortunate. Thanks in advance for any references to how CGO works. I've seen many blog posts and such, and read the CGO docs, but I'm not seeing a lot of detail. (Also, I am not a Go programmer, so I only have at hand the docs that Google can find for me. I could easily be missing something because it comes up too low in the search results.)
M's are real actual machine threads. Are you doing a lot of syscalls or cgo calls ?
Does Caddy impacted ?
For those who downvoted the comment I'm replying to, I'd like to understand why? He has made valid points, especially if you aren't doing micro services or api endpoints. Not everybody has the time or has the experience or know-how required to better or equal a framework that has been eyeballed by tens or hundreds of people and used in production in various scenarios. And even more important if a framework like gin covers the majority of his needs, why should he reinvent the wheel by using something with less features? 
https://news.ycombinator.com/item?id=16112322
yeah, i hear you. you can do regular queries?my schema is pretty basic right now so i don't have to worry about these issues at present. In think in future ill just use regular sql in the data layer. any particular reason you don't use AutoMigrate() ? i shall check out the repo also. thanks! 
&gt; The word 'golang' had been used in reference to the Go programming language since the language birth. Always as a tag or identifier. Never in official, formal text. &gt; there are tons of articles and posts who interchange between golang and go The articles and posts that use anything other than Go in their formal texts are wrong. Just because others do the same mistake it doesn't mean you should as well. &gt; the official Go playgound site is play.golang.org, the official github repo of the language is under the name 'golang'. All those are URLs. We are talking about formal text here.
That looks pretty dope. Unfortunately I only have one thinkpad with wifi, otherwise this would be really fun to play with. 
Thanks for checking it out and please spread the word to anyone you think might be interested!
Thanks for posting the link. For some reason, I can't reply to /u/jmank88's comment, so here I go instead. Now that we have more details about the incident, I realize my suggestion to use the -disable-tls-sni-challenge flag as a precaution was not necessary. As long as the HTTP challenge is still available (which it should be, unless you don't have port 80 going to your service) or you've configured the DNS challenge, Caddy users are happily not impacted. (Interestingly, both Traefik and certbot and some other popular clients apparently experienced issues with the incident. But Caddy should be mostly unaffected.)
you could have just written the layout algorithm as a binary, and kept the amazing modularity of wmutils
“Too much” is dependent on your environment. 
[removed]
Yeah, much like Magic Wormhole without the need for a rendezvous server. Thanks for the tips!
Thank you. I implemented TLS transport in this morning. :)
With respect to errors and logging/forwarding, one thing to consider is Dave Cheney's [pkg/errors](https://github.com/pkg/errors) package. It includes some useful features such as error wrapping (and unwrapping) and stack capture. I've found it useful to use this package to capture and forward rich error context and save error logging for higher application-layer levels. +1 for using Context, now that it's part of the standard library.
[removed]
[removed]
Thank you a lot ! You just gave me a new perspective !
A very minor nitpick: it's better to say «…the `context` package» since it's in the stdlib for pretty long time.
I don't know who downvoted who but you shouldn't care so much about downvotes. For example post anything that praises Go in the programming subreddit and you'll probably get downvoted. Post anything about Rust and you'll be flooded in upvotes. The Go community tends to lean towards using `net/http` as a framework but of course people will always have different opinions.
is faktory compatible with sidekiq?
I'd personally rather spin up a cheap server and shove my binary on it, but if the place I was working for mandated lambda for everything for whatever crazy reason (I've been in worse employer-imposed situations before!), I'd sure as heck be grateful go was available!
It isn't really about making it easier to host your program. FaaS is a newer paradigm that breaks applications down into even smaller chunks than microservices. You can now scale a function as needed instead of your complete program. Also a lambda could be cheaper to scale and run since it can spin down from hot to warm to cold when not in use. You can combine the two concepts. Your main front end could be a binary running on a less powerful instance. But the heavy functions, when accessed, could scale out as needed with lambda. 
 if strings.Contains(j, ":") { user := strings.Split(j, ":")[0] cryptPass := strings.Split(j, ":")[1] Really? Scanning the string from the beginning three times in a row? Please learn about `strings.SplitN` and do parts := strings.splitN(j, ":", 2) if len(parts) != 2 { continue } user, cryptPass := parts[0], parts[1] // and so on... 
There are pros and cons to both approaches. If you need to spread some work out pretty quickly, or the scale changes quite dramatically at times and the workload is suitable for functions then they're great. It means you don't have to spin up a cheap server, you instead automatically spin up much cheaper functions, and when they're used they're gone. Where I work it's a combination of billing and being a bit more flexible.
IMHO It is basically about the auto scaling available is AWS Lambda as well as the costs in which you only pay when your service in running.
I don't think people have really understood your question.. you seem to be asking not why to use AWS Lambda, but why AWS doesn't already support Golang in Lambda, since it should be easy. Consider the following: maybe it's the fact that Go does _not_ require an installed runtime that is making things so difficult. If you look at the 4 supported languages, they are all interpreted or compile down to some intermediate representation which is then run by the JVM / C# runtime. This makes it really easy for the user to provide their code--for Node.js and Python, they simply provide the source code, and for Java/C#, they provide the '.jar's/whatever C# uses, which can be built on any operating system. How does it work with Golang? Does the user compile the code themselves? If so, do they need to target Linux when they compile, or do they have to go so far as to run Amazon Linux in a container in order to 'build' their Go code in the correct environment / with the right dependencies? Or does AWS compile the Go code for you? How do you hook dependencies into your project? Additionally, AWS does a little more to 'support' your Lambda functions than just running them--they include AWS SDK dependencies so you don't have to, so now the Go SDK needs to be available to your new Go Lambda functions. Writing Go for AWS Lambda is already possible if you call your Go code from the Python runtime (https://github.com/eawsy/aws-lambda-go-shim), so we know AWS hasn't left it out because they can't get it to work--it's just a matter of supporting it. I'm not sure exactly what's standing in their way, though. Apparently it's on the roadmap--I think it was mentioned in passing at reinvent 2017.
What I did and can highly recommend is to write any CLI program which is already existing in go. I've written this https://github.com/mstruebing/tldr for example and learned a lot.
What I did and can highly recommend is to write any CLI program which is already existing in go. I've written this https://github.com/mstruebing/tldr for example and learned a lot.
Great writeup! I'm fluent in python and just getting my feet wet with go. In the first implementation, Is it possible to limit spawning more goroutines until others have finished such that no more X are running at once?
Maybe API's...? https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
We are about to do a text adventure on gameswithgo.org tonight 
What are you thinking about when you say that? I'm in no way saying I'm wrong, but I'm interested to see what your thought process is. :)
Well this isn't practical but it teaches a lot if you build it without a framework. Have files send requests to each other. Have a webpage be able to send API's and consume them. Have a request send to another go file server and process it and send it back and do more processing. Things like Google AdWords API's do this all the time. My work has to do this to make reports to enhance AdWords on their sites. 
Hilarious, though I'd love to see some stats. What's the highest it's ever reached? What's the average time between routers? etc.
Thank you for your attention. I will take note of the remark.
Looked over your README and I didn't get what tldr does. Just a suggestion to add a blurb about its purpose at the top
Thx will do :) I thought the screenshot is enough. Basically: pretty prints the most common used parameters to different CLI programs.
You can use it with one additional argument (More possible but only the first one is handled) errz.Log(err, "another error msg") to add more context. If you do not want to handle the error in place you might want to add more context to it.
What? 106,000 days? That's 290 years. I don't understand what I'm looking at....
The most likely reason is they can’t preempt runaway code. Google AppEngine supports go, but it has many restrictions on the FaaS option.
I dunno, you can pass functions around in C# and Java more or less the same as you can in go. Perhaps there is some similarity into the style of having more free functions in in Go/Pythong/Erlang, whereas Java/C# all functions are part of classes/structs. I see Go more as a middle ground between C and C#/Java really, fewer features than Java or C#, more visibility into pointers than Java, native compilation. But it has garbage collection and string support built in, and doesn't allow pointer arthimetic so isn't as low level as C
Probably a null or NaN
They're probably not using a good router library.
Yeah there's a lot different but c# will add goish features soon enough. I wonder why? https://medium.com/@alexyakunin/go-vs-c-part-1-goroutines-vs-async-await-ac909c651c11 On top of the pages of new ones...https://docs.microsoft.com/en-us/dotnet/csharp/whats-new/csharp-7 I think Rob makes this point that hasn't apparently sunk into the c derivative languages engineers minds. https://youtu.be/rFejpH_tAHM 
I've been considering making an OSINT module with GO, but my idea might be too optimistic. Ie. completely out of my depth. :D But in reality anything that is in the realm of security or devops. Could be fun! :)
Yep, thanks I got that but why passing in msgs and then only using the first? Besides, a simple `msgs [0]` would do then. I'm still unsure what you want to achieve here.
The first example probably doesn't do what you want. Even if the buffer is large enough to hold the entire file, `Read` does not guarantee that it will fill the buffer. You need to use `io.ReadFull` or a manual loop to ensure that you read everything.
"Disables your wireless internet connection while in use" That's a pretty major limitation.
that's easy, how many golang developers are there? multiply by 2
AWS Lambda is not worth it compared to the other supported languages (compared to ex NodeJS). I'm stating that because Go has virtually zero startup overhead compared to spinning up a JVM instance to make your function `hot`, or booting the whole nodejs -- in both time and resources (per request and on boot) It's more worth it to have it ran on some simple EC2 server, or if you really need the extra scalability, either elastic beanstalk or some kube cluster. 
You can find the above and more interesting channel patterns here: http://nomad.uk.net/articles/interesting-ways-of-using-go-channels.html
If you're transferring big files or one of the wireless cards is slow, yeah. If it's a quick transfer, it will put you back on your previous wireless network afterwards so you'll only be down a few seconds. One of the main goals of the project was to not require any network infrastructure or internet for it to work, which means one of the computers has to act as the access point.
The built-in logger is very minimalist, like everything else in standard library. I've had fun building small logging libraries.
Hi, I'm building an auto updater dependencies, if you want you could implement a c# updater. It use docker to start builtin tools (npm, maven, pip...) So you could play with docker... The project is here https://gitlab.com/ContinuousEvolution/continuous-evolution All you need to do is implement an interface and you have lot of examples in this directory https://gitlab.com/ContinuousEvolution/continuous-evolution/tree/master/src/updaters Anyway you do, have fun with golang ;)
Depends on the os, and what features the other languages support. Sockets, network, shared memory, files on disk. High level question gets high level response.
There's a Go utility [croc](https://github.com/schollz/croc) too.
&gt; Isn't one of the points of Go the ability to deploy a compiled binary file in almost any system But you've to manage this system. It can be EC2 instances, an ECS/kubernetes cluster or bare metal server somewhere. You have to pay to keep it up and invest time+effect into maintaining it. With lambda, you literally just need to worry about your software. The infrastructure is truly abstracted away.
Ah, I think I misunderstood your question. I guess what you are asking is why Lambda needs a special "runtime" for Go as it just produces binaries and lambda can just execute them. Good question. The answer lies in understanding how lambda truly works. Lambda does not start a new version of your program every time the function is called. The real entry point to the program is somewhere else hidden to customers. That program starts up and then waits for requests like a web server. On every request, it invokes our lambda function. It literally invokes the function, it does not spin up a new instance of the program. The program lambda spawns keeps running until no new requests come in for a certain amount of time which is not known. This is also why first invocation of a lambda function after a long time is slower. Also, there still are other things to take care of. Online code editor support, making sure everything works and there are no bugs, support for compiling the programs edited directly from the browser, etc etc.
&gt; The Go brace style -- opening brace for a function on same line -- is a consequence of the rules that allow the omission of semicolons. Putting the opening brace on the next line leads to an insertion of a semicolon after the ) of the function signature, which leads to an compiler error. Yeah, it's a consequence of the decision to make semicolon omission happen at the lexical level instead of during parsing, to be more specific. The other option to make this happen is to require a semicolon (or empty line) when you have a function call followed by a block. &gt; An argument I never hear about generic programming is that it would lead to a wide set of container libraries that would make it harder to understand Go code. The fact that there are only two containers used in Go code, slices and maps, contributes a lot to the good readability of Go code. I write Java for a living. The collections can be summed up as `HashMap`, `HashSet`, `ArrayList`, and special-purpose collections. In my free time, I write a lot of D. The collections can be summed up as builtin arrays, builtin associative arrays, and special-purpose collections. In Go, the collections can be summed up as slices, maps, and special-purpose collections that omit type safety and incur extra allocations. Such as [container/heap](https://golang.org/pkg/container/heap/). C# 1.1 and Java 1.4 were in the same boat, but C# 2.0 and Java 1.5 were released before work started on Go.
I remembered an interesting program from college called crobots where you wrote a program for a robot in a subset of C and battled against another one in an arena. I'm going to get rid of the virtual CPU's that run the robots and make the arena accessible with GPRC's go the robot code can run native.
I am actually using WiFi Direct for Windows cards/OSes that no longer support hosted networks. But it's based on a C++ WiFi Direct Legacy AP sample from Microsoft that I adapted to a DLL, so it basically acts just like a hosted/ad hoc network. I believe AirDrop uses Bluetooth to initiate the connection, which I don't want to mess with, and it seems like Apple went with Airdrop to the exclusion of WiFi Direct, so their hardware doesn't interoperate with anyone else's. I'm using the CoreWLAN API with Objective C (via cgo) on Mac. I would love to get everything working over WiFi Direct someday, maybe with wpa_supplicant.
Not to throw stones or anything ... but have you ever considered the use of capital letters?
Try with Raspbian ;)
I will admit to a moment's confusion on how to capitalize HTTP. net/http seems to use HTTP though, even when CamelCase might suggest Http, so I went with that. Entire fractions of a second were burned on that decision.
Is it a good idea to count the days.... rather than the hours?
VSCode run on the browser since it's build using electron so I doubt it that the architecture would be the problem. I've made some quick search and there's people successfully using it, but an code editor should not stop you from installing an os that will make you're coding experience better ;)
That's a list of things, you have to unmarshal into a slice: https://play.golang.org/p/watM21z9eiZ
I think you're right. I should probably write one for them.
For Go code, [initialisms are generally done in a consistent case](https://github.com/golang/go/wiki/CodeReviewComments#initialisms).
I use this https://play.google.com/store/apps/details?id=com.codeanywhere.mobile Not really coding on the device itself but found to be the easiest mobile editor.
m := fmt.Sprintf("%s\n", message.(string)) Why you do type assertion here? If int or something is passed into message, Write func will be panic.
m := fmt.Sprintf("%s\n", message.(string)) Why you do type assertion here? If int or something is passed into message, Write func will be panic.
HTTP routers in Go is the equivalent to web frameworks in Javascript or Logging libraries in Java.
Defer simply 'defers' the execution of a function until the enclosing function returns. https://tour.golang.org/flowcontrol/12 You're example is meant to (I assume, I haven't used gorm before) close the database connection when the enclosing function exits. Also, I think you meant to leave off the 'go' at the beginning of both those lines.
[`defer`](https://golang.org/ref/spec#Defer_statements) executes a function when the current function is exiting. It's largely used to clean up connections, which is what you're doing with this code and http response bodies. `db.Close()` closes the underlying db connection and you're telling the code to execute it when the function exits.
I had the same problem a couple of days ago and I think I solved it. Basically when you make a json.Decoder, you have to call `decoder.Token`before calling`decoder.Decode` Experience gophers please let me know if this is correct or not. 
Thanks, /u/anssov ‘s solution worked for me. 
This website doesn’t expose which router it’s using. Unless... it’s always using the latest router available? :)
I've worked with a fair amount of JSON in Go and never knew decoder.Token existed... So no, I don't think that's correct for simple parsing like OP is working on.
Adding on to the responses of others, apart from closing resources and stuff, `defer` is invaluably helpful when your function has multiple code paths, but you want to execute something at the end irrespective for whatever path it takes. For eg - func doInterestingStuff() { if condition { if error { doFinal() return errors.New("something") } } doFinal() } can be re-written as func doInterestingStuff() { defer doFinal() if condition { if error { return errors.New("something") } } } 
Before you use this, note that, * This hasn't seen updates in a year * There are no tests * The API goes directly against the [Go naming guidelines](https://blog.golang.org/package-names#TOC_3.) with stutter like `subcommands.Command` and `subcommands.Commander` There are a number of command line argument parsing libraries that are better maintained, have better APIs, and support more features than just subcommands. * https://github.com/jessevdk/go-flags * https://github.com/alecthomas/kingpin * https://github.com/spf13/cobra 
Conceptually, Unlock syncs registers with variables. It uses a memory fence (aka magic hardware instructions) under the hood. Actually, Lock also has some fences in it. To prevent the compiler performing reordering the "obj.var += 1" above the Lock(). It's also worth noting that the compiler is not the only one playing these tricks to make your code faster. Your CPU is also doing all kinds of stuff (e.g. out-of-order execution, speculative execution, prefetching into caches), and the memory fences ensure that the combined optimization performed by the compiler and the CPU will "do what you expect". I'll reiterate my suggestion to use the race detector. If it detects a race, then something is wrong (if it doesn't detect a race, then you might be ok but that's not guaranteed).
Only point I take issue with is &gt; This hasn't seen updates in a year, with the most recent actual code change being in September 2016 I've plenty of libraries that I haven't updated in a year or more (never mind 5 months) because they're _stable_ not abandoned.
Fair point. I was trying to connect that to the "there are no tests" to indicate that there are none incoming either but I suppose I could have phrased it better.
Oops :-)
We have gotten by quite happily on a very large scale with the standard library and a handful of Gorilla components. I suggest caution.
Misunderstanding on my end - when you wrote Raspbian I somehow implied also a Raspberry Pi hardware, that is, an ARM architecture. Lack of coffee I guess! As my tablet PC has an Intel Atom processor (and probaby does not have any of a Raspberry Pi's specific hardware features), I wonder if Raspbian has an advantage over other Linux distros there? My plan was to install something like Ubuntu or Debian and use the tiniest, resource-friendliest window manger I can find.
To be fair, most of these are probably just personal learning projects, and there is nothing wrong about learning.
[removed]
Also when it doubt you can use a site like https://mholt.github.io/json-to-go/ to generate a struct that is right for your JSON. For example [ { "type":"example", "data":{ "name":"abc", "labels":{ "key":"value" } }, "subsets":[ { "addresses":[ { "ip":"192.168.103.178" } ], "ports":[ { "port":80 } ] } ] } ] turns to type AutoGenerated []struct { Type string `json:"type"` Data struct { Name string `json:"name"` Labels struct { Key string `json:"key"` } `json:"labels"` } `json:"data"` Subsets []struct { Addresses []struct { IP string `json:"ip"` } `json:"addresses"` Ports []struct { Port int `json:"port"` } `json:"ports"` } `json:"subsets"` } You can then take that and change the anonymous structs to types in your code.
No, it needs a standard package management solution. There is missing standardization in just about every area outside of the standard library. You could as well have the webframework of the week, UI library attempt of the week, audio library of the week, package management library of the week, code generation library of the week etc... 
There actually is a standard package management tool: https://github.com/golang/dep. If you see people using other tools, it's only because they haven't updated yet. But I agree with your other points.
This can also be handy for building the boilerplate and then you simply customise (assuming you're using VSCode here of course): https://marketplace.visualstudio.com/items?itemName=quicktype.quicktype
Thanks for your answer :) it helped 
Thanks, I think I get it now the use cases
Go doesn't have RAII like Python (with statement) or C# so you need to manually close stuff to manage resources. defer is just a statement run before the function returns to the original stack, in reverse order. 
In the case of databases, it may be useful to know that you may not be closing the connection. Close may be returning a connection to the connection pool so that it can be used by something else.
Not sure if this can be shortened, but [here's an option](https://play.golang.org/p/0PLBonPTm9u) package main import ( "fmt" "strconv" "strings" ) func main() { input := "01010100 01100101 01110011 01110100" b := make([]byte, 0) for _, s := range strings.Fields(input) { n, _ := strconv.ParseUint(s, 2, 8) b = append(b, byte(n)) } fmt.Println(string(b)) } 
I don't know if you watched the video, but I talked about that, too! :-)
Thank you for sharing so much great content in 2017!
Thank you, had the same approach. I thought there is a native functions to do this kind of things. :-) [Here is my solution, based on yours.](https://play.golang.org/p/V1JPZ1zI8Pb) package main import ( "fmt" "regexp" "strconv" ) func main() { input := "01010100011001010111001101110100" r, _ := regexp.Compile("[0|1]{8}") match := r.FindAllString(input, -1) b := make([]byte, 0) for _, s := range match { n, _ := strconv.ParseUint(s, 2, 8) b = append(b, byte(n)) } fmt.Println(string(b)) } 
Can't help myself but smile seeing Dmitri's gymnastics to not say goroutines when he's listing Go advantages while making a case for GopherJS. Nice vid btw!
*be obvious, not clever* [Idiomatic Go tricks](http://go-talks.appspot.com/github.com/matryer/present/idiomatic-go-tricks/main.slide#28) 
Yes indeed I'm still writing on the first 3 chapters as soon as they are done I will share it here..
That seems like it would erase any error returned by the closure
Neat!
IMO if you want a helper, it makes more sense to have this helper: func Close(c io.Closer, err *error) { if e := c.Close(); *err == nil { *err = c.Close() } } f, err := os.Open("main.go") if err != nil { panic(err) } defer Close(f, &amp;err) Less indent, less callbacks, more idiomatic. But, honestly, just `defer f.Close()`. Most, if not all, Closers deal fine with having `Close` called twice. So in &gt;99% of cases there's no issue in doing something like f, err := os.Open(filename) if err != nil { return err } defer f.Close() if err := doThingWith(f); err != nil { return err } return f.Close() Which is clean, idiomatic code, does what it's supposed to and checks the error as expected.
Thanks, mate, dropped :D
…except that one always must handle errors when closing files *opened for writing.* Please see the `close(2)` manual page for more info. (Not that I find the OP's helper to be useful anyway.)
Golang Development is the preferred choice for many developers today and it supports native app development. 
&gt; …except that one always must handle errors when closing files opened for writing. My code does check the error. [edit] though it contained a mistake, in that I assigned `c.Close`, not e, which I now corrected \^\^[edit] (Also, `(*os.File).Close` does not call `close(2)` directly, but instead goes through the netpoller. Which is why it's safe to call it twice, AIUI)
That’s unfortunate 
Sounds a lot like npm and js land. 
It isn't necessarily wrong or right, it depends on what you are trying to do. `decoder.Token` will yield the first token in the stream, which in this case is the opening of a list. Then anything else you try to consume will be as if that token wasn't there. If you have a list that you _know_ has one element in it, which is what you really want to decode, then that is a fine solution in the real world of ugly JSON. However, bear in mind that with that approach you won't get any observable difference between `[{}]` (a list of one object) and `[{}, {}]` (a list of two objects); in both cases you'll skip the list open and decode the first object, and there will be no errors. In general after decoding the first object I'd call .Token again and verify that it is a closed list as I expect, and at least log a warning if it isn't what I expected. I would also verify that the first token _is_ the opening of a list before proceding and failing out if it is not. This technique has other uses as well. If you have a very long JSON document that is a list of smaller objects (just a lot of them), you can use this technique to pop off the list delimiter, then start iterating through the objects one at a time, instead of parsing the entire JSON file in one shot and marshaling all of the objects into RAM at once. Very useful stuff, in the right circumstances.
That's concerning. Looooads of my projects rely on this! 
Fork it and maintain it yourself 
Could do! 
Yeah, it would be better to try with those first and if it goes well, keep it up ;)
It will. To do this safely either requires the use of some sort of multierror-capable struct, or in the simplest way to do it, returning two errors. As it happens just yesterday a coworker and I were looking over some code where we had to have two separate error objects in a particular function, because we had a place that could generate an error, which would then require some cleanup which could itself fail, and we needed both errors farther down for proper handling (including, but non limited to, logging properly). It doesn't happen often in my experience but it definitely happens.
Note that there is a community fork recommended in the README now.
For those looking. I suggest reviewing [this fork](https://github.com/globalsign/mgo) and switching over to it if it meets your needs.
mongodb has announced it's working on a standard, supported driver... Mongodb for Go will hopefully get even better
That's good news. Though I'm fairly neutral on Mongo myself, I think this will be an important thing for Go considering how many people use Mongo.
&gt; That's concerning. Looooads of my projects rely on this! /u/ewanvalentine then loads of projects should have helped the author to keep going! It's all nice and fluffy to use free work from others. From those "Looooads" of projects relying on it, how come nobody yet contacted the author and said: Hey, we make "Looooads" of money thanks to your free work, here's some $$$ for your hard work for over 7 years.
I don't think that was the issue. Poke through the issue, and this comment in particular. [go-mgo/mgo#416](https://github.com/go-mgo/mgo/issues/416#issuecomment-316154091) They were looking for new maintainers in July.
I'm not sure if that was meant to sound snarky towards me directly people in general. I'm not disagreeing with the authors decision, I greatly appreciate everything he's done and fair play to him for doing this for the past 7 years. My comment was literally just thinking about alternatives because it's such a beautifully written library. It would be a shame to have to use something else. I hope no one took my comment as anything other that huge appreciation for this library and the work it took. I've never directly made any money from mgo, so unfortunately I have no money to pay the guy really. But I agree with the sentiment. 
Ahh cool! This is hopeful, such a well written library I hope it gets continued in this form 
It was directed to the general reader. The problem is that far too often people just take things for granted and don't think of repaying individual open-source developers for their hard work.
Context is the canonical example of Go maintainers trying to solve something that should be solved at the language level in user land. Just like sync.Map . "But but you are using it wrong!" well, it is exposed to me as a library, if it was baked in the language i wouldn't be able to "use it wrong". 
I'm guessing it will. bolt transitioned to coreos/bbolt pretty smoothly, and mgo is larger than bolt in terms of community.
Sure, and having an attitude about it when the dev volunteered their time is also not cool. I certainly understand the frustration and wish I could support every package I use but it's not fair to blame everyone.
Is the slide deck available somewhere?
Interesting. Maybe `io.Reader` has turned out to be the wrong abstraction, and Go should have had some thing like `Read(buf []byte, deadline *time.Time, abort chan struct{})` instead… 
Lol you serious? If you want people to pay you for your work don’t release it under a BSD license. You release under BSD to increase your reputation. I’m sure anyone would hire the guy who wrote mgo.
Maybe in go2 it will be done as part of the language. It wasn't for go1, so they came up with something to enable the needed behavior. How is this a criticism?
I do all my user input validation with https://github.com/go-ozzo/ozzo-validation
Kudos for this guy maintaining it for so long, especially as he stopped using it himself a while back.
I was under the impression that [`flag.FlagSet`](https://golang.org/pkg/flag/#FlagSet) already allowed to create subcommands.
I've been wondering if these changes will affect Caddy. Anyone know? I don't see anything in their issue tracker.
&gt; It was directed to the general reader You literally started your comment with his username lol
`Read(context.Context, []byte)`. Has been suggested before.
I'm not familiar with the Caddy codebase, but there's a [flag](https://github.com/mholt/caddy/blob/97710ced7ea5b5d8025dc6a3e43d82e9a280920e/caddy/caddymain/run.go#L47) to disable tls-sni-challenge (the one disabled by Let's Encrypt), so I would assume that it would fallback to the http-challenge.
Linked here for convenience: https://golang.org/issue/20280
I agree. The close error is prioritised before the closure, maybe some error wrapping would solve this. Note that I don't write code like this often, it was just an inspiration when reading through some python docs. (especially the with statement).
This seems too complex to exist alongside Go's "simplicity" guarantee. I really hate this whole "context on everything" push we're seeing recently, for all the reasons that have already been beaten to death. Needing to cancel some operation midway through is an advanced operation. Go has existed for years with it as an ancillary feature in support libraries, but now its creeping into the standard library, and then into every third-party library you consume. The official GCP library is already full of disgusting boilerplate because of it. Go2 needs to add it to the language itself. I don't know what that implementation will look like, but I feel that cancellation propagation is the single most important thing to get into Go2. 
We maintain a fork at Lyft http://github.com/lyft/mgo
Major CTA: Stop using MongoDB?
And for least clear code of the day: package main import ( "fmt" ) func main() { input := "01010100011001010111001101110100" b := []byte(input) a := make([]byte, (len(b)/8)+ len(b)%8 - int(uint(len(b)%8 - 1))) for i := 0; i &lt; len(b); i++ { a[i/8] |= ((b[i] - 48) &lt;&lt; uint(7-i%8)) } fmt.Println(string(a)) }
I've seen elsewhere that Caddy alternates, trying to pass either http-01 or tls-sni-01 each time, and since it tries dozens of times in total before your certificate expires this should achieve a renewal in practice always. Telling it specifically that it can't pass tls-sni-01 any more should speed up renewal, and if you know you can't pass http-01 (e.g. port 80 is firewalled by your service provider) then that would make it obvious you need to Do Something. Caddy's existing behaviour was a bit dumb, the ACME server is saying "Hey, pass one of these challenges" and Caddy was blindly replying "I'll do *this* one," without reading the list from the server. I've seen that with crappy SSH implementations in the past ("Hey, try interactive or public key" "OK, I chose hostbased" "Bzzzt. Try again, interactive or public key?" "hostbased?" "Bzzt" etcetera) and I hope Caddy fixes it.
The (good) argument that was made is that context is the theoretical dual to error returns - so the philosophy of passing context explicitly is dual to the philosophy of passing errors explicitly. It has also been pointed out, that the explicit passing of context means, that it is more obvious/intentional/clear what you are doing when you *don't* want the cancellation to be inherited - e.g. when passing closures/function pointers through a channel or when dispatching a background task that should survive the current request. I'm not terribly convinced either way, but I think these are good enough arguments to make "it has to be a language feature" anything but a foregone conclusion.
http://reddit.com/r/golang/comments/7pd93d/xcryptoacmeautocert_package_is_broken_because/dshu0bj
Where are examples of how to use upload a file to Azure Storage? (whatever the S3 equivalent is)
❤️
Having someone tell you that you've done a good job is also nice.
It does not. https://twitter.com/caddyserver/status/951582247299170304
That flag is not needed relative to this change.
That's actually a common misconception. It's almost never useful to check the result of `Close()` in Go code (or in other languages for that matter). Here's why: if you care at all about whether or not a file has been written to the disk correctly, you *must* call `Sync()` before calling `Close()`. Because the OS might try writing a file to the disk after `Close()` is called, and it could then fail, and you'd have no way of knowing. I can see why someone would get the opposite impression from Linux's man page for `close(2)`. It explains that the error result from `close` is not what you need if you actually care about the error in the first paragraph of the NOTES section, but then it goes on to say in a semi-condescending way that _careful_ programmers always check the result of `close(2)`, nearly contradicting itself in a few places.
I've been watching that. I do sympathize with the certbot devs, since despite their best efforts, there is an uncontrollable, inevitable mob reaction that nobody really deserves -- especially competent, paid developers such as themselves. Lots of virtual programmer hugs going out to their team this week!
Do you try pragma noescape to avoid escaping the int64 from the stack to heap for your assembly abs? 
Branch prediction
I have switched to this driver and I’m completely happy. No code changes and improved performance with new MongoDB server. 
This is unfortunate but understandable. Gustavo did an amazing job with the `mgo` project. I remember in the earlier days of Go, we might not have packages for certain things but we always had a MongoDB driver thanks to Gustavo. In this case I blame the Mongo company. Why in all those years did they not release an official driver for Go? I guess it's convenient for them to have open source developers do the work for free eh? In any case, I do hope they will step in after this announcement. It's always delightful to see official support for Go by companies.
This is one of the few occasions when Scanf (actually Sscanf) is worthwhile. https://play.golang.org/p/EhhBfcaqA9b
Given [the benchmark code](https://github.com/cavaliercoder/go-abs/blob/82d52854fd17c96382cacba740db56bbac3ece96/abs_test.go#L51-L72) is passing in the same input repeatedly, I think this is exactly what is happening. It would be interesting to see the branching/non-branching versions compared against random inputs.
Thanks for correcting me on that.
https://engineering.mongodb.com/post/considering-the-community-effects-of-introducing-an-official-golang-mongodb-driver as found on /r/mongodb 
Here's a sneak peek of /r/mongodb using the [top posts](https://np.reddit.com/r/mongodb/top/?sort=top&amp;t=year) of the year! \#1: [MongoDB Basics "Cheat Sheet"](https://mo.github.io/2017/01/18/mongo-db-basics.html) | [0 comments](https://np.reddit.com/r/mongodb/comments/5os7ii/mongodb_basics_cheat_sheet/) \#2: [New Driver Features for MongoDB 3.6](https://emptysqua.re/blog/driver-features-for-mongodb-3-6/) | [1 comment](https://np.reddit.com/r/mongodb/comments/6j0jzf/new_driver_features_for_mongodb_36/) \#3: [MongoDB 3.6 adds support for JSON Schema Validation](https://www.mongodb.com/blog/post/mongodb-36-json-schema-validation-expressive-query-syntax) | [0 comments](https://np.reddit.com/r/mongodb/comments/7kvqns/mongodb_36_adds_support_for_json_schema_validation/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/7o7jnj/blacklist/)
There's some issues with this repository. The ones I can see off the top of my head: * `go get github.com/dragonzurfer/quickchat` doesn't work. Yields the error: `package quickchat/database: unrecognized import path "quickchat/database" (import path does not begin with hostname)` * It is generally discouraged to commit the compiled binaries into your repository. It unnecessarily bloats the repo and few people will be able to use it anyways, as it is most likely not compiled for their platform.
Great question! I didn't at the time of writing, though now I have researched a little and added this to the code. I'm not convinced it is needed, as no variables are declared in the function body that could escape, and the int64 is passed by value. Still, I'm not sure how to validate this, so will err on the side of caution.
for those looking for code sample on how to use http-01 challenge, I've have updated my blogpost to use latest autocert update: https://goenning.net/2017/11/08/free-and-automated-ssl-certificates-with-go/ spoiler: it's one line go http.ListenAndServe(":80", certManager.HTTPHandler(nil))
Couldn't you unroll it to avoid rng overhead? Simply generate a massive list of random numbers ahead of time and hard coded as a variable.
https://github.com/Azure-Samples/azure-sdk-for-go-samples/tree/master/storage please open an issue in the repo if you need more!
All this is missing is some mobile app so that I can access these on the go. Though is having the TOTP generator on your machine really 2FA anymore?
Check out [https://golanglibs.com](https://golanglibs.com). There are a couple CMS listed.
If you know any programming at all, you should just be able to go through the official go tour. If you don't know anything, look at code academy.
Many opensource ones too. Thanks! 
You can try [this](https://learn-anything.xyz/1601). It shows what the community thinks the best way to learn Go is as well as any other topic out there. I personally used [Go Tour](https://tour.golang.org/welcome/1), read [Effective Go](https://golang.org/doc/effective_go.html) and tried to build things.
IMHO, Ponzu is one of the most interesting ones.
&gt; Sometimes code looks cleaner when variable declarations are listed after code that uses them. Please, no!
I too just started. I intend to do the Go Tour in full, most of the way through now, and I also plan to read Effective Go. I'll be supplementing with any other resources in this thread and also [hackr.io](https://hackr.io/tutorials/learn-golang)
It comes to no surprise but I'm glad that it's official now. I don't know if Gustavo is lurking on reddit, I've seen him help users on stackoverflow and google forum, but I'd like to thank him for everything he's done and for his incredible drivers.
1 line code ...and I can remove my own TLS redirect. good :D.
I actually just started a “learning Go” series of YouTube videos. Only have a few right now but trying to add a couple new ones a week. Not sure if it’s useful for anyone else, but thought I would contribute back to the Go community in some way. Producing those videos is harder than I thought it would be. As it turns out, keeping sentences together without using “um” every other word is hard for me. Here’s the link to my channel if you’re interested. I’m still pretty new at producing rather than consuming YouTube content: https://www.youtube.com/channel/UCCJp8cZq-w9T63UoZp8aA2w 
Remember that it's not about New methods, if you want that go with c#. If you want new packages, go with js. If you want to learn something that has the longest reuse life span of both and you are tired of the churn and burn then go with go. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
Now I'm just imagining if r/wholesomememes did form validation. "That's a really great username! Good job! Have a great day!"
Everything about this is terrible.
Why the heckin does Go’s abs not accept int64 input?
"I need to be more trusting and slightly less hardcore." I think that's the most sound advice I've seen written in a long while. Lots of devs think they're smarter than a compiler - and that's absolutely true in some cases - but dismiss the hard work some great minds put into making a good program to let you get work done. Really nice article, my Go studies should get a leg up just by hanging around this sub.
[removed]
The official answer is that its waiting for generics.
Woah! Thanks for sharing. Didn't expect the compiler modification to be that straightforward. Did you find helpful docs or did you end up reading the existing code to learn about the stmt declaration lifting? 
I don't think op is proposing this change to the compiler... lol it's not that easy to come up with demonstrable changes that can be implemented in a few blocks of code for a quick blog post! 
Modern branch prediction is more complicated: https://danluu.com/branch-prediction/
I love stuff like this.
Thanks for saying so - I'm its main author, would love to hear what you think; good &amp; bad. I'm at a point with it where the plugin / addon system is the last mile before committing to a 1.0 release so all feedback is welcome 
Thanks for the interest! The modification was indeed small. I was very shocked at how quickly I went from never touching the compiler source to having a working example. I started with looking through the code thinking at some point I'd need to look up some docs, but I never actually needed any documentation; the compiler (at least the parts I read) is very clear and easy to understand. I think types and good variable naming makes a parser (such as Go's) easy to grasp.
Correct! This is not a proposal :) Just a very quick dive into the compiler which I thought I'd document.
&gt; This year, I thought I'll learn Go with a year-long side project. If your goal is to learn Go I would suggest to pick a smaller/less complex project. A CMS can become quite complex depending on how generic you want to make it. It also involves a lot of other things (HTML, JS, CSS etc.). If you still decide to go with a CMS I'd suggest to focus on creating a MVP and then iterate on that.
Then your benchmark is likely to be limited on memory bandwidth rather than CPU.
Small nit, but this sort of code path seems like a strong candidate for speculative execution (on processors which support it) which would remain unaffected by random inputs.
Go tool chain has escape [analysis tooling](https://gist.github.com/cstockton/6933ae5dadcb07354159300ed6e9b085#file-go_aliases-sh-L138) you can invoke pretty easily.
Speculative execution as well. To test this properly one would need to be testing on a machine that lacks a lot of modern CPU features
Nice
You're in luck, Golang has some of the best resources and documentation for beginners. Once you get your feet on the ground I'd reccommend following Dave Cheney and Rob Pike on twitter. They're always full of programming wisdom and I believe Dave writes Go articles here and there. Also, if you use vim/neovim get vim-go, written my Fatih Aslan. Literally the best plugin for Go development **ever**
This is a great post! Anyone flipping out about polluting the language is missing the point.
this
first, Go 2 is coming, which is not predicated on the Go 1 compatibility guarantee. second, this is a short tutorial showing how the Go compiler could be contributed to. `andwhere` is not a feature that is likely to ever be part of *any* official Go compiler.
1. Implement generics 1.??? 1. Profit
Suggest not using this. Instead of using a KDF it is just padding the passphrase with '=' to 16/24/32 bytes, which is crazy easy to bruteforce, making the plaintext of your password recoverable and the encryption pretty worthless. Agree with other comment that 2FA on same device is not 2FA.
&gt; first Based on what the Go team have been publishing over the past few years, I would say Go 2 is *not* really coming. &gt; second Although the OP commented *"I was very shocked at how quickly I went from never touching the compiler source to having a working example"*, the actual blog post didn't have this tone, but was presented as a way to modify the Go gc compiler. I was pointing out in a top-level comment why this doesn't work. &gt; third, and most importantly *huh?* &gt; EDIT I didn't downvote you, nor do I downvote very often -- I prefer reply comments. 
The title to the post says *"A short guide to adding a keyword to go"* and that's exactly what it describes. No other point is made. This change wouldn't *pollute* the language, it would *break* it because the following code would no longer work: package main import "fmt" func main() { andwhere := 7 fmt.Println(andwhere) } 
Nice, that's great, people should be hacking that compiler and experiment at will.
I thought The Go Programming Language was excellent. It gave me a good solid start.
I mean it's still something you know and something you have. If this is not 2FA then having the authenticator on your phone is not 2FA. Depends what threat model you have. If you expect to have someone hack into your computer then don't use this, but that's not how most passwords get found. 
Totally agree - so much if the toolchain and stdlib code is well written that looking up more than the execution path is usually unnecessary. Props to the Go team for that!
Short answer: "too difficult". Note that not even gcc will inline functions written in assembly, although it does have the inline assembly keyword and also compiler intrinsics.
Correct me, but I suspect abs int64 is one line of code, an x86_64 primitive, that deserves a Go call.
A simple twister then? 
Thanks, I should have mentioned I'm a software engineer by trade. 
File a proposal.
Go 2 [*is* coming](https://blog.golang.org/toward-go2). This is only one of many blog posts from the past 6 months from Go core contributors which have cemented that reality. Even the very first sentence of that article is worth quoting: &gt; [...] asking for the entire Go community's help as we discuss and plan Go 2. There are issues [like this one](https://github.com/golang/go/issues/19623) that are clearly not compatible with Go 1, and they are marked with a `Go2` tag. That one is from Rob Pike, so it's not idle discussion.
Love what you do man!!
Also urfave/cli is quite popular.
First of all, thank you for the great work. I love the idea of being headless and also the support for Let's Encrypt out of the box. The single binary deployment is also one of my favourite features. It makes everything so much easier. I evaluated it briefly last summer for a project and there were a couple of things that stopped me from using it: * it does not support OpenAPI/Swagger, which I think is kind of hard to implement as it does not use REST. The idea behind OpenAPI was to let the users know what kind of data can be manipulated with Ponzu CMS. Meanwhile, I think the support for GraphQL is a necessity. That would really give Ponzu CMS a boost in acceptance, usage, popularity and so on. * while using an embedded DB for development is very practical, for production there should be support for other kinds of RDBMS and NoSQL databases. Perhaps I overlooked something, otherwise adding the points that I mentioned above to the feature list would be really great. 
Yeah. One of the reasons I want to learn Go is that it's not Java. I'm so used to thinking in a convoluted way about design now that I'm hoping Go will clear it up for me :)
There is almost no **strong** reasoning. I just felt like learning a language and really want to build my own CMS for my website, becuase I've spent much of the last year fighting with Wordpress :)
After going through the 'Tour of Go' I recommend looking at the '50 Shades of Golang' post. Then take a look at the 'Go Project Layout' post on Medium. Don't be afraid to start coding right after ;) Read other resources as you need them.
Yeh I've started looking up the source of Ponzu. It has some interesting options for sure. There's another one called Fragmenta which seems interesting as well. 
I thought this episode might be of use more generally to the go community, as getting C binding packages set up in windows can be quite mysterious to people new to the ecosystem. This covers how to get mingq/GCC installed and configured, how to add the sdl libraries to mingw, how to grab the bindings package, and get a basic window open with some pixels drawn in it. Linux is also covered a tiny bit, but the process is really pretty easy there anyway. 
Thanks for the advice! Astaxie's book looks quite good! I'm thinking of this as a long-term side project, so no problem if it's a little complex. The goal is to transfer my current WP travel site (not many dynamic things happening there) into this newly created CMS. I was going to use Jekyll, but then I thought why not write my own. A Jekyll-like thing, which is basically a bloggy-CMS that builds static sites and serves them is kind of what I'm thinking of for an MVP
I don't think it would be quite as simple to make this change as the one in the blog since (if keeping with the existing semantics) the where keyword introduces a new block of code, instead of simply adding statements to the beginning of the code block. b and c, or any other temporary definitions in the block, shouldn't be visible before or after this statement.
I recommend http://learnyousomeerlang.com/
I used the same resources and also https://www.golang-book.com/books/intro for its chapters 8 to 12, which are in my opinion more readable than the tour + the specification.
I did spot the PABS family of instructions as part of SSE3, though I don't have the chops to extend the assembler to support these.
I couldn't fall asleep so I started googling again. It seems that the reason was due to systemd. It has nothing to do with go. All I had to do was to add: KillMode=process into service definition. systemd kills spawned children by default when the main process dies.. Now I really need some sleep :D
Any tips on how to prevent the compiler from invalidating the benchmarks? Does the same issue manifest on your benchmarks for fastrand?
I think it's possible to do that but is going to be trickier and harder than maintaining a constant pool of workers pull work from a channel. 
Yea systemd has its quirks. Glad that you had it resolved.
I still have setsid and pdeathsig but I am quite convinced that this is unnecesary. Apart from these, it is a perfectly ordinary sudo call, without any ampersands and what have you. I'll reply again tomorrow as I turned off the machine and I want to sleep a bit (have been debugging this for at least 5 hours :D)
Cool, get some sleep and keep me posted! I'm curious what you discover.
Cool, get some sleep and keep me posted! I'm curious what you discover.
Ah yes, it does. That code is old, from before the SSA backend came along with improved optimization passes and program analysis and broke almost all the benchmarks. The current "best practice" is to save the result to a package global. var sink int func BenchmarkThing(b *testing.B) { for i := 0; i &lt; b.N; i++ { sink += thing() } }
With the slice be careful not to be benchmarking allocation instead. You'll also have a much larger increase in memory bandwidth which, depending on what you're testing, could alter results.
Does that apply even if you preallocate the slice then reset the benchmark timer before doing the actual work?
Less so, but yes. Filling up your CPU cache with pointless data will flush more useful things out giving you unrepresentative numbers (unless you're trying to benchmark behaviour with a contended cache...) . And it still means that you're allocating a huge chunk of memory that might cause the garbage collector to run during your benchmark that will also affect the performance reported.
1. Download the new binary to $name.new, check it's ok. 2. mv $name.new $name 3. Stop. Systemd should restart the service.
Lol I posted mine 40 minutes before you but I got downvoted, I want my one point back it takes me around 2 comments to earn that much :D
If it's static and you could use Jekyll for it, then you could try [Hugo](https://gohugo.io/) which is written in Go.
I mean, standard in the sense of the core devs/tools supporting it, not standard in the sense of an "official experiment that might become standard or not". Why is it taking so long to develop dep? Because it has to respect all the quirks of current dependency "management" (gopath, vanity imports, vendor directory and what not) instead of solving it at the root (import directive and go get). Dep will be a fragile tool with lots of bugs and edge cases because of the complexity it tries to solve. It is a dead born baby. Not simple, not elegant and not reliable.
The first thing that comes to mind is to not write the service as a `for {}`; write it as just one iteration, and use a systemd `.timer` unit to do the for. Then the next time the timer fires, it'll run whatever the binary is. My next thought is, why stop the service before replacing the binary? Surely you can do that in the other order? Then all you need to do is quit, and systemd will start you again. As to _why_ your child process is getting killed, that might be for a number of reasons. Does it also happen when not running under systemd, for example?
Its funny how there are some people who take this waaaaaay too serious. Anyone with a little brain clearly should see the purpose of the post was educational and not a proposal. And this is seen before reading comments. "this post should have different title" some people might claim? But why? The title never said "Proposal" so don't make up things and start screaming "this won't ever make it, this is bad". I personally greatly appreciate such attempts to figure out how modifications of certain kind could be done. A specific task, without everything around it. "how can I make one specific code block compile with my new change". It gives very good initial overview of things. Anyways, kudos for posting this :) I enjoyed reading it. 
This should be the accepted answer.
ah, that is a very nice tip (about timer), thank you very much! as I understand, systemd won't fire the service one more time until the first spawned process finishes? why stop the service before replacing the binary - well because unless I do that, linux gives me an error that 'text file is busy'. when I stop the service, I can copy the file. why the child process is getting killed - this was purely due to KillMode default setting (which is control-group)
thank you so much for the elaborated answer! In fact, I think that I have already made the code in a way you suggested, but due to late hour yesterday and thinking too narrow I wasn't able to spot it ;) Basically, the updater and the 'main' program is the same program. The updater part is executed when you invoke the program with a -u argument. So you could look at it in a way that the thing which is executed by systemd is just the downloader - i.e. a progam which checks if there is a new version of the binary, then downloads it and executes it. So even though in my case they are *located* in the same binary, that's actually irrelevant. Because, even if in n+1 release the updater code changes, the downloader part won't. So I can fire my updater without ever stopping the downlodaer systemd. I'm sorry, it probably makes no sense but that's the best way I can explain it
ah! you're doing it wrong: don't modify the executable *in place*. If you have a problem mid-modification (the download is interrupted, or any other thing), you'll end up with an unusable binary. Download it to a different file in the same directory, and then rename it. That shouldn't give you the 'text file busy' error, and if you sync the file before the rename, and the directory after, you'll be safe from a host of issues.
You really should use more meaningful variable names for example `a := os.Args[1:]` would be better as something like arguments, args or something. And if I'm seeing this correctly: you want to get two arguments, without but only pass one to the server function. the
maybe epris could mean stuff like having an apt repository or a rpm repo ? I'm just guessing. depending on the system, you could even write hooks which execute before system stop, after start, etc. (at least that's what I ocassionaly see on systems which update systemd services :D)
No. A package can have no imports but still do unsafe things using assembler code. Side note: `grep` won't help anyway, use `go list`.
Ok. I removed setsid and pdeathsig and everything still works the same ;) Although I believe that this whole thing can be solved easier - please see the first answer (About mv + systemd respawning the service)
I was actually under the impression, that Go code more often than not uses very short und undescriptive variable names (a, r, bs etc.). Thanks for the feedback though, I agree very much with you. As for your second point, the second argument gets not read by the main() function but rather randomQuote(). This is one thing where I would like more feedback for example? Is it better to pass this argument through three functions while only needed in the last of them or is it better to access it directly where needed?
I would suggest to read this varibale inside your `main` function and pass it to your functions as needed. Because then you have all side effects (in this case, user input) only inside your `main` function and not overall in your code base
Something like this help? https://github.com/inconshreveable/go-update
Tiny thing, but from most code I've read - func main is usually at the top (also arranging your functions in order of execution is useful for people reading the code)
I guess a symlink would also work?
Thanks!
Symlink pointing to where? Shouldn't overwrite the old binary till we checked that the new is complete and working.
&gt; I was actually under the impression, that Go code more often than not uses very short und undescriptive variable names (a, r, bs etc.). I see where you're coming from, but as far as I can tell, the go standard library usually has abbreviated variable names. It's not just random. A good example is [`strings.EqualFold`](https://golang.org/src/strings/strings.go?s=22754:22786#L864).
Thats what I was thinking off when I wrote the code. My variable names are also (heavily) abbreviated, but not randomly chosen. I guess one has to find a middleground there?
That's usually the problem, yes. I tend to go for half-abbreviations so that you can still understand what the variable contains when randomly stumbling on it, without it being overly long.
Well i was thinking you have a binaryname-releases/binary-1.0 nnd binaryname-releases/binary-2.0 - when you need to upgrade/downgrade, just run a command ln -sf binaryname-releases/binary-$VERSION /target/dir/binary
This is one of the rare places where systemd shines. If I was to write a golang service, i'd use systemd [socket activation](http://0pointer.de/blog/projects/socket-activation.html). This allows the service to stay up during upgrade and is basically inetd on steroids. There's example code: https://github.com/coreos/go-systemd as well as a bit of background information. http://0pointer.de/blog/projects/socket-activation.html Thanks for reminding me, I need to have a play with this stuff!
**If I were**
There are also [data races](https://research.swtch.com/gorace) which can be used to implement any unsafe operations you want. If you want to isolate Go code, use [nacl](https://github.com/golang/go/wiki/NativeClient), it's what the playground is running on.
For Limited time anyways. I'm not affiliated with them but I know what go books I'm reading today! 
I was curious to see what a different compiler would make from this. push rbp mov rbp, rsp mov rax, rdi ; make a copy of the number (rdi) into rax neg rax ; same as "sub 0, rax" - sets the carry flag, see below cmovl rax, rdi ; if carry flag is set, rdi was already positive, so move it into rax. pop rbp ret ; return rax The `neg` operation does the same as the "TwosComplement" function in the Go example, but in one instruction, instead of five. If rax was positive, the number in rax will now be negative. But we have a backup of the number in rdi. Now, `neg rax` is the same as `sub 0, rax`. If we have an operation that is `a &lt; b` and we do `a - b`, it will set the carry flag to 1. Meaning if we do `neg rax` and `rax` is positive, it will set the carry flag. This way we know that the number was positive (and is now negative, because neg replaces the number with the inverse). At least that is my explanation of the assembly. I did not performance-benchmark it, but I can imagine that one instruction is faster than several movq and xorq calls.
Yes, you start the updater in a different process group.
Sometimes writing tests will teach you to write better code. Take your `randomQuote` function for example: func randomQuote() ([]byte, error) { bs, err := ioutil.ReadFile(os.Args[2]) if err != nil { fmt.Println(err) return nil, err } q := strings.Split(string(bs), "\n") r := rand.Intn(len(q) - 1) return []byte(q[r]), nil } It has three problems: 1. it depends on `os.Args` 2. it depends on reading from a file 3. it depends on randomness You can easily solve 1. if you pass a string instead of calling `os.Args` from inside the function and have something like this: `func randomQuote(file string)` But how would you test that? You would need to create a temporary test file on disk, pass that as an argument to your function and delete the file after the test finishes. If you need to do all those things to test your function, it's a sign that there might be something wrong. Wouldn't it be better if the function could just read from an arbitrary source? I suggest you to read [SOLID Go Design](https://dave.cheney.net/2016/08/20/solid-go-design) more specifically for this case the "Interface Segregation Principle". By passing an `io.Reader` to your function it becomes much more general and flexible since it can read from any source `func randomQuote(r io.Reader)` while the responsibility for opening the file goes to the caller. With this change 2. is solved since all you need to do in your test file is something like this: `r := strings.NewReader("quote 1\nquote2")` Testing for randomness is trickier and a whole subject on itself. The simplest thing you could do to solve 3. is to just pass the seed as an argument which will guarantee the same results for the same seed and have a function like this: `func randomQuote2(r io.Reader, seed int64) ([]byte, error)` You can take this even further. The function has a "hidden problem". It depends on the format of the input which could be a good or a bad thing. You could eliminate that and make your function more "strongly typed" by just passing in the quotes directly. This would mean that nothing can go wrong in your function (no errors) and it would be simplified to this: `func randomQuote3(quotes []string, seed int64) []byte` Of course with all these changes, a lot of the work (opening file, reading, splitting) is moved to the callers and the implementation of `randomQuote3` comes down to 1-3 lines and by that point maybe it shouldn't even be a function. I am not saying that you should go this far but it is good food for thought. In order to easily test your function, `randomQuote2` shows the least amount of changes you need to do and it is probably where you should stop. [Example implementations.](https://play.golang.org/p/hdoSu_7rpwB)
https://golang.org/pkg/strconv/#ParseUint
the go style guide mentions using short, abbreviated variable names like this. it's one of the many things I disagree with about Go style, and actively ignore.
Wow, thanks a lot for the detailed feedback! Really appreciate it! The idea to pass an `io.Reader` is great! 
Ah okay, that’s good to hear. I stand corrected there. I like that.
No matter what there is always a better solution than arbitrary code execution. This is a XY problem though given your description, since it is impossible to require code execution as you described it. This is because given the constraints of **no imports** and the function signature: func F(map[string]string) map[string]string { ... } F must use a deterministic algorithm, since it is a deterministic algorithm it can be represented in a finite state machine. Since it can be represented by a finite state machine it could be represented by a graph. Since it can be represented by a graph it may be represented by a structured encoding. So you could create a library that allows a user to give it source, and generate the encoded schema. This is actually a much simpler effort in Go than it sounds since the [go](https://golang.org/pkg/go/) package provides a powerful set of libraries to prove the source meets your constraints. For example: - Declare your function as F(in, out map..) so you don't need to allow them to call the make() built in. - Declare a numerical constant of Length that is always the size of the in param of F. - Blacklist all statements and expressions. - Allow a for statement in the form of for i := 0; i &lt; Length; i++ - Allow the minimal expressions with well defined bounds until you are satisfied. It's more work sure, but under no case would I suggest you execute arbitrary code even under nacl, unless you understand all the potential attack vectors that remain. For example no matter what you set as upper bounds for system resources, the potential for exhaustion through busy loops or allocations will always be susceptible to denial of service. This is mitigated for golang.org because it lives within Google IP space so is protected by a 600 billion dollar tech giant. Attacking them is futile so they don't need to even quantify the risk of DDoS.
for {}
This is really cool, thanks a lot for doing this. I'd been looking at using sdl2 recently but had no clear path for learning it, so I'll be mooching off your expertise!
Ty this course https://www.udemy.com/go-the-complete-developers-guide
Just focusing on the server func here, but you can apply a lot of this feedback to your other functions. func server(port string) { server doesn't return an error. You will pass any errors generated internally to fmt.Println, but that's not desirable in practice and handling errors like this, deep within your code, leads to bad design patterns. In general, always pass errors back up to the caller. Even if they just get passed back up to something in main. In general, let the caller handle an error. Also, fmt.* functions aren't the best place to handle errors, take a look at the log package and log errors using it. Rather than take a port in as a string, which limits you to tcp only, why not take in a net.Listener interface? Now your server works with unix domain sockets or anything else! Plus it's one less error path to handle within Server. It also makes your code more testable, as you can give any struct that emulates a net.Listener, which makes mocking out requests way easier. Here is what I'd suggest this look like: func server(ln net.Listener) error { for { c, err := ln.Accept() if err != nil { return err // There is no obvious way to recover, so return err. } // Now use a goroutine to call handler, and if there is an error, log it. go func() { if err := handler(c); err != nil { log.Printf("On request from %v handler returned: %v", c.RemoteAddr(), err) } }() } } 
This is a very good review, thanks
You need &lt;servicename&gt;.path and systemctl-restart@.service. &lt;servicename&gt;.path will watch if binary changed and restart the service based on service name, ``` [Unit] Description="Watch {{ service_bin }}" [Path] PathChanged={{ service_bin }} Unit=systemctl-restart@%p.service [Install] WantedBy=multi-user.target ``` systemctl-restart@.service, ``` [Unit] Description=systemctl-restart@%i [Service] Type=simple ExecStart=/bin/systemctl restart %i ```
That’s quite a list. I could have used some more examples in net/http a few months ago. Maybe I’ll take a crack at that next weekend. 
This works as well mask := -(x &gt;&gt; 63) return (x + mask) ^ mask
I’ve been waiting for this series to get into making games using sdl2 so it’s nice to see this since it means I can probably start watching it soon. I got as far as using the sdl2 and OpenGL binding together in the past to create a first person style camera that can fly around a small space. For model imports I just built assimp and called some of its functions with cgo. Do you plan on going that far with this series or will you stick with simple 2D games?
Good suggestion! I'll have to remember it, I like plush on the first view. I have been recommending [slinso/egon](https://github.com/SlinSo/egon) even in the recent past with the caveat about compiling it, but plush seems a good runtime replacement.
strictly, you must do this db, err := gorm.Open("sqlite3", "/tmp/gorm.db") if err != nil { // error handling } defer db.Close() 
Method 3 is not a race
Seems like a great way to learn more about what's in the stdlib, too.
Awesome thanks! I've incorporated your feedback into the benchmarks. I'm seeing slightly different results (less favourably for the branching approach), though the results are consistent between runs. Are there any other variables lurking in my approach that could be skewing the results? https://github.com/cavaliercoder/go-abs/blob/master/abs_test.go
You need to print the `err` variable. That contains the details about the failure.
Yes, this works too! Though the compiler output is a little longer, so performance takes a mild hit: TEXT ·WithTwosComplement(SB) MOVQ n+0(FP), AX MOVQ AX, CX SHRQ $63, AX MOVQ AX, DX NEGQ AX SUBQ DX, CX XORQ AX, CX MOVQ CX, ret+8(FP) RET There are also two other approaches listed in Hacker's Delight.
[removed]
LGTM. As the rng is not zero cost, maybe as a baseline benchmark consisrit of just adding up the rng output so we can see the incremental cost of each of the approaches.
Great idea. Done. $ go test -bench=. goos: darwin goarch: amd64 pkg: github.com/cavaliercoder/go-abs BenchmarkRand-8 500000000 3.26 ns/op BenchmarkWithBranch-8 200000000 6.57 ns/op BenchmarkWithStdLib-8 200000000 7.67 ns/op BenchmarkWithTwosComplement-8 500000000 3.42 ns/op BenchmarkWithASM-8 500000000 3.71 ns/op PASS ok github.com/cavaliercoder/go-abs 10.552s I notice WithBranch and WithStdLib have ballooned to ~3ns after the RNG runs. The random inputs seem to have had a marked impact.
Very cool!
On mobile so didn’t watch all but some interesting points that relate to some of the best practices in go. This idea of being clear with flow of control with if else statements instead of multiple if statements brings to mind go’s way of handling errors and returning early in preference to nested code. It doesn’t quite follow that example but I feel has it’s own merit/reasoning behind it.
&gt; sometimes dynamic languages feel too magic and the hidden stuff can confuse beginners. Plus, the lack of static typing can cause obvious programming errors to go unnoticed by the compiler and come back and haunt you at run time, by causing unexpected behavior that is hard to track down.
&gt; it's still something you know and something you have. But it's not something that *only* you have, if the token generator runs on the same computer that you use to log in to the service. An attacker who captures your computer can get your password via keyboard logger and the 2FA token via the token generator. This is the same as having no 2FA at all. Only if you have the token generator on a different device, this scenario cannot happen. The attacker would then also gain control over the device where the token generator resides.
I like it. Thanks for building it! I especially like the `jobber list` and `jobber log` commands, which is something crontab sorely lacks, imo. One suggestion might be to add some examples of notifications. The sample config has a `/home/foobar/notify.sh` or something, but there's not really much of an idea of what that might look like. Alternatively, it would be great if it could log errors to disk somewhere.
Or you know, systemd-timers /Me shrugs
I can recommend you this pattern: func main() { if err := run(); err != nil { fmt.Fprintf(os.Stderr, "Error: %v", err) // or log.Fatal os.Exit(1) } } // like main but returns error func run() error { file, err := os.Create(info) if err != nil { return fmt.Errorf("creating file for info: %v", err) } defer file.Close() // more work } There's two things to pay attention to on the code above. 1. os.Exit and log.Fatal [do not let deferred functions run](https://golang.org/pkg/os/#Exit) 2. putting context to your errors with fmt.Errorf (or errors.New) By using this pattern you deal with 1 because your `run` function will simply return an error (and normally call the deferred functions) ensuring the file will close. This pattern avoids the common pitfall of `os.Exit` and makes your main code work like the rest of your code (returning errors). It is a good practice to ["decorate" the errors you return with extra information](https://blog.golang.org/error-handling-and-go) so that you know why and where the error happened by reading one line. In the program above, if `os.Create` fails, the program will exit and will print "Error: creating file for info: &lt;the real reason&gt;". (Notice how when we decorate the error we do not use capital letters or periods.) This is a lightweight approach to error handling compared to other languages (no stack traces). The nice thing about this way is that because [errors are just values](https://blog.golang.org/errors-are-values), you can make your error handling [as elaborate as your project requires](https://commandcenter.blogspot.gr/2017/12/error-handling-in-upspin.html).
[removed]
I am confused. Is this an API or a client library for the Blizzard API?
Is this code inside a function or is it the body of the loop you mention? If the latter, note that defer will only execute when the enclosing function exits, not at the end of each iteration. This means that Close() will not be called and you are leaking file descriptors, which I suspect it's the error your encountering.
&gt; The official answer is that its waiting for generics. That sounds like a good answer at first but IMHO it very much isn't. The trouble is that simple Java-like generics (or even simpler) require the same implementation for all types. I'm not sure whether using a different implementation for float and int is needed (it might be and it might be more practical), but for other types - complex numbers, for example - you _definitely_ need a different implementation, which would require generics _with specialization_. Go is likely to implement type erasure kind of generics which don't go well with specialization if at all (not to mention that specialization is an additional complexity which I presume Go wants to avoid). A more elegant solution is (IMO) what some other languages do - support of methods on primtive types. That way, you can have for example `someInt.abs()`, `someFloat.abs()`, `someComplex.abs()` and the like. 
There's nothing to defer that that point, so it's valid.
So over 500 years?
Or if you don't want the output to be like a log line, you can still use the `fmt` package, but use : if err != nil { fmt.Printf("Error writing info: %v", err) os.Exit(1) }
Hmm what do you mean? I was under the impression that there was a `defer file.Close()` call in the code. 
Would not that be the point ? There is probably no purpose to running the defer when the resource creating call has failed.
Hmm yeah you are right. I guess I am too used to avoid Fatal when there's any kind of defer statement.
I've used usql for working with SQLite files and found it to work well. I'd recommend it. 
I work on cryptogrpahy for a living. Knowing where my entropy comes from is very important to me. This blog posting, because it didn't start with "LOL this is code golf, JK. Don't use this in production!" makes me very nervous. If you want entropy for real, there is only one place to get it: crypto/rand. -jeff
It's not *golf*, but fair enough :) Also, first sentence &gt; I come up with a couple of useless […] Personally, I find the whole "don't ever roll crypto" adage a bit overblown. I trust people to be halfway reasonable and consider it fairly obvious that this is not usable for crypto (and even expect everyone who know that "entropy" is important for crypto to definitely realize that this isn't cryptographically secure entropy).
Yup, in times of systemd comparing a job scheduler to cron doesn't make sense because at this point it has already been deprecated and replaced.
This, is the true answer.
After looking up both terminologies, I would say this is a client library for the Blizzard API. I will update the documentation accordingly. TY!
Yes, I noticed it too.
we will do some simple 3d stuff eventually! 
I usually have trouble inspiring someone to even click the up arrow, let alone reply to my comments so I can't condemn this blog post! Besides, the hash map iteration method sure is better than seeding math/rand with unix time stamps.. which I some how still find in projects &gt;_o
For non-cryptographic applications, seeding math/rand with the current time is fine. Just sayin' :) Also, I think `math/rand`+`time.Now().Unix()` is probably better than my implementation for the map-iteration anyway. It uses a better PRNG and I would runtime fastrand PRNG is also just seeded with the current time (or something along those lines). :)
[removed]
Is there a quick summary somewhere?
But then you have to install systemd...
# Method 5: Just define your own random number generator Technically without imports ;). var state uint64 = 1 func rand() uint64 { x := state x ^= x &gt;&gt; 12 x ^= x &lt;&lt; 25 x ^= x &gt;&gt; 27 state = x return x * 0x2545F4914F6CDD1D }
That doesn't actually give you entropy, it just gives you a PRNG. This is about how to seed it so it becomes non-deterministic. (And FTR, the post defines its [own PRNG](https://gist.github.com/Merovius/283ff12a1186d001815485fca1094968#file-entropy-go-L103))
 if err != nil { return errors.New(err.Error()) } Why don't you return just err?
Interesting stuff. I'd argue some of these are cheating, but I'm also a stickler Meeseeks. Map Iteration and Select Priority are both pseudo-random, not just "incidentally random" or "undefined", so its likely somewhere in the compiler they're reaching out to math/rand code to help. Correct me if I'm wrong. IMO you can't say that your code avoids a certain import by effectively calling into a new module that makes the import for you. Methods 3 and 4 are the most interesting. One idea for the memory pointers; print out the pointer locations using fmt, that string will be hex, convert it back into an integer. 
Basically push and pull to remotes, while keeping the code intact. If necessary, use glide or another package manager to specify the desired fork.
&gt; so its likely somewhere in the compiler they're reaching out to math/rand code to help They are not, they are reaching out to the runtime, which comes with a cheap PRNG and ways to seed it. Both use [runtime.fastrand()](https://github.com/golang/go/blob/39687051e9e781bb438ad32154472356fddf98a8/src/runtime/stubs.go#L94), which is seeded with [CPU ticks and goroutine-ID](https://github.com/golang/go/blob/39687051e9e781bb438ad32154472356fddf98a8/src/runtime/proc.go#L557). But that is kind of the point (useless as it is): Figuring out in what ways the language/implementation exposes these side-effects to you. Note, that the original question was about whether excluding imports would make for safe or deterministic code - that's the context you should read this in. It's not really "do we have to rely on external code", but more "is not importing anything really an indicator that we are isolated".
You know that's not true for the most dominant distros out there. The ones - and mostly these are the only ones - that you're offered at pretty much every VPS provider.
I've finished updating my amd64 core. It looks like my code is faster for smaller sizes (&lt;512 bytes or so), but your avx2 core is faster for larger inputs.
The post that the talk is based on can be found at: https://medium.com/capital-one-developers/closures-are-the-generics-for-go-cb32021fb5b5 . The talk has more examples and background info, though. TL;DR: Until Go figures out its generics approach, closures can be used in many cases to abstract over types.
I'm not sure why I did that, I'll switch it to err. The fmt.Println() will be removed as well. TY!
&gt; But that is kind of the point (useless as it is): Figuring out in what ways the language/implementation exposes these side-effects to you. Note, that the original question was about whether excluding imports would make for safe or deterministic code - that's the context you should read this in. It's not really "do we have to rely on external code", but more "is not importing anything really an indicator that we are isolated". The subject of my comment was that it is _never_ safe to execute arbitrary code, which I thought I made that very clear in my post. I was just trying to determine his actual use case, since no network connectivity or third party packages are mentioned it's clear the outputs are deterministic based on inputs. I wasn't giving him the go-ahead to execute arbitrary code because it was safe as long as it was deterministic formed under the premise that generating confusion and diffusion at runtime was impossible. So I don't mine the fact you quoted me in such a way that it made it appear as if I was stating determinism was a mutual inclusive property to a lack of imports, since it led to a useful thought exercise and I felt you framed the post around "generating entropy" without imports. But please include my **FULL** comment if you are going to frame your conversation around arbitrary code execution, cryptography or security in general since it appears as if you are proving me wrong against a conclusion I never made. Thanks.
The difference is not stylistic. In the former case, you can now call the methods of `io.ReadCloser` on `Foo` as well, which also means that `Foo` satisfies any interfaces those methods enable it to. `f := Foo{os.Stdin, 42}` is creating a new `Foo`, created with os.Stdin as it's `io.ReadCloser` and 42 as it's `SomeMoreStuff`. `f` implements io.Reader because it is composed of an `io.ReadCloser`, which itself implements `io.Reader`.
is os.Stdin a variable of the os package that you're typecasting to the type io.ReadCloser?
Whoa... that is really cool, I think I get it. It's like if there are method that you want to have associated with a specific struct, you can embed a type that contains those method. So it seems almost like a way of better organization. 
That's one way to think of it, but I think the use of the phrase "typecasting" would be refused by some Go developers.
Thanks for the suggestion -- I'll do that
Ah, I first learned C. Why would you want the variable os.Stdin to be of type io.ReadCloser ? just to have access to the read and close methods from io.ReadCloser?
Nice one
Unix sockets.
Can you use something like https://godoc.org/golang.org/x/crypto/nacl/secretbox instead?
That's a shared single key scheme. The encryption key needs to be relatively short and easy to share, which is why I have an interest in EC keys. The end goal is just forward secrecy, where only the recipient will be able to pick out the message in a public forum which anyone can see. Edit: Some context would be that users have an app that generates a key pair on their phone and provide public keys to begin exchanging messages. 
In Go interfaces are implicitly satisfied. This means that when any function/struct requires an interface, it really says that: 'I don't care about your type as long as you implement my interface'. In jargon people say that Interface defines 'contract' and each concrete type which satisfy(implement) this contract (all of it) can be used. In example above io.ReadCloser is an interface from io package which is by itself combined from two other interfaces io.Reader and io.Closer so to satisfy io.ReadCloser contract one needs to provide concrete type which implements two methods: * Read(p []byte) (n int, err error) * Close() error Such concrete example is an os.Stdin instantiation of filehandler from os package. 
Oops, meant to send https://godoc.org/golang.org/x/crypto/nacl/box ; was on my phone. Sorry.
A way to signal early termination to a goroutine, yeah?
It's called struct embedding. What happens is that the outer struct inherits (please don't think in terms of OOP-ish class inheritance; I just mean the word) methods and fields of the embedded struct. A typical example is embedding `sync.Mutex` in your struct to provide a locking mechanism. Say you have a concurrency-safe cache, you could implement it as type SafeCache struct { sync.RWMutex cache map[string]interface{} }
not sure what you mean ... that's not at all what the post is about
If only Google cloud functions (aka firebase functions) would support go. Writing my firestore triggers in JavaScript makes me sad.
Why does this not have more upvotes!!??
I recall reading over this some time ago. Though I think I was hitting a dead end for some reason with nacl. Not 100% sure what that was, so I'll re-evaluate it and reply back to let you know how it goes. :)
You can try https://godoc.org/golang.org/x/crypto/curve25519 with https://godoc.org/golang.org/x/crypto/ed25519
A lot of languages would have a `zip` or `merge` function in std-lib for this kind of problem, which requires far less time to write and can't be used wrong. The simplicity of Go does harm here, by introducing unnecessary complexity.
ok.
Alternatively (mostly because I wanted to write it using `goto` :-) func merge(a, b &lt;-chan int) &lt;-chan int { c := make(chan int) go func() { defer close(c) for { select { case v, ok := &lt;-a: if !ok { goto drainb } c &lt;- v case v, ok := &lt;-b: if !ok { goto draina } c &lt;- v } } draina: for v := range a { c &lt;- v } drainb: for v := range b { c &lt;- v } }() return c }
No
Sweet Jesus, YES!
Go is super simple and super obvious... until when it comes to channels, where nothing is simple nor obvious to me.
i think it can be simplified https://play.golang.org/p/8Rt9p7g4GAl 
I've messed around with OpenGL etc in Go before, but I don't have all that much experience making actual games which is the primary reason I'm interested in watching. The procedural generation and genetic algorithm stuff does sound like something I can look forward to though :)
https://www.youtube.com/watch?v=HxaD_trXwRE This talk explores a FSM, but for a very different purpose. It might give you some ideas on how to represent states and keep some type safety.
Reasoning about concurrent mechanism is never easy, regardless of the language. Flow-based programming (FBP) attempts to provide a more intuitive approach by putting the data flow first, often supprted by a graphical representation of the same. (I love the idea but I still need to see if and how this can scale nicely beyond trivial examples.) 
It's a valid point even if it hasn't been phrased in the most sensitive way. You should address it.
&gt; Reasoning about concurrent mechanism is never easy, regardless of the language. Erlang
Yeah... here is the original: https://www.youtube.com/watch?v=nhmAyZNlECw
Out of curiosity, I implemented [this in Rust](https://gist.github.com/xfix/ca95593d0cd13191096e20f0ac063dc8) and it seems so much simplier, without any `nil` channels and so on. Am I misunderstanding something?
ok
Any information on how they call the functions? Like do they use golang plugins, or are the functions started in separate processes? 
They are running a local TCP server.
Damn Hugo looks awesome. Thanks for that! Plus its open source apparently. Off to hunt down and examine some code. Thanks!
It kinda boggles my mind despite how successful Google has been they seriously lack any proper coordination between their departments. 
I also generated an example project using the default values [here](https://github.com/loderunner/echo), if you don't want to use [boilr](https://github.com/tmrts/boilr).
All caching algorithms have different tradeoffs in terms of speed and expiration accuracy. Your post doesn't give enough details on your workloads. Depending on the recomputation cost, even something like random eviction can be sufficient and has the advantage of a very simple implementation: https://github.com/dgryski/trifles/blob/master/cachetest/random/random.go .
What's wrong with a simple map?
Sure, I wasn't enough clear about what it's my current case. I have a microservice which focus on serving files. These file live in different provider (AWS, Azure and so on) I want to avoid hit everytime AWS or Azure for the same object (these objects are Pre-Signed URL). It's very simple just fetch first time the URL and sub-secuent request return cached data instead of hit external API.
I'm excited to try their new driver. 
So how effective does your cache hit ratio need to be? How expensive is a cache miss? Can you just store all the queries? How big is the working set compared to what you can store and how big the total collection is? My suggestion is still to start with something dumb and measure the effectiveness. Bonus points if you have a query trace you can use to simulate different caches with to see which one matches best. (But really, anything above a simple LRU is just small incremental improvements in cache hit ratio.
Awesome, thanks!
No it doesn't make sense to have waited that much time to start writing an official mongodb driver, instead they relied on the work of a single guy, like mongodb inc can't spare a few thousands $$$ to pay for a developer... that's the reality of IT for most of us, not what Hacker news the "valley" would like people to think. Instead of writing a blogpost about it, why don't they just go ahead and actually release the code? 
Because you're using a third-party library to facilitate that. It's possible to do the same thing with Go.
From https://aws.amazon.com/blogs/compute/announcing-go-support-for-aws-lambda/ : &gt; The lambda.Start() method takes a handler, and talks to an internal Lambda endpoint to pass Invoke requests to the handler. &gt; The lambda.Start() method blocks, and does not return after being called, meaning that it’s suitable to run in your Go application’s main entry point.
The announcement blog post has a good overview and example code: https://aws.amazon.com/blogs/compute/announcing-go-support-for-aws-lambda/ 
Indeed, the only thing that Jobber offers that systemd-timers don't is better control over what happens if a job fails --- e.g., Jobber can do exponential backoff in that case. Of course, if you are using a system that doesn't have systemd --- which is often the case with Docker images --- then Jobber may be useful. In any case, if whatever your OS provides --- cron or sytemd-timers --- is good enough, you should certainly use that.
Yes - first thing is that your example doesn't scale well. It uses threads so if you try to spawn, for example, 10000 producers it will likely occupy a lot of memory. The second thing is that your bounded example is not equal to unbuffered channel, but is more akin to ```make(chan int32, 1)```. Go runtime has one interesting optimization - if channel receiver goroutine is ready to execute it will be executed in the same thread as a producer goroutine replacing it. Other than that - the Rust example is definitely friendlier in some cases, but Go's is more flexible overall. This canonical merge/zip example would actually really benefit from generics (actually vararg generics), but in all my years of experience with Go I think I had to write canonical merge function maybe 2-3 times. Most of the time I used select quite differently. But again YMMV. 
Your example uses 5 goroutines instead of 3. In some cases it will likely to be slower, and it will definitely will occupy more memory. Although if you do not spawn millions of producers you're going to be fine. 
More like sync.Map, I guess. Anyway - you'd have to write all the logic by your self. How big can your cache grow, how to clean it etc.
two of the goroutines exist only to generate test data so not sure how that is an issue my example is shorter, more idiomatic, and doesn't rely on weird side effects like setting the input channels to nil tfa basically just takes a long weird detour to recreate `range` using other syntax, that's it if you are worried about memory why are you even discussing using channels? they are among the worst performing core features...
Link is dead - https://github.com/machinebox/toys/blob/master/anonproxy/main.go. And where is the `anonymise(img, faces)` function defined ?
Why not just use App Engine + Go? It has better deployment tools, better observability tooling and it autoscales down to 0 instances if you want it to. With secure PubSub push-style subscriptions, pretty much anything that you expect to trigger a Cloud Function should work also for App Engine standard environment.
[removed]
&gt; I think that the 8 cores might be emulated? I think I remember it being a quad core processor when I bought it. That's [Hyperthreading](https://en.wikipedia.org/wiki/Hyper-threading), a technology that virtually doubles your cores. Go takes the number of logical cores as a basis, not the number of physical cores, HT is where the difference lies.
You have 4 cores and 4 hyperthreads, making for a total of 8 logical cores. As for how the different values of GOMAXPROCS affect your execution, leave it default as it's clear you need more reading before you can start changing it. From the manual: &gt; The GOMAXPROCS variable limits the number of operating system threads that can execute user-level Go code simultaneously. There is no limit to the number of threads that can be blocked in system calls on behalf of Go code; those do not count against the GOMAXPROCS limit. Playing with the number of active threads will result in better or worse performance as well as potential issues being hidden (like race conditions when the value is 1)
very interesting project! Some time ago I thought about something similar, so I did small proof of concept: Instead using the whole Docker environment to manage images and containers, I used [buildkit](https://github.com/moby/buildkit) to build images from Dockerfiles and [containerd](https://github.com/containerd/containerd) to run containers (actually Docker using it underneath). Possible, that it's more lightweight and flexible solution. some questions: - new container is created for every "request" (always cold start)? or container is still running, and only the function inside is re-started? - do you plan some another ways of communication with function than stdin? eg. via REST or files? good luck!
Thanks Good hint the buildkit and containerd combo is pretty smart! I've gone the lazy way with docker, mainly planning to support swarm. Do you have any code to see? Container is started and kept idle, function is called with an exec. It's a bit faster, on a simple nodejs function it shows 0.6ms vs 0.3ms. Still looking for better way, I've seen openfaas uses fastcgi. I would give a try to a native language wrapper that load deps, idle and exec on call. The nice thing of current approach is that require minimal or no native language coding just docker files so extension is pretty easy It exposes a grpc based API and http+json Swagger here https://github.com/muka/mufaas/blob/master/swagger/api.swagger.json Generating grpc client code should be relatively easy also Cheers
The point is not about a zip or a merge function. It's a clever solution to dealing with any for-select idiom where you're reading from more than 1 channel and expect those channels to be closed eventually.
&gt; they seriously lack any proper coordination between their departments. If you've got better ideas, I'm sure you could get a job there in a heartbeat. Not many orgs with 10s of thousands of developers... you wouldn't have much competition.
Is this true go support or just indirectly supported with something like python or javascript like the workarounds that already existed?
This is the real deal. https://aws.amazon.com/blogs/compute/announcing-go-support-for-aws-lambda/
[removed]
This looks _great_.
Why would the send time writing a driver if, at the time, mgo satisfied their requirements?
Just tried the simple "hello world" example out, the code start was really fast (0.5ms), which is impressive. Really looking forward to using this in the future! 
Doesn’t support streaming or bidirectional communication; it’s pure RPC like it says on the box. If that’s what you need, though, and you’re a mostly Go shop this looks like a *much* simpler solution than gRPC or hand-coded routers.
Their points seem good, but I bet someone will add streaming soonish. It's really nice and useful to be able to use the RPC mechanism even for data that doesn't all fit in memory. (Protobuf before gRPC didn't support streaming either, IIRC. Though at that point it was only interface generation.)
Bidirectional streaming is hard to do in a way that works on HTTP 1.1. We've figured out how to do client-to-server - that's just some framing around each message in the body. Server-to-client is even easier, since it's just chunked transfer. But I am not aware of any way to do both at the same time in pure HTTP 1.1, and I'd rather not require http/2 just to support bidirectional streaming because it's kind of niche. I'm extremely open to suggestions on that front, though.
I have been happy with https://github.com/bluele/gcache - although am considering writing my own, as I dislike interface{} using interfaces as they potentially break if and when I fumble wrong types around :-p
True, native Go support officially from Amazon.
I understand that (Go user since 1.0). Most of the time I really enjoy programming in Go, but sometimes I can't overcome the feeling that Go should have some more abstract built-ins. This was especially true while watching the last JustForFunc video. Implementing `merge`by-hand just feels wrong. Instead of me copying code around, the compile should do that for me. 
IIRC, they paid Gustavo to work on the driver. 
First off: really neat project, the code looks clean and much more idiomatic than the generated gRPC code If uni-directional streaming is relatively "simple" to do then that'd ofc be great to have. (At least I have found many more use cases for unidirectional streaming than for bi-.)
Thanks for reply. I assume you use 'dlv attach' to attach to a running program, right?
Repo has been taken down.
To be honest, I just use the graphic controls in Visual Studio Code.... so under the covers probably.
You could have stackEquals take https://golang.org/pkg/fmt/#Stringer and then s.String() and t.String() will be available which looks like it will fix what you were trying to do... but it won't be efficient. You probably want to allow for some sort of iteration... so have a separate interface for that functionality and have your stackers satisfy that as well... then you can have stackers implement a StackerEq interface{ Equal(StackIterator) bool }
Thrift is a Lovecraftian nightmare protocol, nonidiomatic in every language and in Go especially, and complected by almost-always needless decisionmaking hoisted on the user around things like framing. The codegen tooling makes gRPC look like a walk in the park. I'm sure it must have solved a problem for someone, at some time; these days, after years of never-say-no guardianship under the ASF, it's become something that nobody in their right mind would voluntarily choose.
I am vaguely nervous I'm solving a homework problem here, but I hope not. The core problem here is you want to examine the entire stack, but the interface doesn't give you a way to do that. The best software engineering solution would be to add a way to do so to the interface. However, the next best thing is to observe that you certainly seem to be working within one package, as evidenced by the number of lower case things, including the fact that the interface declares several lower-cased method names. That means external packages can not implement this interface, which means we can legitimately say we have a complete view of all possible stack implementations. Therefore, we can implement a private function within the module which will unify the stack types into a single type of iterator: (None of the code here is tested, I'm just bashing it out in a text editor.) // The int is valid when the bool is false; true means we've hit the end. func iterator(s Stacker) func() (int, bool) { select s.(type) { case StackSlice: // within this segment of the select, s is now known to be a // StackSlice, not just a Stacker // give our closure some memory idx := 0 return func() (int, bool) { if idx &gt; len(s.slice) { return 0, true } val := s.slice[idx] idx++ return val, false } case StackLinked: // now s is known to be a StackLinked, and not just a Stacker curr := s return func() (int, bool) { if curr == nil { return 0, true } retval := curr.value curr = curr.next return val, false } } } Now you can take either kind of stack, and any kind of other stack you may implement, and convert it to an iterator. That was the hard part; using the iterator to compare the two is straightforward after that: func stackEquals(s, t Stacker) bool { sIter := iterator(s) tIter := iterator(t) for { sVal, sDone := sIter() tVal, tDone := tIter() // If they end at different lengths, not equal if (sDone &amp;&amp; !tDone) || (!sDone &amp;&amp; tDone) { return false } // if the values differ, not equal if sVal != tVal { return false } // if all the values up to now were the same, and // the stacks end at the same time, they are equal if sDone &amp;&amp; tDone { return true } } } As is often the way with linked lists, I've got no checking here for loops. Passing two looped StackNexts will infinitely loop. Because you're peeking, you can also cheat; you could examine the types and if both are equal, you can call reflect.DeepEqual on them. But you'd still need to fall back to this if they are different. You could also penetrate the types and use this to make the .String() approach work, though comparing equality based on serializations is generally a very bad idea.
Well, this doesn't really matter in your current case, but to encourage you to make your code reusable in the future, I made that suggestion. net.Listen can take a bunch of socket types per: https://godoc.org/net#Listen ["tcp", "tcp4", "tcp6", "unix" or "unixpacket"] Anyone who wants to use your code, including you, in a unix domain socket scenario can do that now, and you server function won't need to know about the underlying type. Does that make sense?
I have added benchmark code into [rpcx-ecosystem/rpcx-benchmark](https://github.com/rpcx-ecosystem/rpcx-benchmark)
&gt;A more colorful, user-friendly implementation of `ls` we have graphical shells for this purpose. it looks ugly to me.
32 cores, ./twirp_client -s http://127.0.0.1:9982 -c 500 -n 100000 INFO : concurrency: 500 requests per client: 200 INFO : message size: 581 bytes INFO : took 4302 ms for 100000 requests INFO : sent requests : 100000 INFO : throughput (TPS) : **23245** INFO : mean: 19598076 ns, median: 14000336 ns, max: 135761910 ns, min: 97330 ns, p99: 98075198 ns INFO : mean: 19 ms, median: 14 ms, max: 135 ms, min: 0 ms, p99: 98 ms
 func stackEquals(s, t Stacker) bool { pop := func(s Stacker) int { v, _ := s.pop() return v } tmp := &amp;StackSlice{} defer func() { for !tmp.Empty() { v := pop(tmp) s.push(v) t.push(v) } }() for !s.isEmpty() &amp;&amp; !t.isEmpty() { l, r := pop(s), pop(t) if l != r { s.push(l) t.push(r) return false } tmp.push(l) } return s.isEmpty() &amp;&amp; t.isEmpty() } But also, please don't write abstract data structures in Go. It sucks (for the lack of generics) and that's a good thing, they don't really add any value and only make code complicated (case in point) and slow (case in point).
font-size below 16px for main text...
[removed]
For instance to control running microservices, collect stats and if you have complex multi-tier architecture, to pass data/signals between services across the network. 
I just noticed that your Stack-interface also has copy, which means it is even simpler (but more potentially more expensive, but maybe the spirit of the assignment): func stackEqual(s, t Stacker) bool { s, t = s.copy(), t.copy() for !s.isEmpty() &amp;&amp; !t.isEmpty() { l, r := pop(s), pop(t) if l != r { return false } } return s.isEmpty() &amp;&amp; t.isEmpty() } And in case you are interested in Go-specific advice: 1. Make the methods of the interface exported 2. Call the interface "Stack", not "Stacker" (a "Stacker" would be `interface{ Stack() }` or the like) 3. Remove `isEmpty`, as it is redundant with `size` -- and if you *must* have it, call it `Empty() bool` 4. Remove the `error` returns from `pop` and `peek`, they make the common case (people know what they are doing) pretty unergonomic. Instead `panic`, which breaks the uncommon case (people don't know what they are doing) but that's exactly what panic is for: Pop'ing from an empty stack is equivalent to indexing into an empty slice, which also panics.
&gt; But I am not aware of any way to do both at the same time in pure HTTP 1.1 BOSH and Bayeux protocols. In a nutshell, two HTTP 1.1 uni-directional connections. But implementation would be not so simple.
The documentation is plentiful: https://golang.org/doc/effective_go.html#for. Your problem is not with ranging over a slice, it's the declaration of "pntr". 
You might ask /u/JasonLiuENGR, it seems they are [in the same course](https://www.reddit.com/r/golang/comments/7qwuu5/golang_comparing_two_structs/) as you ;)
Neat project! Code looks clean will definitely try it in one of my projects
It's just a contamination.
Oh and to answer your question (see the last paragraph [here](https://www.reddit.com/r/golang/comments/7qwuu5/golang_comparing_two_structs/dst23n9/) for what I think about cheating yourself out of an education): The same way, you iterate in any other language. func (s *StackLinked) copy() Stacker { if s == nil { return s } return &amp;StackLinked{ value: s.value, next: s.next.copy().(*StackLinked) } } Or, without recursion func (s *StackLinked) flip() *StackLinked { tmp := makeStackLinked() for !s.isEmpty() { tmp.push(s.pop()) } return tmp } func (s *StackLinked) copy() Stacker { return s.flip().flip() } Or func (s *StackLinked) copy() Stacker { var tmp *StackLinked for s != nil { s, tmp = s.next, &amp;StackLinked{ value: s.value, next: tmp, } } return tmp } Which of these is best is left as an exercise to the person doing the assignment ;)
a few notes, may help but im a begginer. 1) you still need `:=` the first time you assign a variable... or.. you could define it earlier. this would help you! the compiler will print a clearer error! so use`var pntr *int` as the first line in your func 2)im not sure, but go is new and might not have reverse declarations or forward declarations... whatever theyre called `*ptr = somevalue`..... https://play.golang.org/p/MPv-wmRhxFJ but it does work when i do `pntr = &amp;somevalue; ss=append(ss, *pntr)` not sure i just managed to confuse myself. if it helps i like to think of it like this &amp; is `address-of` * is `pointer-to`; basically everything is either a byte slice or a pointer to a byte slice, (a pointer being a 8 bytes that equal a memory address)
thanks for all the help, but sadly I can't change the function to a pointer :/ I somehow used the builtin functions of list and made it work 
&gt; thanks for all the help, but sadly I can't change the function header to a pointer :/ Because it's an assignment, I assume? &gt; i was just curious if it was possible to create a pointer to the first element of the linked list You stumbled upon the point of the exercise :) Yes, it is possible to do so: `&amp;firstElementOfTheList`. But that's probably not what you want.
It's a function as part of a longer project, but finally got all my tests to pass 
I'm biased since I contribute to Thrift (both to the generator and library), but I feel "nightmare" is a bit too much. Thrift isn't ugly because of the ASF or "needless decision making". It evolved to what it is today in order to support many, *many* languages with widely different type systems, data structures and runtime models. As it stands, Thrift isn't perfect and there is lots of room for improvement but people are working on it. I personally worked on removing lots of cruft from the generated code and making things more idiomatic Go (i.e `set&lt;T&gt;` used to be represented as `map[T]struct{}`, now it's `[]T`). I agree with you that Twirp looks *really* good right now, but as it gains popularity and support for other languages, there will inevitably be changes to accommodate different requirements. Even on its *first day* there are feature requests opened for [an HTTP client interface](https://github.com/twitchtv/twirp/issues/12), [client customization](https://github.com/twitchtv/twirp/issues/7), [logging redesign](https://github.com/twitchtv/twirp/issues/4) and [streaming support](https://github.com/twitchtv/twirp/issues/3). Thrift is 11 years old. Imagine what Twirp will look like in that time.
https://changelog.com/gotime
Don’t get me wrong it’s a cool thing you build. I just get the feelings overall with the amount of rebuilds of existing solutions in go it starts to feel like the npm space. Everyone is reinventing the wheel. 
&gt; It evolved to what it is today in order to support many, many languages with widely different type systems, data structures and runtime models. Yes, I understand that, and I believe strongly that it has been a mistake. The consequence of this “evolution” is an IDL that’s user-hostile to the extreme. It’s important for projects to aggressively as “no” to scope-expanding feature requests, in deference to a carefully considered and coherent design. 
&gt; It’s important for projects to aggressively say “no” to scope-expanding feature requests In theory, I completely agree! But I'm not sure if it's realistically possible for a language-agnostic RPC system that wants widespread adoption. If Twirp people choose to limit themselves to only languages with similar enough structure to Go so they can avoid feature creep, that'd be perfectly fine. I only argue that there is no way to have Thrift's reach without becoming, well, Thrift.
Exactly.
Sweet, this is pretty great. I'm not doing anything special with mongoDB but I've also felt into a few problems with mgo where its interface/behavior didn't lined up with the mongoDB spec. I can't imagine the amount of trouble you will get if you need more advanced functionalities. I'm excited to finally get an official driver that will keep up with the specs. ;)
I'm probably being pedantic here (it's clear to me that you already understood anyways) but both have users. The difference is the kind of users they can get. Both types are meant to be consumed by machines; however, REST APIs works very well on web browsers (good for websites with dynamic content) unlike rpc.
You could say the same thing about Go itself, yet the language itself hasn't change much at all. The standard library has evolved, features have come and gone, but BC breaks have been very rare. As long as the Twirp team have a clear vision, and stay vigilant and say no every now and again when they need to it'll work out fine.
I'd advocate using it for internal, inter-service traffic usually. You can use it on for front-end systems, but generally speaking regular HTTP-JSON services are going to be easier to use with a browser. In the backend, just think of it like a different way of calling a remote service.
For software projects in general, I agree. But I think it's unavoidable for language-agnostic RPC systems. See my [reply to Peter](https://www.reddit.com/r/golang/comments/7qvi0w/twirp_a_sweet_new_rpc_framework_for_go_twitch_blog/dstcbld/).
This might have been a good opportunity to study the Unix philosophy and some history on the development of those commands. Modern Linux distributions have commands that take dozens of flags and try to do everything by themselves. Over the years, more and more features and bloat have been added which has lead to [5000+ lines monstrosities](http://git.savannah.gnu.org/cgit/coreutils.git/tree/src/ls.c). Meanwhile in Plan 9, the proper way to print your files in multi column format is to do `ls` and pipe the result to [`mc`](https://9fans.github.io/plan9port/man/man1/mc.html) which is what the `lc` command does. Here's the Plan 9 [ls source](https://9fans.github.io/usr/local/plan9/src/cmd/ls.c) for comparison.
Meanwhile, the first three words of the main text are: &gt;Size does matter!
Possible for users to define dependent tasks?
Indeed, I can understand how it has gotten to that point. I'm not sure if Twirp is exclusively targeting Go (at least for now) which will help keeps things simple - but also will mean it won't be as flexible. For some, that won't be a problem I suppose.
[removed]
In my opinion, the two biggest advantages of JSON "REST" are its simplicity and readability. As soon as you introduce HATEOAS, schemas and a whole bunch of other [useful noise](http://jsonapi.org/), those two advantages are gone out of the window and you start hearing the faint, sarcastic laughter of XML in the distance.
I guess they have to also run that on multiple machines to deal with high loads? 
What are you looking to get out of these podcasts? What kind of information? I ask simply because, in my experience, general programming podcasts are far more interesting than language specific ones, and depending on what you're looking for, I might have a couple of good GP-podcasts for you :)
Speaking of wheel, I think it's time we reimplement sudo in Go
The static binaries plus fast cold boot times (obviously YMMV) are the biggest advantages. At work we have a lot of Java based lambdas, which work great but if you are not careful you can easily run into the 50mb code size limit of a fat JAR, especially if you're pulling in one of the behemoth dependency trees. So I think Go will help a lot in this department. The downside is you can't view the code in the Lambda console, which is true for the Java/C# solutions too so not a huge deal, but it means there is still clumsy integration between AWS's "Cloud9" IDE service and Lambda's that are not written in JS or Python 
I agree. I want people to make sure they use the correct names when they talk. REST is a great idea. It's a terrible way to make APIs. I've only seen it done in a few places. Ultimately the humans using it completely ignore it. We figure out the templates and just use those until they don't work anymore.
Great article. It is great to have so many options to read files, a little confusing at first, but great nonetheless. If I am not mistaken, the `ScanBytes` has a typo, it is using `ScanWords` instead: &amp;nbsp; line 9, `scanner.Split(bufio.ScanWords)`.
that just means its catching on imo. glad thats happening :D
Seeing where this tool got its inspiration from is enough to bring back painful memories of the complex, "enterprise-level" building tools of the Java land. :P 
[removed]
&gt; study the Unix philosophy Much more people talk about this than actually do anything about it, and for good reason. And generally the talks only work by being _very_ picky about the data. &gt; Linux distributions have commands that take dozens of flags and try to do everything by themselves If you don't then you aren't building commands, but tools that useful commands can be made out of. Microsoft powershell tried to do both, are you using that? The way everyone else went (including "Unix philosophy") was API reuse ... this was/is the major failure of gnu-coreutils IMNSHO. You can even see it in Go ... if they valued the "Unix philosophy" it would be easier to create processes that communicate, instead they made it easier to split your single large process into APIs that can communicate within itself. &gt; 5000+ lines monstrosities. LOL. &gt; Here's the Plan 9 ls source for comparison And how many people use plan9 ls+lc to build an ls? Much less than the number of [exa](https://github.com/ogham/exa) users? Close to the number of ls-go users? Having smaller reusable pieces is a great goal, and this code does have some parts split out (textcol/pad) but you don't need to force those to be on a process boundary because of of some historical thing that is mostly imagination.
Yes that is true. On the other side my guess is that 60% of all npm packages is utter garbage. And no there is no need for 10 packages that all tackle the same issue. But that is an open source plague: not invented here syndrome. 
I use MongoDB + MGO for a small production system and have found the combination a joy to use. Thanks to their developers. . Having an officially supported driver is great news and should increase the use of Go + MongoDB. I hope the design allows programmers to get the job done with a minimum of fuss the way MGO does.
Think you can just do “go run *.go &amp;” Why do you need to do this though? Curious as to what use case can possible require this.
&gt; You can even see it in Go ... if they valued the "Unix philosophy" it would be easier to create processes that communicate, instead they made it easier to split your single large process into APIs that can communicate within itself. What are you talking about? It's part of the Go philosophy to use [small interfaces](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=5m17s) that encourage many different programs and implementations to work well together. In addition, Go's [concurrency model](https://blog.golang.org/share-memory-by-communicating) has its history on [CSP](http://www.usingcsp.com/) which stands for Communicating Sequential Processes. It's literally in the name. &gt; LOL. Well I am glad you also find funny the fact that the core-utils implementation of `ls` is over five thousand LoC. ;D &gt; because of of some historical thing that is mostly imagination. A lot of people in the Go team worked on Plan 9 before and many of their ideas and philosophies have been transferred to the Go ecosystem. 
I think this should be posted in /r/bash, but anyhow I am not sure what you expect to happen here after execution: * Execute all and exit bash script * Execute all and wait until Ctrl+C is pressed which would kill all executed and exit the bash script If you need just execute all and then exit bash script I would go this route: go run *.go &gt;&gt; stdout_log_filename 2&gt;&gt; stderr_log_filename &amp; PID1=$! go run *.go &gt;&gt; stdout_log_filename 2&gt;&gt; stderr_log_filename &amp; PID2=$! This will give you two separate log files for each "instance", one which will have stdout (useful if your go uses fmt.Println or similar which outputs to console), and stderr which will be written only on standard error. Each "instance" will have own PID which you need to remember (write it to file then later read from file and check if it's running), or using ps command. Please note that you will need to make "start|stop" script.
Exactly what I wanted. Thanks very much for your help!
I'm just playing around with how Go and bash work. Starting a bunch of different services at once before moving to docker/docker compose to bring them up.
 Just deployed my first Lambda function on the new go runtime, and it was super smooth. Cold starts are hardly an issue anymore. 👍🏼
&gt; It's part of the Go philosophy to use small interfaces Interfaces are not programs. If you suggested he could split some functionality into a small/reusable interface we wouldn't be having this discussion. &gt; CSP which stands for Communicating Sequential Processes. It's literally in the name. Not even sure if you are trolling anymore. If not read: https://en.wikipedia.org/wiki/Communicating_sequential_processes#Primitives &gt; find funny the fact that the core-utils implementation of ls is over five thousand LoC. It's kind of funny you think 5,000 LoC is "big".
&gt; you are saying you think Docker started great but has refused to say no to features and is now bloated/ugly/etc? Well, it started mediocre but with a lot of promise, and then grew too big too fast, without coherent design direction, and became a maze of bugs begat by accidental complexity. I stopped following development closely a year and a half ago or so, but by then it was well pass irredeemable, IMO.
i would highly recommend against handling errors by inspecting the error message like https://github.com/acarl005/ls-go/blob/3baacbe84f4702c9da0139c7ff2e9904acd7f53d/ls-go.go#L92
I guess I'm looking for Information and things happening in the Go community. If you've got some good recommendations for general programming podcasts please share them. I'd love the check them out 
This is the Java way. Proxies can make things very hard to debug. I think you should just use some Go techniques/features to achieve a similar result. For example you could use a closure to provide logging around a function call: https://play.golang.org/p/AItD4Av3utN 
[removed]
I respect the division of duties. There is nothing quite like make! For my purposes, I am keen to find a make-like build system for Go projects that natively supports cross-platform development—in particular, performing all the common tasks like archiving, packaging, and cleaning up artifacts, without having to divide the shell operations into one set (rm...) for UNIX development hosts and another set (del...) for Windows hosts. It sucks to have to maintain a cross-platform Makefile, I tell ya! One workaround is to write all build scripts in sh, and require Windows users to invoke the build tasks from a bash/cygwin environment, though this is quite painful to setup. Rather, something like the mage project would be a decent Go-ish alternative for make. I wish that mage featured more builtins (plugins?) for common operations, rather than just the Go stdlib. Or that there were more Go ports of many UNIX CLI tools, so they could be called from mage without opening the UNIX/Windows shell division portal to hell all over again. Anyway, dependent shell(ish) tasks are what I need, while cross-platform support sans user written per-OS logic is a nice to have. I want to be able to build my systems language projects for macOS, Windows, and Linux without having to maintain three different conditionals in my build system :P
When will you take the meta leap and build a tool that builds build tools?
Skimming over the readme, I would paraphrase the tool as a "javascriptable, cross-platform `make`". Correct? So no more ugly Makefile syntax to break and no more, "I use Windows, I cannot run your makefile!".
Great article. Just a tiny nitpick: &gt; Go may have its share of problems Every language has its share of problems, so I wonder why the author mentions this explicitly, especially without naming the problems.
Please open an issue on the tracker tracker and provide the IDE logs. You can find the logs via Help | Collect and Show Logs in... and attach the zip file to the issue at https://youtrack.jetbrains.com/issues/Go It would also be great if you can enable the debugger output to logs via Help | Debug Log Settings... and add this line: #com.goide.dlv.DlvVm , then go about your usual debugging workflow. Whenever the issue happens, please continue for a bit and then go to the Help | Collect and Show Logs in... part. Thank you.
of course! Do you think that an integration is needed to make that more clear?
&gt; Attribute("password", String, "Avatar of user", func() { Example("password") }) Attribute("salt", String, "Phone number of the user", func() { Example("salt") }) It's a good thing the GoA framework requires descriptions for its attirubtes. I would never have guessed that `password` is the "Avatar of the user" and that `salt` is the "Phone of the user".
Your website fails on basic accessibility. _"[Background and foreground colors do not have a sufficient contrast ratio](https://dequeuniversity.com/rules/axe/2.2/color-contrast?application=lighthouse). Low-contrast text is difficult or impossible for many users to read."_ I had to open the dev tools and manually change the text color to something readable.
&gt; Instead, you just write Javascript to define your workflow. [&lt;Confused screaming&gt;](https://i.imgflip.com/22wg8t.jpg)
Since you haven't had any response to this, I'll take a crack at an answer. Almost all Golang libs are in GitHub, so a quick glance at the open issues, commit history, code, tests, and pulse graphs will tell you a lot about a libraries maintenance. Gokit, and redigo are two examples of libs I vetted this way before deciding to bring them into prod use at work. Also, Golang libraries tend to be small, and tend to have fewer transitive dependencies than say Java or JavaScript, so it it's quite easy to vet a projects total set of dependencies in this way.
&gt; these libraries are proven to work well for production-code, their authors won't disappear, they're actively developed, there's good documentation, good community, they're developed by experienced teams/contributors, they're used by other big/known tech companies, etc. You want the Go standard library.
As an example: ``` vars, err := shell.SourceFile("foo.sh") if err != nil { ... } fmt.Println(vars["VARNAME"].Value) // VARVALUE ``` These kind of files are fairly common, such as PKGBUILD scripts in Arch Linux. I think this could be useful.
"JavaScript is notorious for bad code and poor developer practices", this man is aware
Another possible useful bit of info is this new func: https://godoc.org/mvdan.cc/sh/syntax#TranslatePattern TranslatePattern turns a shell pattern into a regexp one can feed into regexp.Compile. This matters because what you get with `path.Match` and `filepath.Match` isn't the same syntax that you have in a shell: https://github.com/golang/go/issues/23456
Great to see some constructive criticism about the actual code. Have an upvote! 
Use the standard lib as much as you can, then https://github.com/golang/go/wiki/SubRepositories and then use /u/des09 advice &amp; common sense to vet what is reliable and what is not.
I really like the nerd-font so I've created a shell function to replace my system ls with yours. If I run into any problems with daily usage I'll let you know. echo ' ls() { case $* in * ) command ls-go -n "$@";; esac } ' &gt;&gt; ~/.zshrc 
He's not forcing you to use it. He just coded this thing, and he's proud of his work. I like the fact it uses nerd-fonts. I'm happy he shared. It's not like he is trying to replace everyone's ls.
neither of these are really next gen in any way! 
Looks good. Definitely worth a star.
Most mature Go based software, are tools, like docker. There are very stable and good (open source) tools too. Like NATS (a pub/sub nervous system) with official clients for many languages. Or CockroachDB, a scalable, PostgreSQL-Compatible database. But if you are looking for next WordPress or Rails, Go has nothing comparable - in terms of maturity, features and community size of that tool (yet).
I'd be really sad to see channel directions go personally. It seems that the majority of people being vocal on this issue agree.
[removed]
The standard library covers the vast majority of general-purpose needs. For database drivers, API clients, and so on, at this point you can usually find a stable, official client library for anything in widespread use. For anything beyond that, there are some stable libs out there, but they're really not necessary. If you do want to import a library, since imports are resolved directly from the source repo, it's really easy to vet them and know what you're getting (unlike, say, npm or nuget, where the package you download doesn't necessarily match what's in the repo). My general recommendation though would have to be: don't take on dependencies unless you have to. The standard library is very broad, the language is very easy to work with, and personally I think the import-happy culture of NodeJS, .NET, Java, Ruby, and so on is a plague on software development. We're in dire need of a move toward fewer dependencies and better-vetted dependencies.
libraries to do what? 
That is the IDE sending the command to continue to delve. As it seems, you don't have any breakpoints set in the code, given the message ID. Do you actually have breakpoints in the code? Please open an issue so that I can have a look at the logs instead of trying to assume what's going on. Thank you.
I've never used gin, before but the godoc says: func (c *Context) File(filepath string) File writes the specified file into the body stream in a efficient way. Which sounds like it is trying to find a file named whatever the base64 string decoded to, not send those bytes. I think you might want to use something like https://godoc.org/github.com/gin-gonic/gin#Context.Data 
Sorry; I do not understand your comment.
Anyone using this in production?
Thank you. I shall try this and report back.
I was agreeing with your comment that there are a lot of mature go tools like docker. Many of those tools have a lot of dependencies on other packages. Looking at the packages that tools like docker or kubernetes rely on is another way to find utilities that are mature.
How is it that you unilaterally decided on a language without even evaluating the ecosystem, consulting your staff, or even used the language yourself?
I don't have breakpoints. but a remote debugger should halt on attach even without bp. 
It was a hypothetical questions. I'm not in this situation myself or know of anyone in this situation. I'm new to the language and i'll be joining a company that uses Go. I realize that I'm not familiar enough with the ecosystem to have an unbiased opinion and therefore i'm asking for information from people who do have the experience. Would you want to share your opinion on libraries you'd trust your company with?
I’d recommend Uber’s stack as well. Tally for metrics, Fx for dependency injection, jaeger for tracing, zap for logging, yarp/tchannel for thrift rpc. Lots of stuff there and it’s updated regularly. 
&gt; I don't have breakpoints. Then please set some breakpoints. &gt; but a remote debugger should halt on attach even without bp. It does halt, which is why the IDE sends the continue command after it connects and does the initialization/discovery part. However, at the point where delve halts the execution for the process it debugs, that process can be anywhere in the application execution so I don't know how helpful that would be. So, what should the IDE do in this case? Can you explain your use-case and why you think it should show something?
https://github.com/ddollar/forego is probably what you want.
I updated the question to try to give a bit more direction. Thanks for pointing it out
Why are you encoding the data to base64? Why not store [BLOBs](https://mariadb.com/kb/en/library/blob-and-text-data-types/)?
Reinventing the wheel is the best way to learn about wheels.
[removed]
I have a web server running at the remote side. From my java debugging experience, every time I attach to a running process, it halts the it. The IDE will print the stack frame at the halt point for all threads (for golang, this is goroutine I guess). But I got nothing to display from Goland. I can't simply set a breakpoint as the web server is a large project. Currently the running path is unclear so most likely a breakpoint I set will not in the running path
Working towards a wordpress / rails combo replacement in Go: https://ponzu-cms.org -- would love to get some more people contributing so that your answer might be different next time around :)
&gt; When will you take the meta leap You called?
Awesome use of Otto! Was there anything in particular that led you to use this over another embedded JS runtime in Go? 
Ahh thank you! I took portions of the code from another project I was working on and forgot to change the descriptions 🙂
I'm working on a way to generate Ruby clients for Twirp as I'm prototyping a new service that we'll need to call from our main Rails app. It might be interesting to anyone else who's in a similar boat. https://github.com/gaffneyc/protoc-gen-twirp_ruby
If I were a CTO, I would make sure that I have a team who could fork and maintain any open source library they used. I.e. I wouldn't worry about it. 
Problem half-solved! I can download small files only larger files do not download. You got me on a new track. Now I'm seeing that `base64.StdEncoding.DecodeString(fileDataRaw)` results in the following error message being produced: illegal base64 data at input byte 65532 I need to dig deeper. Thanks for your help.
Lots of gems in here, one of those "watch it because you don't know what you don't know" hints, learned a lot about the toolchain from this.
&gt; https://www.youtube.com/watch?v=HxaD_trXwRE That's a very good presentation. Thank you!
I usually look here to start: "Awesome Go" - https://github.com/avelino/awesome-go But remember to code review where it makes sense. This is a real threat everyone should be aware of: https://hackernoon.com/im-harvesting-credit-card-numbers-and-passwords-from-your-site-here-s-how-9a8cb347c5b5 
I hope everyone does who claims to be an engineer reviews* their dependencies, initially and every time they update them. review*: at least look at each file at least once. 
can someone just link to the slides...infoq is so annoying about that
&gt; I have a web server running at the remote side. From my java debugging experience, every time I attach to a running process, it halts the it. The IDE will print the stack frame at the halt point for all threads (for golang, this is goroutine I guess). But I got nothing to display from Goland. I've created this as a feature request for the IDE: https://youtrack.jetbrains.com/issue/GO-5245 &gt; I can't simply set a breakpoint as the web server is a large project. Currently the running path is unclear so most likely a breakpoint I set will not in the running path You can set the breakpoint on the first line in the handler that you are interested in following its execution or in the method / function you are interested in debugging / observing. 
How do you encode the file to base64 and what's the type of your SQL column? There's a few things that comes to mind but of course I can't really test without your full setup. 1. If you are using a VARCHAR column instead of BLOB the database engine will treat the data as text and apply collation to it, which could fuck shit up. 2. You aren't encoding the same way you are decoding. ie: NoPadding vs w/ Padding 3. Maybe something unrelated to what you presented us here. 4. Some fuck up with the headers &amp; content ie: Not POSTing a multipart/form-data or not correctly POSTing a pre-encoded file. 5. Anyways, you will want to stream the response to the client for performance reason and because it can close the connection/timeout before your server finish decoding. 
+1 to what /u/des09 and /u/mistretzu said, but going down your list for fun: - authentication/authorization: this depends too much on what you're doing. You might like [this list](https://github.com/avelino/awesome-go#authentication-and-oauth) for something "out of the box". - messaging: [gRPC](https://grpc.io/) is all the rage these days. - http2: The standard library http client has some of the best http2 support of any language: https://golang.org/pkg/net/http/ - websockets: https://github.com/gorilla/websocket is what most people use - emails: The standard library is pretty decent, but [more here](https://github.com/avelino/awesome-go#email). - database clients: Lots of SQL drivers in the standard library: https://golang.org/pkg/database/sql/, but also many modern databases are actually written in Go. Depends what you're looking for, lots of things here including ORMs etc: https://github.com/avelino/awesome-go - caching: [groupcache](https://github.com/golang/groupcache) is surprisingly good, but there are again just too many options for various cases that it's hard to pick one. - distributed configuration management, service discovery clients, scheduling, deploying, monitoring, etc: All the standard modern tooling applies to Go too. Kubernetes is pretty popular these days. - logging, profiling, tracing, etc: Go has some of the best tooling for this right now. Lots of great posts here: https://rakyll.org/ and https://medium.com/@rakyll Hope this helps.
It's definitely a Javascript-able build tool! Definitely no more Makefile syntax. I did a super small test (making sure the tool can execute `dir`) on Windows as well. Some of the commands defined in a build file might still be incompatible with Windows though. I am going to add build-in-docker support which will help that situation soon.
**What is inside?** * Calling recover outside of a deferred func * Calling defer in the wrong order * Not checking for errors * Releasing the same resource twice * panic/recover can get and return any type 
Hardly a fair comparison. The JavaScript implementation is O(n^2 ) and the Go one is O(n) when you take into account the benchmarking loops. Edit: typesetting the superscript
Good catch. Recursive Fibonacci is closer to O(2^n ).
Python provides a very dynamic and feature rich environment, especially with machine learning and mathematical libraries to perform calculations without much programmer overhead. Golang is slightly faster, but doesn’t currently have significant backing in terms of open source libraries (especially in financial computing). For this type of project, I would use Python as you would have access to a multitude of libraries like Numpy which will help you out.
I think the reference here is based on github’s stats of language used in projects. It’s not weighted and Node packages tend to be on the small side so there are a lot more smaller projects in node then in other languages. Also, many of the really popular projects are self hosted. Popular Java projects, for example, are usually hosted by Apache. Further screwing the results. I alway have to put my skeptic hat on then a paper opens with a poorly thought out comparison with out explicitly citing the source. Generally it means the paper is full of confirmation-bias. 
I am primarily a web API developer and microservices systems architect, so I have a biased opinion. Two right off the bat I cannot live without: github.com/stretchr/testify/assert Being able to assert on various conditions makes things SO much nicer and cleaner. github.com/jmoiron/sqlx NamedExecs, auto-scanning, and more makes this a dream to work with. Database access has been far more elegant. I also love Chi, but enjoyed Gin and Gorilla.
I stand corrected.
&gt; Golang is slightly faster Slightly? More like 10x faster than python (unless your python code actually is C code with python as a glue, which is the case for numpy). But pure Python vs. pure Go code, the speed difference is big. 
Raw performance yes, but using a library like Numpy or TensorFlow can bring Python to a comparable speed to Golang.
If you're going to implement a simulator for pilot-run or backtesting, efficiency of CPU cycles would still be concerned. Also, I believe Go is better for unattended, long-running process when it comes to reliability. But Python is better if the task involves mainly interactive operations. A REPL interpreter is clearly nicer than edit-compile-run.
It's not a standard lib, but gorilla/websocket is better than x/net/weboscket. 
&gt; http.ServeMux is a good example. Is it? Maybe I am alone in this but I've been using ServeMux for years and I've had no issues.
I got the impression that it cannot do parameters, doesn't do the subroute composable thing, and performs pretty bad compared to everything else, if that matters.
In all my years writing high performance services in Go I've not once seen HTTP routing show up in my pprof output.
Looks like the Go code is even O(1), given that it only calculates fib(1): func fibonacci() func() int { x, y := 0, 1 return func() int { x, y = y, x+y return x } }
...which has a constant number of iterations (30).
I would agree. DB Access, I/O, network calls, etc tend to be far more draining on performance than a good HTTP router. I mean, I don't use the standard router, but I haven't encountered a situation in which the router was my bottleneck. 
Yeah I should have been clearer when I said "take into account the loops" (ie n loops) which makes the JavaScript one even worse, given that I got the recursive complexity wrong.
Can you show what do you want and how does it is side by side please?
[removed]
[removed]
Do you have any other extensions that might format the file? I had an issue like that and disabling the extension fixed the issue.
The canonical go format is that the opening curly goes on the same line. Just go with it - the go fmt tool will reformat your code this way anyway.
Oh, I might not have made myself clear. Code gets formatted usually like: Foo() { int i For (i=0; i&lt;100; ++i) { //loop } } But I don’t like it this way since it is harder to tell which brackets have been closed so in Java, that is what I usually use, I format it like: Foo() { int i for (i=0; i&lt;100; ++i) { //loop } } However building it like this throws errors. Is there a way to fix it?
If it matters, everything else except fasthttp is literally built on top of net/http.ServeMux. So... I'm not sure to what you are talking about when you say it's performing pretty bad comparing to the everything else (which is built on top of it), but I'm sure you've got your facts wrong. The only issue with net/http is that it doesn't have a convenient way to handle the various routing other packages depend on, and you'd need to build your own router every time. See an example here: https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html And to add to dgryski's user report, I too have never experienced issues with the http performance in Go, mainly because by the time a real app gets to be used, I run out of network bandwidth, memory, performance on the dependency services (which usually have the similar recursive problem), etc.
Am I the only one that has a problem with the "volume" of testing? &gt; For this we ran a longer test using loadtest, sending a total of 1000 requests at 10 requests / second using five concurrent workers. We turned on keepalive. I know how lambda is supposed to work and all, so don't even start on that, but if you have a workload like that, optimizing for speed seems like a low priority when instead it could be readability or maintenance...
They probably have more important things to do rather than just rewriting their website which serves them well. Because otherwise one could ask why is the machine learning not done in Go either, which would have the same answer.
You mean like this? Foo() { int i For (i=0; i&lt;100; ++i) { //loop } } Foo() { int i for (i=0; i&lt;100; ++i) { //loop } }
Did you just make a struct with each error appended to the fields slice? And then JSON serialised?
Four spaces at the beginning of the line to format code. Something Like This
Yes. This allows the user to show the errors for each individual field. The fields object can contain errors for multiple fields at once.
i would stick with whatever is the idiomatic way of writing stuff. if you can get over this everything is much simpler. No debates about code style, everything looks the same, git commits only show actual chnages etc. go fmt is our best friend!
[removed]
[sqlx](https://www.github.com/jmoiron/sqlx) has been very helpful. Without it, while fetching data from my database, I'd have to make variables for each column, with the same name as the column in the DB, and then scan into those variables. Without sqlx: query := "SELECT username, userage, userheight FROM person" rows, err := db.Query(query) //do error checking here var username, userage, userheight string for rows.Next(){ err = rows.Scan(&amp;username, &amp;userage, &amp;userheight) } With sqlx: type Person struct{ var name string `db:"username"` var age string `db:"userage"` var height string `db:"userheight"` } rows, err := db.Queryx(query) var p Person for rows.Next(){ err = rows.StructScan(&amp;p) } `StructScan()` is super helpful. 
This fud that `http.ServeMux` is not good enough or even bad, needs to stop.
A great talk from a stripe engineer on how to gain better insights to whats happening into large scale distributed go applications Extract: &gt; Monitoring and Tracing Your Go Services by Aditya Mukerjee &gt; “If a Go microservice falls down in the middle of a server farm, does my pager make a sound?” &gt; If your service is automatically monitored, then the answer is “yes!”. But what if your service isn’t monitored yet? Or what if your monitors alert you when the server is offline, but not on subtler problems like latency spikes or CPU load? &gt; Fortunately, there’s a quick and easy way to get high-resolution metrics for monitoring your services. The Go standard library now contains the basic building blocks for application tracing. When you combine these tools with Veneur, a pure Go distributed metrics aggregator, you can easily answer the questions you care about, like “Which servers are currently running near maximum capacity?”, or “Can our infrastructure handle tomorrow’s product launch?”. [All GothamGo 2017 Conference Talks](https://talkery.io/conferences/505?pageNumber=1)
&gt; Foo() { //Memes } Not a valid Go snipper. Do you perhaps mean func Foo() { bar() } Because `gofmt` keeps that style: https://play.golang.org/p/l_25FYqnEB_F (click "Format").
Have you considered putting a few examples in the readme? Often times I find myself not using code without examples, even if it is as short as yours
I'd submit that while some of the other problems mentioned here are important, there's another one this is overlooking, which is that this sort of numeric code where it is trivially provable that everything is an int is easy-mode for JITs. This is the sort of code that JIT writers use to say "With a JIT, our code is 50-100 times faster than it was pre-JIT!". They aren't lying, expect perhaps by omission when they fail to correct everybody else who runs around thinking "Oh, a JIT language means I'm getting the same speed as compiled languages on everything!" This is, however, not true. On real code, JIT'ed languages seem to have hit a speed barrier somewhere around 10x-slower-than-C, and I haven't seen a lot of evidence that leads me to believe they're going to get very far past that. Plus they typically pay a _lot_ of RAM to get that additional speed. For this benchmark, if you're going to run this sort of code, my suggestion would be to elide the code entirely and just benchmark the moral equivalent of "return 1". Then everybody will see that you are measuring function overhead in lambda for the two different languages, which is a perfectly legitimate question to answer. It turns out to be really hard to write a useful microbenchmark for comparing a JIT'ed language to anything else, because it's hard to get a realistic test suite that covers what real code does in those languages. Unless your code really is just manipulating numbers, you can't use numeric manipulation code to test JITed languages real performance.
Or even better: type Stuff struct { ID int64 `json:"id" db:"id"` UserID int64 `json:"userId" db:"userId"` SomeField int64 `json:"someField" db:"someField"` } func GetStuff() ([]Stuff, error) { stuff := make([]Stuff, 0) err := Config.DbConn.Select(&amp;stuff, "SELECT * FROM Stuff") return stuff, err } 
Wow, didn't know that one. Thank you. 
&gt; anything in widespread use. I don't think SOAP has been in *widespread* use for a few years now.
Oh yes it is! You'd be surprised how many commercial systems still utilize it to full extent up to this very moment and have no plans to replace what's been working all these years.
That's great that you use JSON serialization of protobuf v3. But I really talk about what you call "Twirp JSON protocol", not about serialization. About that thing: POST /twirp/twirp.example.haberdasher.Haberdasher/MakeHat Content-Type: application/json {"inches": 10} If you tweak it a little, you will get a proper JSON-RPC 2.0 request: POST /twirp Content-Type: application/json { "jsonrpc": "2.0", "id": 1, "method": "twirp.example.haberdasher.Haberdasher/MakeHat", "params": {"inches": 10} } JSON-RPC 2.0 clients exist for every language already.
I know I already said this on Hacker News, but it bears repeating again... describing the _entire semantics_ of defer, and every possible way of using it, as a _gotcha_ is... how to put this... not conveying the truth properly. Especially when you title it "Gotchas Part III" and then the first paragraph is "well, not _gotchas_ per se, more like techniques". You're clickbaiting. Since you claim to be creating a Go course, let me suggest that you be much more discriminating about what you call a "gotcha" in the course. At the rate you're currently going, you're on track to create "The Five Thousand And One Gotchas Of Go", which in actuality is just a slow walkthrough and expansion of the Go specification document. By labeling _everything_ a gotcha the poor student won't have any clue what actually _is_ a bit tricky, not to mention coming away thinking what is _literally the simplest general-purpose language in current common use_ is somehow riddled with gotchas. Goodness only knows what you'd make of Python or C++ or something if you treated it like this.
Interesting. I didn't compare to Goja but I will now. Otto doesn't seem to implement an exact standard, but that hasn't slowed me down yet. If Goja has an easier to use API, I'll go with it.
Why is it preferable to expose a stream of bytes interface on a message based protocol? That seems like a design error to me. 
As an employee at stream.io I can tell you that this is indeed the case. Our website doesn't need nearly as high performance as our API. In theory it could be rewritten in Go, but the Python version already works and handles the load we have just fine. The machinelearning is another story though. It's not likely to be rewritten in the foreseeable future, since most good and easy to use ML libraries are not available in Go. 
Is there a way I can remove the green lines asking me to convert all ***Id to ***ID?
In reality, reflection should be used very sparingly. Almost every time I've seen devs try and use it in-house they were solving their problem improperly, or were solving the wrong problem entirely. 
Ah, I see what you're saying - you're talking about routing. We use the same routing scheme for Protobuf-encoded messages, not just JSON-encoded messages. That would mean we would either need two different routing schemes (one for JSON, one for Protobuf), or we would need a similar proto-encoded wrapper for all protobuf requests. Each option is a significant increase in complexity. I don't think the benefits are quite worth that cost. Sounds straightforward enough that someone could make an adapter you could plug in, though, if you really needed this.
Thanks for the response. most of what you enumerated are lacking in Go not because of immaturity of the language, it is old enough to be mature in these directions IMO, but because of the strong community views. For example, I do not see ORM or web frameworks being ever widely accepted in Go community. That means we will never have Django of Python or Rails of Ruby in Go. The community view on this is so strong that it feel to me if Go 2.0 comes with generics, a big chunk of the community will continue with a forked version of Go 1.0. My question was not all about making the response time shorter for the website. It was also about the development side, having the ease of working with a typed language, single binary deploy, and much more. It is interesting to see that companies are not widely using Go for their websites, in fact, I am not aware of a big enough company that does that. Stream was another confirmation.
I agree! It's a tool you should only go to when you need it. The subsequent post gives some examples of when it makes sense.
So how do you do params?
Don't underestimate something like gonum in terms of a Numpy like library. There are many others in the Data Science field for Go that are up and coming.
While I really like the concept of streaming data through a sequence of processors, I wonder what the performance impact is and if it really is faster than just loading it into memory and applying the processors in sequence. Some preliminary tests on a minifier (stream of text -&gt; tokenizer -&gt; parser -&gt; minifier -&gt; output stream) showed worse performance due to additional bookkeeping, goroutine lock-ups and channel coordination. I feel that there are only certain use-cases that benefit from streaming: - When the input is too large to fit into memory (or if you want to reduce memory consumption to a minimum) - When the input stream comes in slow (slow internet connection), so that it makes sense to already start processing what you have Other than being memory constraint or having slow input, I think non-streaming implementations will always out-perform streaming implementation. What is really the advantage of streaming then?
To get useful help, you'll need to put the JSON response into the code as well. I suggest using the Go playground to post the request; it makes it very easy to support people in situations like this. If you include it in the post and decode from the []byte, it'll probably be easy to answer. As it stands now, the best thing I can give you is "Your struct probably doesn't match the JSON you're getting back."
If you end up doing a lot of network calls though, it's easier to do those concurrently on Go than Python 3.5 imo :)
Unfortunately the server is closed to the outside :\ and my admin is gone so I can't open it to do that. The response stored in res is a giant byte array. Unless I'm missing something, I thought the bytes fed to json.Unmarshal were decoded when stored in the pointer to the struct?
That sample is enough to see the problem. You're trying to decode an object, but what you have is an array. I believe if you change stuff to be `[]data{}` instead, it'll decode into a slice with one `data` element for you. I wasn't asking you to open the endpoint; I was asking for a sample []byte embedded in a go playground instance so we could see a sample of the source data, which is what turned out to be necessary to identify the problem, since the code looked correct. If you know your datapoints are ints, I'd recommend setting them to `[][]int` or something as well; you're going to get tired of the casting from `interface{}`.
Possibly, at times they can be null so setting it as a slice of int could throw an error couldn't it? I used some null examples when I used the json to go converter tool Changing it a slice of the struct worked perfectly. I didn't even think about the array brackets around the json object thanks!
[removed]
Im sorry to say that you cannot write go code like that. This is because of the fact that we do not have to add semicolons to the end of lines. If you were to open the function body on a new line the lexer would add a semicolon before the opening brace and that would cause unwanted effects. https://golang.org/doc/effective_go.html#semicolons
&gt; When the input is too large to fit into memory (or if you want to reduce memory consumption to a minimum) &gt; :)
Here's a [way to do it](https://youtu.be/yi5A3cK1LNA?t=11m44s). In case you don't know the speaker, he is the creator of [pat](https://github.com/bmizerany/pat), a small but still popular http muxer which he admits he doesn't use anymore.
[jray@jray-pc ~]$ go get github.com/GoesToEleven/GolangTraining can't load package: package github.com/GoesToEleven/GolangTraining: no Go files in /home/jray/go/src/github.com/GoesToEleven/GolangTraining 
the folders exist but the content does not
You could create a REST api in a Go web framework and then serve a Single Page Application (in Angular or react etc)
go1.10beta2 was released last week also.
Bit of a broad question. If you wanted something batteries included you could try something like https://gobuffalo.io/ If you want something much less opinionated you could use http://www.gorillatoolkit.org/pkg/mux and http://jmoiron.github.io/sqlx/ to get you going with an API, the build your front end using Vue or React or whatever, and reuse it when the mobile app comes up?
The web browser API is message based and Gorilla has an API to match. If an application layers a stream abstraction on top the browser API, then the application should do the same on the Gorilla PI (it's 20 or so lines of code). If not using a browser and using streams, then there's little reason to use Websockets. Just use a TCP connection. 
How so?
You should follow the Go conventions while you are writing Go. You wouldn't use snake case for your Java variables would you?
Basically just the bullet points you suggested. 
"Mouth breather. " 
Lack of features? 
Actually, ou may find some example in test code :)
TL;DR 1. Default [HttpClient](https://golang.org/pkg/net/http/#Client) shouldn't be used in production. If we read the doc we are told that the default timeout is infinite. 2. To reuse connections from your pool you actually need to read the entire body of the response and not just close it: ``io.Copy(ioutil.Discard, res.Body)`` with ``res.Body.Close()``. 3. Timeout control so you don't let potentially long running process hanging forever. A bit of personal comment, I felt like the only data that was available at Kurio was just response time, memory, and cpu usage. I don't know how long it took to find the issues but the profiler could have helped along with more metrics, and logs. As for 3-4 the hotpath for the API always start 3 go routine, it's not free to start go routine and I would be interested to profile the performance of the current pattern vs different ones ie: Job/Worker pattern
Have you tried deleting the empty folders and running go get again?
`json.Unmarshal` returns an error. You might want to check that. I think the `[][]interface{}` might be the issue. I would recommend that you unmarshal it as a `[]interface{}`. Subsequently, you can access each of these `Datapoints`' value perform a type assertion on concrete array of some type.
Yeah it's quite common. I think Algolia also does something similar. C++ for the API and Ruby for the site. It's not so much that you can't do this with Go, it's just that the ecosystem in Python/Ruby is better for building a simple site. On the other hand. Django was first created by a tiny team. 2-3 devs can have an impact. Just have a look at Phoenix for instance.
That did not answer my question.
If you're referring to the word list reading example, then `ScanWords` indeed is the right one.
Interestingly I have toyed around with the idea of building a package very similar to this as a 2-3 part exercise for Gophercises.com
This bench tool is used to test the whole processing of rpc frameworks, which contains transport, message encoding/decoding, message processing style, business logics time. Basically it is like apache bench tool. `-c` for concurrent clients and `-n` for total test messages. I have added a new option `-option` for mocking time of processing business logic such as calling another services, accessing databases and cache. So it looks a rpc service as a black box and use concurrent clients to test the benchmarks. Of course, there are many different cases to use rpc, long biz processing time ,short processing time or others. So I think you should design your test environments for your cases. This tool is is an option to help you do this. At least, it provides three options: concurrent clients, count of total messages and a mock processing time. 
Where are you getting number 2 from? The documentation notes that closing the response body is sufficient. From what source do you gather that you also need to read it? https://golang.org/pkg/net/http/#Client.Do &gt; If the returned error is nil, the Response will contain a non-nil Body which the user is expected to close. If the Body is not closed, the Client's underlying RoundTripper (typically Transport) may not be able to re-use a persistent TCP connection to the server for a subsequent "keep-alive" request.
Use the Go naming conventions and the green lines will disappear. Don't sweep the dust under the carpet.
Write a [Progressive Web App](https://developers.google.com/web/fundamentals/codelabs/your-first-pwapp/) with a Go backend. It's much cheaper than developing a separate mobile app.
`go get github.com/GoesToEleven/GolangTraining/...`
Um, maybe not quite yet: "SAM Local supports the following AWS runtimes: node.js 4.3 node.js 6.10 python 2.7 python 3.6 java8" 
That wasn't his point at all though
Should it be called a relational database library if it doesn't support relationships? 😜
Does it work on iOS yet ( service worker in the background) ? 
Agreed, I've never heard of the need to fully consume the response entity before closing it.
It works on Safari using polyfills.
[Standard Package Layout](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1)
I thought about this _(assuming I understand you properly)_, but doesn't that present the same problem if you want code separation? Eg, lets assume each of those 3 packages are quite large, so combining them is a no-go. If we invert it, it might look like this: /users/client /users/handler /users/db So while that works great for the respective client/db packages, it conflicts again to consumers of those packages if they use other packages. Eg, it would conflict with: /content/client /content/handler /content/db Note though that in that example I'm clearly not using an interface to abstract the need for `client` returning a special `db.Content` type, if instead it was `content.Content`, that would solve this *specific* basic example. However, even in my basic codebase, the Client and the DB offer very different methods for varying reasons. Having to always make my HTTP and DB match big monolithic interfaces seems heavy handed, and that's ignoring the non-idiomatic interface that the many-method construct would become. I suppose they could be made to be mirrored, always - but that seems quite inhibiting, and I don't feel like enforcing code changes due for the sake of code organization is the end-all solution. Note, I'm not arguing, just trying to discuss. Fwiw, the Standard Package Layout is apparently what I've been using in all my other projects, and I've done so strictly to abstract the http vs local implementation of code. So for that it's worked quite nicely. Perhaps I should try it for this too, and see what issues I encounter.
Hmm, immediately I ran into an issue haha. My `content.ContentService` returns something like `Content() (*UserContent, error)`, where `UserContent` has both a Content, and a User on it. This isn't inherently a problem, but now we've the `content` package referencing the `user` package, which could lead to circular problems down the road. Hmm
&gt;Where are you getting number 2 from? I got number 2 from reading OP article (it's a TL;DR) ;) First time I heard of it as well. I did do a small research on the subject to make sure that it's not just plain bs but it was late and found old threads on the subject. I just double up the effort to get a bigger picture and here's what I found: The HttpTransfer is supposed to [discard the body](https://github.com/golang/go/blob/release-branch.go1.9/src/net/http/transfer.go#L942) but there are a few problems that people said they fixed by flushing the body manually (beside OP): [Why is Go HTTPS Client not reusing connections?](https://stackoverflow.com/questions/17959732/why-is-go-https-client-not-reusing-connections) I haven't tested it myself but could it be that it's because Transport wasn't set with [MaxIdleCoons](https://golang.org/pkg/net/http/#Transport)? &gt; &gt; // MaxIdleConns controls the maximum number of idle (keep-alive) &gt; // connections across all hosts. Zero means no limit. From OP own link to where they got the [idea (it's right above that paragraph)](http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/index.html#close_http_conn). ["Now it's your responsibility to read and discard the remaining response data."](https://i.imgur.com/xj0n6q0.png). [But according to the go team, connections are re-used and you don't have to manually flush the body.](https://github.com/golang/go/issues/15703)
&gt; Can you just not be an asshole? Excuse me for trying to help.
Well maybe I didn't phrase it correctly. I am not saying that you should use a `package model`. This is definitely an anti pattern. You shouldn't keep all-all your structs in your root package either just for the shake of it. What the article is saying and what Upspin does are not mutually exclusive. In fact they might be the exact same thing depending on your definition of "service packages". For example Upspin has a bunch of structs and interfaces in `package upspin` but it also has structs and an interface in `package metric`. By now I am almost convinced that thinking about package structure using terms like "models" and "services" is problematic. Sometimes you need to do what makes sense for your project. 
Go support is being worked on: https://github.com/awslabs/aws-sam-local/issues/264
&gt; You fall into the fallacy described in the video as Predetermination. You have already decided that you will forever use an external router because http.ServeMux "lacks features". This is not what I would call good engineering. I know I need url parameters, I need to group routes together and apply middleware differently to each group, and I want easy subrouter mounting so I can compose my app in smaller pieces and plug them together. It looks like if I used http.ServeMux I'd have to reimplement this all myself, so I'm going with chi.
Just a quick suggestion: rename your ContentService in the content package to simply Service. Instead of content.ContentService it would be content.Service
You might consider one of the frameworks built around lambda. Apex has a command for invoking your functions remotely. http://apex.run/#invoking-functions Serverless lets you test locally using their emulator: https://serverless.com/framework/docs/platform/commands/
Sure, use whatever makes sense for your project's requirements. But saying "I'm never using http.ServeMux" without talking about the project's requirements is not very good.
I am trying to work my way through https://awesome-go.com/#web-frameworks and slowly building this simple middleware package to help me do normal input -&gt; output processing on data. If I'm missing something please let me know. I'm still learning about Iris dark past and how martini had too much magic so @erizocosmico wrote negroni. 
You used to have to drain the body, many versions ago. I think that was changed around 1.5 or so so that closing handles it for you. 
Agreed completely. :)
you could have "a" be shared state among multiple goroutines, and have a race that is modifying it in a loop. At some point, the condition would evaluate to true. you could even run the program under an x86 emulator which implements that every equality instruction always finds equality. in my opinion, this is a pointless mental exercise, just as it was during that interview.
The shared-state race condition is the only way I could think of in Go as well.
I'm not sure I understand. It compiles and works just fine: https://play.golang.org/p/KsYTpJlGrzB Were you declaring both versions or something?
Sure it can: https://play.golang.org/p/-gF1qvNiUOy
That doesn't work.
&gt; it would work only for *point type and not point type itself This is not true. [It works for both types](https://play.golang.org/p/O4K5BEwVAvp). Rule of thumb: Use a pointer if your method needs to modify the struct.
what the fuck
&gt;Simple and free from slow, magic packages like reflect Go's reflection is neither slow nor magical. It actually beats the marshaler for speed for certain applications. Blanket statements like this tend to perpetuate a myth that's true in other languages. 
It's not pointless. This is a legitimate source of bugs in languages with a lot of implicit, overridable behavior, and it's a valuable data point in the skill level of a programmer whether they know this, because it's probably because they've experienced it.
&gt; This is a legitimate source of bugs in languages with a lot of implicit, overridable behavior It is no such thing.
A sufficiently smart compiler could easily optimize that comparison to a constant `false`. Remember that a program with data races is not a valid program.
Thanks, this worked.
The question was about Golang, not some hypothetical language. If you're going to say that bugs or undefined behavior make a program into "not a valid program", then I hate to tell you that basically all of the software we run today is made of "not valid programs".
Posted in response to this? https://codeburst.io/javascript-can-a-1-a-2-a-3-ever-evaluate-to-true-aca13ff4462d But Go doesn't allow operator overloading. 
I assume you've never used Ruby then?
[removed]
In general, you pick whether your is expected to be used as `T` or `*T` and implement the methods on whichever you choose.
I think the premise for his argument wasn't well formed, since I agree with you this condition would be a rare encounter. But I do agree with his argument that it isn't pointless, going through enough thought exercises exactly like this was what allowed you to draw a conclusion. Which enabled you to write two polite and helpful sentences for the OP, the trailing line had a hint of condescension which turned things contentious.
Fun but that's not really answering the main question (it's not the same "a").
If a candidate can answer OP's question (in languages where operators can be redefined, not in go), he will probably be able to find potential errors in custom equality operators.
&gt; If you're going to make a correct assertion, then I will be forced to respond with hyperbole.
Did you read *but passing by value for big structures is inefficient.*?
gcc is a sufficiently smart compiler. Undefined behaviour in C is a real problem because it's so easy to hit. The Go specification doesn't even mentioned 'undefined'. The Go compiler produces code that assumes there are no data races. I probably should have said "conforming program" instead of "valid program".
Doesn't it make three hardest problems? I would however add timezones and DST to the list.. 
Hence "off-by-one errors"
&gt; Did you read but passing by value for big structures is inefficient.? * There's no such thing as passing by reference in Go. Everything is passed by value. Everything. * You should use a pointer when a pointer is appropriate. * Write simple, straightforward code. Aim for semantics first and efficiency second. * Optimize code only when necessary.
OK, mind blown, can someone explain, so I can goto: sleep
If you look closely, those aren't a's, they're characters from the Canadian Aboriginal Syllabics block, which are allowed in Go identifiers. From Go's perspective, those are just three long identifiers. 
I would be careful with that. I don't think can exactly do this in Haskell, but you can play with the Eq type class for a custom type.
This particular problem has more to do with type safety than functional programming. For instance if you have the ability to define == as a function to always return true then functional programming doesn’t help you.
Alright, you can possibly do this one, but you can't get this to work in Haskell: a == 1 &amp;&amp; !(a == 1) Which you can get in Go, JavaScript, etc.
Exactly as another comment described, by concurrency with shared variables and race conditions.
That comment was deleted but I understand now, thanks.
My Haskell isn't amazing, but data Fnord = Fnord Integer instance Num Fnord where (Fnord a) + (Fnord b) = Fnord (a + b) (Fnord a) * (Fnord b) = Fnord (a * b) negate (Fnord a) = Fnord (negate a) abs (Fnord a) = Fnord (abs a) signum (Fnord a) = Fnord (signum a) fromInteger = Fnord instance Eq Fnord where a == b = True main :: IO () main = do a &lt;- return (Fnord 42) print (a == 1 &amp;&amp; a == 2 &amp;&amp; a == 3) return ()
I suggest a user package with (generally) a file per responsibility. user/ db.go service.go handlers.go ... In DDD terms, I tend to use an aggregate root to determine package scope/context. Organization like this allows you to more easily reuse packages or split them out of a given repo when needed. Think of packages as small self contained services within Services, each with their own "public" interface.
Eh, wasn't sure if the compiler would optimize things away (maybe more likely in the original version). https://play.golang.org/p/QaNx44K_gx4 Doesn't work on play, but locally it works very quickly.
aaaarggggghhhhhhhhh .. of to bed !!!!!!!!!!!!!!!!!!!
What do you suggest ? 
Curious: Does Go allow overriding of equality according to some interface, as in C++, Java, Ruby, Haskell? If so, implementing an EqualTo() or such could be specially implemented to return true for inputs 1, 2, 3, ...
Without getting into details, I will cover only a minor portion of your discovery adventure, namely old hardware. I can confirm from my own experience that Go can make you think twice before throwing away old "junk". To be more precise, last year, I was cleaning up, and about to get rid of a 2009 Asus EeePC netbook with two 32bit cores and two Gigs of RAM (had upgraded from 1 back in 2010). I had just refactored a self-made rudimentary, on the cheap, trading system written in Go, into several modules: - provider (pricing streams and trading atomic operations from various registered online players) - broker (pricing and trading messaging, currently using nats.io) - recorder (dump the real-time streams into a time-series for post-mortem, at rest weekly macro decisions, plus later backtesting replaying; currently, using influxDB) - workers (handling strategies, trading decisions, etc) On a whim, I installed ArchLinux (32bit CPUs only community supported at this point) on that EeePC, and moved the provider + broker + recorder components on that pc, and I can tell you it copes very well, leaving the strategies + trade decisions components handled by a fleet of Odroid XU4s. Empirically, I had noticed that Java's newer generations garbage collectors are generally unsupported or a complete disaster on older, 32bit machines. I originally wanted to use Kafka instead of InfluxDB: the CPU simply spikes in a demented manner. But with Go, CPU usage is manageable. To sum up, as long as you have a concrete idea to implement, I think you should aim to repurpose any old hardware you have before you throw it away. I have no comments regarding the 100K reqs/seconds. Cheers and good luck
But don't goroutines only pre-empt each other except at well defined boundaries? Or has that changed? Could there be a data race in between expressions like that? Looks like /u/nevyn below has had to add manual yielding in a function call to achieve an approximation.
Pretty cool. Seems to be one guy running the show. I would love to see a full stack golang web app framework that can actually compete with JS frameworks.
That'd be great. We still have to rely on some JS to interact with the DOM, but hopefully browsers will eventually let us run WASM binaries without needing the js interop.
it is possible for a not-well-written concurrent program, though the possibility is very low.
In your test, you run gRPC using `RegisterHelloServer`, which runs the code on an http/2 server. For Twirp, you run it with `http.Serve`, but you don't set TLS configs, so it's running on HTTP 1.1. This is what I mean: the test demonstrates that, when making many concurrent requests from one machine, http2 is faster than http 1.1. But Twirp could be run in http2 just as easily if [this line](https://github.com/rpcx-ecosystem/rpcx-benchmark/blob/master/twirp/twirp_server.go#L38) were changed to use `http.ServeTLS`. This would make a very big difference.
The example talks about "function closures" which is what is causing what you're seeing. Here's some extra reading on it: http://keshavabharadwaj.com/2016/03/31/closure_golang/
https://golang.org/ref/spec#Function_literals
&gt;In other words, the function defined in the closure ‘remembers’ the environment in which it was created ah, right! thanks! now it makes sense
You should catch and check the error returned. Also it looks like the JSON is an array of objects that match you ‘data’ data type, but you are trying to marshal it into a single object. Change your local variable to be of type []data. 
But when you are passing the pointer by value you are copying much less than you would with a very large struct, no?
This is the way to do it!
Thanks for the interest. Join the conversation here https://gitter.im/spacemesh-os/Lobby
I will change the code to use TLS for Twirp, thanks.
Not sure if allusion to generics joke. Have an upvote.
I like to build my HTTP services so that can run as a "normal" service, or as a Lambda function behind AWS API Gateway. In this case testing is just testing a HTTP server, once you're comfortable with the wrapper that transforms the Lambda event into a HTTP request for your HTTP service. The other case is where you have a function that is invoke via something like a Kinesis event. I test those as a service that receives an event I can create in unit tests. I know you said not unit testing, but there you go. Once your local testing is solid, why not use Lambda for actual integration testing? It is super cheap and if you're only testing a limited number of interactions you're definitely not going to break the bank.
go-swagger is a great tool define a REST apit and you can generate the go code for the server, models and you just register your handlers / write business code. Helps alot to fathom about the API at a later date, i.e. what does this route take / receive and because you generate the core API objects from it its always 100% in sync which we have found most useful especially if you need to provide your API to someone, external testing services etc which you may have to if it handles sensitive info. With the rest API in place you can write a mobile app. I would suggest React because you can write a website in react easily, then write a mobile app in react-native -&gt; create android and ios version easily. With a tool called expo its particulary to build / deployreact-native applications so long as you dont have to do something complicated / write your own code native code. If its hit a few API's, present some data it works great.
Cool project ! That's exactly what I'd like to experiment while learning Go. Thanks for sharing.
Yeah so? You are also forcing an extra lookup, allocation on the heap, extra work for the garbage collector, reduced memory locality and possible compiler optimizations that could be happening. If you want to do it right then measure and compare.
Thanks for the input ! Interesting piece of DB really. I see from your link that the 128b benchmark is quite similar to what I try to do actually. They claim to write 250M key/pairs of 128bytes at 5.920.000 reqs/minutes which is 99.200 req/s. This would be a total success for me, but they mention a HEAVY hardware with a i3.large instance which stands for: 2x cores at 2.3 GHz + 16GB RAM + SSD... Anyway, I am still confident :p ahah As to put everything on Github I WILL SURELY DO IT. Let me edit the post right now to mention that, thanks ! 
Yeh, I wanted it as close as possible to the question.
In RDBM world tables are relations, connection between tables are called references 
The word relational refers to the ability to have keys that can reference a foreign table. Simply having a table doesn't make a database relational. ANSI SQL uses joins and sub-queries for this. If you don't support that but you still have things like indexes then I would argue we have something a little more versatile than a key-value store but not a relational database.
Iirc, it sounds like he says it's possible now, just not super neat. I'm not sure if direct DOM access is available, but he mentions that interop is possible, and if interop is possible we can make *something* work. As soon as I _(or anyone I imagine)_ see an example of this, I imagine I'll work on an abstraction layer to write DOM code against.
The work being done can be found at: https://github.com/neelance/go/tree/wasm-wip?files=1.
[removed]
Maybe this way: https://play.golang.org/p/6Q5dCHPUWCL
Thank you, this appears to be the trick I'm looking for.
SOAP is still very much in use and even in the new apps. Don't overestimate startups and "tech" companies they are a very small group in the world of software.
The language basically requires that you have a single piece of code responsible for closing a given channel. Anything else is prone to panics. If you're having trouble figuring out: - when multiple producers are all exhausted: use a sync.WaitGroup - how to abandon pending items in the channel (when client goes away): use a `done chan struct{}`, such as provided by `context`
If performance (extra allocations) are an issue, you can also use a bytes.Buffer. https://play.golang.org/p/w1BqD0WI4qw
The reason that double closing a channel causes a panic is that a design where multiple goroutines can close a channel is subject to a race condition. The language is trying to force you to use a better design for your concurrency. Once you’ve done it correctly once or twice, it gets easier to reason about. 
You should test your assertions. This has the same number of allocs, and it's nearly twice as slow. Simple concat is faster than both implementations: https://play.golang.org/p/Q8V7UJ1UE0C BenchmarkWithJoin-8 5000000 260 ns/op 112 B/op 5 allocs/op BenchmarkWithBuffer-8 3000000 425 ns/op 144 B/op 5 allocs/op BenchmarkWithConcat-8 10000000 205 ns/op 48 B/op 5 allocs/op 
Looks like an interesting approach, but if it is just invoking Lambda functions I can invoke "real" functions from the unit tests. The addition of another component (the proxy) bothers me as it isn't something you have in production. Lambda event are just structs to Go. If you treat Lambda as a transport layer that delivers a message to your service a lot of the difficulties go away. 
First of all, start using &lt;-chan and chan&lt;- whenever you can, it helps the mental model. Secondly every channel needs to have an owner, which is the one closing it. If the channel only has one writer then it's easy, that's the owner. If there's multiple writers I usually end up using a special message for removal of one writer. The receiver then tracks the number of writers and owns the channel. 
I made some improvements: https://play.golang.org/p/vs04fUFlGsc 1. Buffer also allocates memory when necessary. To keep the risk at a minimum, you have to estimate how much space you need. I assumed that on average the numbers have two digits. 2. In this case, using `[]byte` directly is easy enough. 3. Instead of checking every iteration of the loop, just drop the first byte. That's way faster.
Instead of creating temporary strings or []bytes, have strconv put the result right in sbytes by using https://golang.org/pkg/strconv/#AppendInt 
`sync.Once` is also extraordinarily useful here.
This program will be used to decode a information packet provided by one party, and place it on a machine made by other party over RS232 (the goal is to replace the first parties windows xp only program) Use case will max out at 4-5 times an hour. So my biggest goal is to try and make it look less convoluted if I can, this is as much as anything a learning experience for myself (learn go, get back into programming again)
This looks super promising...
Long-winded, but I think very insightful. I doubt the majority of Go programmers will agree with some of the conclusions.
My issue is more with how it looks then how it performs, but yeah I'll be lucky if the machine will even accept over 600 baud for the connection.
As I said in my other answer, simplicity is better than clever solutions. Your code panics on an empty array...
nice one! and also nice that somebody measured it:)
Yeah this ended up removing the loop to read the characters into the []array, thank you
I think the author makes some good points, and this is one thing I really like about Rust. Personally, I think Go 2 should opt for the result type solution because it forces error handling. In fact, this is one of the reasons why I'm looking to Rust first to solve problems and then falling back to Go. I used to like Go's error handling, but that's before I used Result in Rust and mostly came from C's errno (terrible) and exceptions. I really hope the Go developers address this in some way.
Me too, error handling is abysmal in Go. Rules out an entire use case of lightweight scripting.
You're right, I interpreted that part wrong and was looking for an example that used `bufio.ScanBytes`.
I believe the recommendation by Dave Cheney is that the sender is who closes the channel. This simplifies things greatly because since it's what will be sending on the channel, it can make sure you don't try to send on a closed channel.
You can use React native and use Go as backend for creating rest/GraphQL.
&gt; Personally, I think Go 2 should opt for the result type solution because it forces error handling. I hear this phrase in one form or another fairly regularly regurgitated, but don't believe people understand just how many language features are missing to make this happen. First you need Attributes so you can implement the #[must_use] attribute for Result, so you may have your main selling point of "forces" error handling. Which is really just a warning from a tool chain that doesn't have to churn out assembly for 45~ architectures from 45~ years worth of language specification from a 30 year old code base, allowing better warnings that people pay better attention to. Now that we have our warning when we don't use it, how do we even know when it was never used? We need static guarantees about the lifetime of values, time to implement RAII. Throw away all memory semantics and that useless GC in Go, we will have clear owners for values and strict guarantees around mutability. So we need move semantics, ways to allow aliasing because writing software in a partial-ssa form won't be fun, welcome keywords mut and ref. Now when a value has to escape a function we need to carry lifetime information, change the call signature for every function in Go. Tedious, add elision, sometimes (when it makes sense of course, learn when that is), Coercion. What if a value lives forever? Keyword static. I could go on and on about this since it's a huge part of rust, but I think this paints the picture. I don't think I actually need to keep going, but so far we can _almost_ declare a Rust variable. Only need Generics to carry static guarantees for Result values, pattern matching semantics to make them useful. Pull in those features dependencies. Now lets give them behavior with Traits, which we sort of have in Go with interfaces, except we don't. Since Traits require explicit implementation and I don't see a way around this without breaking one of those tightly coupled language features that enables RAII, you have to throw away Go interfaces. See ya standard library, see ya Go. I would call it Gust, but I'm not sure enough is left for the G to remain at this point. That all said I like Rust a lot and have played with it a good bit now but I'm sure I may be off in a few places. The general take away here is that Go and Rust are so different comparing individual idioms or features just seems unreasonable, since it's the entire design of the languages that allow the features to have a cohesive feel.
When writing Rust, I do prefer plain "match/case" expressions to `try!`, `?` or those `unwrap` friends even if it looks more verbose. I feel healthier when taking fewer syntax sugars.
A very interesting article; I guess few of us have thought that deeply about error handling, propagation, and avoidance. A few minor comments: &gt; What to do with errors? We could write it to stderr, but fmt.Fprintf also returns an error, so what to do with that one? From all experience, the chance of failing to write to `stderr` is too remote to worry about. And if writing to `stderr` fails, your machine apparently has a bigger problem than just some Go process that failed. &gt; Plus, a lot of people end up writing return err far too often, simply propagating the error to be handled elsewhere Often, there is a simple reason for this: The local code lacks the context to handle the error sufficiently. After all, the error might result from wrong arguments passed in, and the local code cannot tell why the caller passed in those arguments that led to the error, and what the correct arguments should have been.
&gt; I think Go 2 should opt for the result type solution because it forces error handling. Personally, this is not a problem I consider worth solving (and the downsides would probably outweigh the upsides). I can't remember a single instance where not handling an error lead to bugs. I'm not saying there *is* no problem, just that I consider it blown out of proportion. Combine that with a) it pretty often being the right choice to ignore an error and b) the excellent comment of /u/epiris about the complexities hidden behind this feature and you end up with something, that I probably don't want in the language (I just happen to *also* think we have to be intellectually honest when talking about it and not claim Go would "encourage explicit error handling).
I agree. That's why I've put it under the "performant" solution. And I'm glad that it's only a little bug. I've written that code in my bed just before closing my eyes.
Unions (either union structs or full-on union types) would let you implement Result-style return values without resorting to generics, RAII or any of the other things you mention: fund Hello() string|error { Type assertions/switches could be use to match against the return value, and a shorthand syntax for quickly matching would be feasible. Go could natively provide some syntactic sugar to you "continue or return error", e.g.: s := try Hello() would correspond to (Go 1.x): s, err := Hello() if err != nil { return err } There are of course tons of possibilities, as well as potential issues. But unions would let you do this sort of thing more elegantly than today.
But this is about error propagation, not really error handling. I could nitpick the details of your arguments, but really, that would just miss the same basic point: In the greater scheme of things, it doesn't matter *that* much how we propagate an error, it is more important how we *handle* it. Could Go add more convenient/less repetitive error passing mechanisms? Sure, it could. You make two suggestions, both of which had been made very many times before. But *should* it? IMO, no: Making error propagation more convenient seems to lead to people doing it more, instead of inspecting the error, see what went wrong and correcting for it. Good error handling will include some control flow to differentiate between error conditions and handle them differently, or create new errors from them, which clearly say what went wrong and how to correct it. Making it easier to omit these isn't really a *good* thing, IMO. From what little exposure to Haskell I had, how broken error handling is was one of my main gripes with the ecosystem - precisely *because* they have both the things you mention library authors don't tend to invest any time in making good, robust runtime error handling happening (instead spending an incommensurate amount of effort on handling programmer errors). The question "would you rather write `s, err := Hello(); if err != nil { return err }` or `s := try Hello()`?" is a distraction; the answer is *neither*, because both are very broken. You should inspect the error returned from `Hello` and correct for it. How to do that will require thinking, code and will depend heavily on the application and the error - and no amount of syntactic sugar can take that off your hands.
Thanks, simple example added in README.
he just wanted to sound smart.
😊
Ahhh. Yes. Thanks a bunch, stranger!
Stay away from iris. The author has a shady history ranging from flattening the repo to remove contributors, banning people that post constructive issues for no reason, dissing other projects without basis. A quick google returned this: https://www.reddit.com/r/golang/comments/57w79c/why_you_really_should_stop_using_iris/ but there's more around.